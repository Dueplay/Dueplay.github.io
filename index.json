[{"content":"stl算法\n算法把迭代器作为中介从而间接操作容器中的元素，而不直接操作容器本身。所有标准库算法都实现为函数模板的形式，其中模板类型参数一般都是迭代器类型。模板化的函数通常可通过函数参数推导出模板类型，因此通常情况下可以像调用普通函 数(而非模板)那样调用算法。\n简单例子 1.find和find_if\nfind()在某个迭代器范围内查找特定元素。可将其用于任意容器类型。这个算法返回所找到元素的迭代器: 如果没有找到元素，则返回迭代器范围的尾迭代器。注意调用 find()时指定的范围不要求是容器中元素的完整范围，还可以是元素的子集。 注意： 如果 fnd()没有找到元素，那么返回的迭代器等于函数调用中指定的尾迭代器，而不是底层容器的尾迭代器\nauto endIt =cend(myVector); auto it = find(cbegin(myVector),endIt,num); // it == endIt -\u0026gt; not find // c++17 if (auto it = find(cbegin(myVector),endIt,num); it == endIt) { // not find } 一些容器(例如 map和 set)以类方法的方式提供自己的 find()函数。如果容器提供的方法具有与泛型算法同样的功能，那么应该使用容器相应的方法，那样速度更快。比如，泛型算法 find()的复杂度为线性时间，用于 map 迭代器时也是如此; 而 map 中find()方法的复杂度是对数时间。\nfind_if\nfind_if()和 find()类似，区别在于 find _f()接收谓词函数回调作为参数，而不是简单的匹配元素。谓词返回true或false。find_if()算法对范围内的每个元素调用谓词，直到谓词返回ture: 如果返回了true,find if()返回这个元素的迭代器。\nfind_if(cbegin(myVector),endIt,Prec); 2.accumulate\n我们经常需要计算容器中所有元素的总和或其他算术值。acumulate函数就提供了这种功能，该函数在(而非)中定义。通过这个函数的最基本形式可计算指定范围内元素的总和。\n// 总和 int sum = accumulate(cbegin(nums)， cend(nums)， 0); // 给accumulate提供的二元回调。也可以是lambda int product(int num1，int num2) { return numl *num2; } // 计算乘积 double mult = accumulate(cbegin(nums)， cend(nums)，1，product); std:function std:function 在头文件中定义，可用来创建指向函数、函数对象或lambda 表达式的类型; 从根本上说可以指向任何可调用的对象。它被称为多态函数包装器，可以当成函数指针使用，还可用作实现回调的函数的参数。\n模板定义：\nstd::function\u0026lt;R(ArgTypes..)\u0026gt; R 是函数返回值的类型，ArgTypes 是一个以逗号分隔的函数参数类型的列表。\nstd:function 真正有用的场合是将回调作为类的成员变量。在接收函数指针作为自定义函数的参数时，也可以使用 std::function。\n// 实现一个函数指针f1指向func function\u0026lt;void(int，const string\u0026amp;)\u0026gt; fl = func; f1(1，\u0026#34;test\u0026#34;); 当然，上例可使用 auto 关键字，这样就不需要指定 f1 的具体类型了。下面的 f1 定义实现了同样的功能而且简短得多，但 f1 的编译器推断类型是函数指针(即 void(*f1)(int,const string\u0026amp;)而不是 std:function:\nauto f1 = func; std::function作为函数形参可以接收任意可调用对象。如果用普通函数指针作为函数参数，lambda表达式实参作为参数传递给该函数是不行的。\nvoid process(const vector\u0026lt;int\u0026gt;\u0026amp; vec，function\u0026lt;void(int)\u0026gt; f) { for (auto\u0026amp; i:vec) f f(i); } void print(int num) { cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } int main() { vector\u0026lt;int\u0026gt; vec{0,1,2,3,4,5,6,7,8,9 }; process(vec,print); cout \u0026lt;\u0026lt; endl; int sum=0; // 如果process第二个参数是普通函数指针,传递lambda是不行的 process(vec，[\u0026amp;sum](int num){sum += num;}); cout \u0026lt;\u0026lt;\u0026#34;sum = \u0026#34;\u0026lt;\u0026lt; sum \u0026lt;\u0026lt;endl; return 0; } lambda 使用 lambda 表达式可编写内嵌的匿名函数，而不必编写独立函数或函数对象，使代码更容易阅读和理解。\n语法：\n[捕获列表] (参数列表) mutable -\u0026gt; 返回值类型 { 函数体 }; (参数列表) ：如果没有可省略\n可以忽略返回类型。如果忽略了返回类型，编译器就根据函数返回类型推断规则来推断 lambda 表达式的返回类型\nlambda 表达式的方括号[]部分称为 lambda 捕捉块capture block)。捕捉变量的意思是可在 lambda 表达式体中使用这个变量。\n指定空白的捕捉块[]表示不从所在作用域内捕捉变量; 在捕捉块中只写出变量名将按值捕捉该变量; \u0026amp;变量名将按引用捕捉该变量\n编译器将 lambda 表达式转换为某种未命名的仿函数(即函数对象)。捕捉的变量变成这个仿函数的数据成员,将按值捕捉的变量复制到仿函数的数据成员中。这些数据成员与捕捉的变量具有相同的 const 性质。\n仿函数总是实现函数调用运算符 operator()。对于 lambda 表达式，这个函数调用运算符被默认标记为 const, 这表示即使在 lambda 表达式中按值捕捉了非 const 变量lambda 表达式也不能修改其副本。把 lambda 表达式指定为mutable，就可以把函数调用运算符标记为非const.\n注意如果指定了 mutable，就必须给参数指定圆括号，即使圆括号为空。\n在变量名前面加上\u0026amp;，就可按引用捕捉它。lambda 表达式可以直接在其内\n修改按引用捕获的变量。\n按引用捕捉变量时，必须确保执行 lambda 表达式时，该引用仍然是有效的。\n使用默认捕捉时，只有在 lambda 表达式体中真正使用的变量才会被捕捉，使用值(=)或引用(\u0026amp;)捕捉。未使用的变量不捕捉。 警告: 不建议使用默认捕捉，即使只捕捉在 lambda 表达式体中真正使用的变量，也同样如此。使用=默认捕捉可能在无意中引发昂贵的复制。使用\u0026amp;默认捕捉可能在无意间修改所在作用域内的变量。建议显式指定要捕捉的变量。\n泛型lambda表达式\n可以给 lambda 表达式的参数使用自动推断类型功能，而无须显式指定它们的具体类型。要为参数使用自动推断类型功能，只需要将类型指定为 auto，类型推断规则与模板参数推断规则相同。\nlambda 捕捉表达式 lambda 捕捉表达式允许用任何类型的表达式初始化捕捉变量。这可用于在 lambda 表达式中引入根本不在其内部的作用域内捕捉的变量，例：\nmyCapture使用lambda捕捉表达式初始化为字符串“Pi:”\ndouble pi=3.1415; auto myLambda= [myCapture =\u0026#34;pi:\u0026#34;，pil[ cout \u0026lt;\u0026lt; myCapture \u0026lt;\u0026lt; pi;); auto myPtr = std::make_unique\u0026lt;double\u0026gt;(3.1415); auto myLambda = [p = std::move(myPtr)]{ cout \u0026lt;\u0026lt;*p;}; // 捕捉变量允许使用与所在作用域(enclosing scope)内相同的名称。 automyLambda = [myPtr = std::move(myPtr)]{ cout \u0026lt;\u0026lt;*p;}; lambda可作为函数返回值，返回类型为function\n还可以作为函数参数，参数类型为function\n函数对象 在类中，可重载函数调用运算符()，使类的对象可取代函数指针。将这些对象称为函数对象(function objiect),或称为仿函数(functor)\n函数对象适配器 1.绑定器： 绑定器(binder)可用于将函数的参数绑定至特定的值。为此要使用头文件中定义的 std::bind，它允许采用灵活的方式绑定可调用的参数。既可将函数的参数绑定至固定值，甚至还能重新安排函数参数的顺序。\n假定有一个 func函数，它接收两个参数:\nvoid func(intnum，strinqviewstr) { cout \u0026lt;\u0026lt;\u0026#34;func(\u0026#34;\u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34;，\u0026#34;\u0026lt;\u0026lt; str \u0026lt;\u0026lt;\u0026#34;)\u0026#34; \u0026lt;\u0026lt;endl; } 通过 bind将 func函数的第二个参数绑定至固定值 myString。结果保存在 f1中。使用auto关键字是因为C++标准未指定 bind的返回类型，因而是特定于实现的。没有绑定至指定值的参数应该标记为 1、2和3等。这些都定义在 std::placeholders 名称空间中。在f1的定义中，func第一个参数应该出现在1这个位置。之后，就可以用一个整型参数调用 f1。\nstring myString =\u0026#34;abc\u0026#34;; auto f1 = bind(func，placeholders::_1，myString); f1(16); 输出: func(16，abc) bind还可用于重新排列参数的顺序, fun第二个参数应该出现在f2的_2这个的位置。也就是说f2第一个参数将成为函数 func的第二个参数，第二个参数将成为函数 func的第一个参数。 auto f2= bind(func，placeholders::2，placeholders::1); f2(\u0026ldquo;Test\u0026rdquo;，32); 输出: func(32，Test)\n修改序列算法 从一个范围向另一个范围复制元素、删除元素以及反转某个范围内元素的顺序。 警告: 修改算法不能将元素插入目标范围中，仅可重写/修改目标范围中已经存在的元素。使用迭代器适配器，在目标范围中真正插入元素 map和 multimap 的范围不能用作修改算法的目标范围。这些算法改写全部元素，而在 map 中，元素是键值对。map和 multimap将键标记为 const，因此不能为其赋值。set和 multiset 也是如此。替换方案是使用插入迭代器。\n1.转换 transform\ntransform算法对范围内的每个元素应用回调，期望回调生成一个新元素，并保存在指定的目标范围中。如果希望transform将范围内的每个元素替换为调用回调产生的结果，那么源范围和目标范围可以是同一范围。其参数是源序列的首尾迭代器、目标序列的首迭代器以及回调。\n// 将vector中的每个元素增加100 transform(begin(myVector)，end(myVector)， begin(myVector) [](int i)[ return i + 100;}); transform的另一种形式对范围内的元素对调用二元函数，需要将第一个范围的首尾迭代器、第二个范围的首迭代器以及目标范围的首迭代器作为参数。\n例: 创建两个 vector，然后通过transform计算元素对的和并将结果保存回第一个 vector. 这里 : vec2的大小应该 \u0026gt;= vec1, 因为是到end(vec1)结束。\ntransform(begin(vec1)，end(vec1)，begin(vec2)，begin(vec1), [](int a,int b){return a + b;]); 注意: transform和其他修改算法通常返回一个引用目标范围内最后一个值后面那个位置(past-the-end)的迭代器\n2.复制 copy算法可将一个范围内的元素复制到另一个范围，从这个范围内的第一个元素开始直到最后一个元素。源范围和目标范围必须不同，但在一定限制条件下可以重叠。限制条件如下:对于 copy(b,e,d)，如果 d 在b之前，则可以重叠; 但如果 d处于[b.e]范围，则行为不确定。与所有修改算法类似，copy不会向目标范围插入元素，只改写已有的元素。所以要保证目标范围要有足够空间。\n这个例子将 vec1 中的所有元素复制到 vec2:\nvector\u0026lt;int\u0026gt; vecl， vec2; populateContainer(vecl); vec2.resize(size(vec1)); // 以确保目标范围有足够空间 copy(cbegin(vec1)， cend(vec1)，begin(vec2)); copy_backward算法，这个算法将源范围内的元素反向复制到目标范围。换句话说，这个算法从源范围的最后一个元素开始，将这个元素放在目标范围的最后一个位置，然后在每一次复制之后反向移动。\n源范围和目标范围在一定限制条件下可以重叠。限制条件如下:对于copy_backward(b,e,d)，如果 d 在e之后，则能正确重叠；但如果 d 处于b,e]范围，则行为不确定。\n前面的例子可按如下代码修改为使用copy_backward而不是 copy。注意第三个参数应该指定end(vec2)而不是 begin(vec2):\ncopy_backward(cbegin(vec1)， cend(vec1)，end(vec2)); copy_if算法时，需要提供由两个迭代器指定的输入范围、由一个迭代器指定的输出范围以及一个谓词(函数或 lambda 表达式)。该算法将满足谓词的所有元素复制到目标范围。复制不会创建或扩大容器，只是替换现有元素。因此，目标范围应当足够大，从而保存要复制的所有元素。copy_if返回了目标范围内最后一个复制的元素后面那个位置(one-past-the-last-copied element)的选代器，以便确定需要从目标容器中删除的元素。例: 只把偶数复制到 vec2:\nvector\u0026lt;int\u0026gt; vec1， vec2; populateContainer(vec1); vec2.resize(size(vec1)); auto endIterator = copy if(cbegin(vec1)， cend(vec1)， begin(vec2)，[](int i){ return i%2 == 0;}); vec2.erase(endIterator， end(vec2)); copy_n从源范围复制n个元素到目标范围。copy_n的第一个参数是起始迭代器，第二个参数是指定要复制的元素个数，第三个参数是目标迭代器。该算法不执行任何边界检查，因此一定要确保起始选代器递增n个要复制的元素后，不会超过集合的 end()，否则程序会产生未定义的行为。\ncnt = min(cnt, size(vec1)) vec2.resize(cnt); copy_n(cbegin(vec1)， cnt，begin(vec2)); 3.移动 move,基于移动语义。如果要在自定义类型元素的容器中使用这两个算法，那么需要在元素类中提供移动赋值运算符operator=(Class\u0026amp;\u0026amp; rhs).\nclass MyClass { public: MyClass() = default; MyClass(const MyClass\u0026amp; src) = default; MyClass(string_view str) :mStr(str) {} virtual ~MyClass() = default; // Move assignment operator MyClass\u0026amp; operator=(MyClass\u0026amp;\u0026amp; rhs) noexcept { if (this== \u0026amp;rhs) return *this; mStr = std;:move(rhs.mStr); cout \u0026lt;\u0026lt;\u0026#34;Move operator= (mStr=\u0026#34; \u0026lt;\u0026lt; mStr \u0026lt;\u0026lt;\u0026#34;)\u0026#34; \u0026lt;\u0026lt; endl; return *this; } void setStrinq(string view str) [ mStr =str; ] string view getString() const (return mStr;l private: string mStr; }; int main(){ vector\u0026lt;MyClass\u0026gt; vecSrc{ MyClass(\u0026#34;a\u0026#34;)，MyClass(\u0026#34;b\u0026#34;)，MyClass(\u0026#34;c\u0026#34;)}; vector\u0026lt;MyClass\u0026gt; vecDst(vecSrc.size()); move(begin(vecSrc)，end(vecSrc)，beqin(vecDst)); for (const auto\u0026amp; c : vecDst){ cout \u0026lt;\u0026lt; c.getString() \u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 输出如下所示: Move operator=(mStr=a) Move operator=(mStr=b) Move operator=(mStr=c) a b c 注意这段代码包含两种不同的 move用法。一种是，move函数接收一个参数，将 lvalue 转换为rvalue，在中定义:而另一种是，接收3个参数的 move是标准库的 move算法，这个算法在容器之间移动元素。\n注意：在移动操作中，源对象将处于有效但不确定的状态。在这个例子中，这意味着在执行动操作后，不应该再使用 vecSrc 中的元素了，除非使它们重回确定状态，例如，在它们之上调用方法(不包任何预置条件)，如setString()。\nmove_backward使用和move同样的移动机制,但按从最后一个元素向第一个元素的顺序移动。对于move和 move_backward，在符合某些限制条件的情况下允许源范围和目标范围重叠。限制条件与 copy和copy_backward的相同。\n4.替换 replace和 replace_if算法将一个范围内匹配某个值或满足某个谓词的元素替换为新的值。replace_if算法的第一个和第二个参数指定了容器中元素的范围。第三个参数是一个返回 true 或 false 的函数或lambda表达式，如果它返回 true，那么容器中的对应值被替换为第四个参数指定的值:如果它返回 false，则保留原始值。\nreplace_if(begin(vec)，end(vec)，[](int i)[ return i%2 != 0;}，0); 5.删除 假设要将某个范围内满足某特定条件的元素删除。第一个解决方案是查看文档，确定容器是否有erase方法，然后选代所有元素，并对每个满足条件的元素调用 erase。vector 是包含 erase方法的容器之一。然而，如果对 vector 容器应用erase，这个方法的效率非常低下，因为要保持 vector 在内存中的连续性，会涉及很多内存操作，时间复杂度 O(n*2)。这个方法还容易产生错误，因为必须非常小心地确保每次调用 erase之后选代器依然有效。例如，如下函数从 string vector 中删除空字符串，未使用算法。\nvoid removeEmptyStringsWithoutAlgorithms(vector\u0026lt;string\u0026gt;\u0026amp; strings) { for (autoiter=beqin(strings); iter != end(strings);) if (iter-\u0026gt;empty()) iter = strings.erase(iter); else ++iter; } 这个问题的方法是“删除-擦除法”(remove-erase-idiom),只需要线性时间。算法只能访问迭代器抽象，不能访问容器。因此删除算法不能真正地从底层容器中删除元素，而是将匹配给定值或谓词的元素替换为下一个不匹配给定值或谓词的元素。为此使用移动赋值。结果是将范围分为两个集合:一个用于保存要保留的元素，另一个用于保存要删除的元素。返回的迭代器指向要删除的元素范围内的第一个元素。如果真的需要从容器中删除这些元素，必须先使用 remove算法，然后调用容器的 erase方法，将从返回的迭代器开始到范围尾部的所有元素删除。这就是删除-擦除法。\nvoid removeEmptyStrings(vector\u0026lt;string\u0026gt;\u0026amp; strings){ auto it = remove_if(begin(strings)，end(strings) [](const string\u0026amp; str){ return str.empty(); }) // Erase the removed elements. strings.erase(it, end(strings)); // [it, end) } 注意：remove函数系列是稳定的，因为这些函数保持了容器中剩余元素的顺序，尽管这些算法将保留的元素向前移动了。\n6.唯一化 unique算法是特殊的remove，remove能将所有重复的连续元素删除。list 容器提供了自己的具有同样语义的unique方法。通常情况下应该对有序序列使用unique，但unique也能用于无序序列。unique的基本形式是就地操作数据，还有一个名为 unique_copy的版本这个版本将结果复制到一个新的目标范围。\n7.抽样 sample算法从给定的源范围返回n个随机选择的元素，并存储在目标范围。它需要 5个参数: 要从中抽样的范围的首尾迭代器 目标范围的首迭代器，将随机选择的元素存储在目标范围 要选择的元素数量 随机数生成引擎\nvector\u0026lt;int\u0026gt;vec{ 1,2,3,4,5,6,7,8,9,10 }; const size_t numberOfSamples = 5; vector\u0026lt;int\u0026gt; samples(numberOfSamples); random_device seeder; const auto seed = seeder.entropy() ? seeder() : time(nullptr); default_random_engine engine( static_cast\u0026lt;default_random_engine::result_type\u0026gt;(seed)); for (int i=0; i\u0026lt;6; ++i) { sample(cbegin(vec)，cend(vec)，begin(samples)，numberOfSamples，engine); for (const autok sample : samples) { cout \u0026lt;\u0026lt; sample \u0026lt;\u0026lt;\u0026#34;\u0026#34;; cout \u0026lt;\u0026lt; endl;} } 8.反转 reverse算法反转某个范围内元素的顺序。将范围内的第一个元素和最后一个元素交换，将第二个元素和倒数第二个元素交换，依此类推。 reverse最基本的形式是就地运行，要求两个参数: 范围的首尾迭代器。还有一个名为 reverse_copy的版本，这个版本将结果复制到新的目标范围，它需要3 个参数:源范围的首尾迭代器以及目标范围的起始迭代器,目标范围必须足够大，以便保存新元素。 9.乱序 shuffle以随机顺序重新安排某个范围内的元素，其复杂度为线性时间。它可用于实现洗牌等任务。参数是要乱序的范围的首尾迭代器，以及一个统一的随机数生成器对象，它指定如何生成随机数。\n操作算法 此类算法只有两个: for each和 for_each_n，后者是在 c++17 中引入的。它们对范围内的每个元素执行回调，或对范围内的前n个元素执行回调。可利用这两个算法结合简单的函数回调或lambda 表达式执行一些任务，例如打印容器中的每个元素。但使用基于区间的 for 循环通常比使用这两个算法更简单、更容易理解。\n1. for_each() map\u0026lt;int，int\u0026gt; myMap={ {4，401}，{5，50}，{6，60} }; for_each(cbegin(myMap)， cend(myMap)， [](const auto\u0026amp; p) {cout \u0026lt;\u0026lt; p.first \u0026lt;\u0026lt;“-\u0026gt;\u0026#34; \u0026lt;\u0026lt; p.second \u0026lt;\u0026lt; endl; }); p的类型是 const pair\u0026lt;int,int\u0026gt;\u0026amp;。\n利用lambda计算和与积：\nvector\u0026lt;int\u0026gt; myVector {.....}; int sum=0; int product =1; for each(cbegin(myVector)， cend(myVector), [\u0026amp;sum, \u0026amp;product](int i) { sum += i; product *= i; }); 关于 for_each和 for_each_n，使用 lambda 或回调时，允许通过引用获得参数并对其进行修改, 这样可以修改实际迭代器范围内的值\n2.for_each_n 算法需要范围的起始选代器、要选代的元素数量以及函数回调。它返回的选代器等于 begin+n。它通常不执行任何边界检查。下例只迭代 map 的前两个元素:\nfor_each_n(cbegin(myMap)， 2， [](const autos p) { cout \u0026lt;\u0026lt; p.first \u0026lt;\u0026lt; “-\u0026gt;\u0026#34; \u0026lt;\u0026lt; p.second \u0026lt;\u0026lt; endl; }); 交换算法 1.std::swap(a,b), 有效的交换两个值，并使用移动语义(如果可用的话)\n2.std::exchange, 定义在头文件中，用新值替换旧值，并返回旧值。\nexchange用于实现移动赋值运算符。移动赋值运算符需要将数据从源对象移到目标对象。通常，源对象中的数据会变为 null。\nFoo\u0026amp; operator=(Foo\u0026amp;\u0026amp; rhs) noexcept { // Check for self-assignment if (this== \u0026amp;rhs) [ return *this; } // Free the old memory deletemPtr;mPtr =nullptr; // Move data // Move data from source to destination mPtr = rhs.mPtr; rhs.mPtr = nullptr;// Nullify datain source return *this; } //对于方法底部的mPtr和rhs.mPtr的赋值，可使用exchange0实现，如下所示: Foo\u0026amp; operator=(Foo\u0026amp;\u0026amp; rhs) noexcept { // Check for self-assignment if (this ==\u0026amp;rhs) ( return *this; } // Free theold memory deletemPtr;mPtr=nullptr; // Move data mPtr = exchange(rhs.mPtr,nullptr); // Move + nullify return *this; } 分区算法 partition_copy算法将来自某个来源的元素复制到两个不同的目标范围。为每个元素选择特定目标的依据是谓词的结果: true或 false, true放第一个。partition_copy的返回值是一对迭代器: 一个迭代器引用第一个目标范围内最后复制 的那个元素的后一个位置(one-past-the-last-copied element)，另一个选代器引用第二个目标范围内最后复制的那个元素的后一个位置。将这些返回的迭代器与 erase结合使用，可删除两个目标范围内多余的元素。下例要求用户输入一些整数，然后将这些整数分区到两个目标 vector 中，一个保存偶数，另一个保存奇数。\nvector\u0026lt;int\u0026gt; vec1， vecOdd,vecEven; populateContainer(vec1); vecOdd.resize(size(vec1)); // 保证有足够空间 vecEven.resize(size(vec1)); auto pairIters = partition_copy(cbegin(vec1)， cend(vec1) begin(vecEven)， begin(vecodd) [](int i)[ return i % 2 ==0;}); vecEven.erase(pairIters.first，end(vecEven)); //删除两个目标范围内多余的元素 vecOdd.erase(pairIters.second,end(vecOdd)); partition0算法对序列排序，使谓词返回 true 的所有元素放在前面，使谓词返回 false 的所有元素放在后面 在每个分区中不保留元素最初的顺序。下例演示了如何把 vector 分为偶数在前、奇数在后的分区:\nvector\u0026lt;int\u0026gt; vec; populateContainer(vec); partition(begin(vec)，end(vec)，[](int i){ return i%2==0;}); 排序算法 标准库提供了一些不同的排序算法。“排序算法”重新排列容器中元素的顺序，使集合中的元素保持连续顺序。因此，排序算法只能应用于顺序集合。排序和有序关联容器无关，因为有序关联容器已经维护了元素的顺 **序。排序也和无序关联容器无关，因为无序关联容器就没有排序的概念。**一些容器(例如 list和 forward list)提供了自己的排序方法，因为这些方法内部实现的效率比通用排序机制的效率要高。\n因此，通用的排序算法最适用于vector、deque、array和C风格数组。sort函数一般情况下在0(NlogN)时间内对某个范围内的元素排序。将sort应用于一个范围之后，根据运算符 operator\u0026lt;，这个范围内的元素以非递减顺序排列(最低到最高)。如果不希望使用这个顺序，可以指定一个不同的比较回调，例如greater。 sort函数的一个名为 stable_sort的变体能保持范围内相等元素的相对顺序。然而，由于这个算法需要维护范围内相等元素的相对顺序，因此这个算法比 sort算法低效。\nsort(begin(vec)， end(vec)， greater\u0026lt;\u0026gt;()); // 非递增 还有 is_sorted和 s_sorted_until: 如果给定的范围是有序的is sorted就返回 true，而s_sorted_until返回给定范围内的一个迭代器，该迭代器之前的所有元素都是有序的。\n二叉树搜索算法 有几个搜索算法只用于有序序列或至少已分区的元素序列。这些算法有 binary_search、lower_bound，upper_bound和 equal_range。\nlower bound、upper bound和 equal range算法类似于 map 和 set 容器中的对应方法。。 lower bound算法在有序范围内查找不小于(即大于或等于)给定值的第一个元素，经常用于在有序的vector 中应将新值插入哪个位置，使 vector 依然有序。\nvec.insert(iter, num); auto iter = lower bound(begin(vec)，end(vec)，num); binary search算法以对数时间而不是线性时间搜索元素，需要指定范围的首尾迭代器、要搜索的值以及可选的比较回调。如果在指定范围内找到这个值，这个算法返回 true，否则返回 false。\n集合算法 集合算法可用于任意有序范围。includes算法实现了标准的子集判断功能，检查某个有序范围内的所有元素是否包含在另一个有序范围内，顺序任意。includes(a,b)检查b是否是a的子集\nset_union ：并集得到的结果是两个集合中的所有元素\nset_intersection ：交集得到的结果是所有同时存在于两个集合中的元素\nset_difference：差集得到的结果是所有存在于第一个集合中，但是不存在于第二个集合中的元素\nset_symmetric_difference：对称差集得到的结果是两个集合的“异或”:所有存在于其中一个集合中，但不同时存在于两个集合中的元素\n这四个的参数都是集合1的首尾迭代器，集合2的首尾迭代器，目标范围的起始迭代器\n注意：\n1.务必确保结果范围足够大，以保存操作的结果。\n对于set_union和set _symmetric_difference，结果大小的上限是两个输入范围的总和。\n对于 set_intersection，结果大小的上限是两个输入范围的最小大小。\n对于set_difference，结果大小的上限是第一个输入范围的大小\n2.不能使用关联容器(包括 set)中的迭代器范围来保存结果，因为这些容器不允许修改键。\nmerge算法可将两个排好序的范围归并在一起，并保持排好的顺序。结果是一个包含两个源范围内所有元素的有序范围。这个算法的复杂度为线性时间O(M+N)。这个算法需要以下参数:\n第一个源范围的首尾迭代器 第二个源范围的首尾迭代器 目标范围的起始迭代器 (可选)比较回调 如果没有 merge，还可通过串联两个范围，然后对串联的结果应用sort，以达到同样的目的，但这样做的效率更低，复杂度为 O(Nlog N)而不是merge的线性复杂度。\n注意:一定要确保提供足够大的目标范围，以保存归并的结果。\n最大最小算法 min和 max算法通过运算符operator\u0026lt;或用户提供的二元谓词比较两个或多个任意类型的元素，分别返回个引用较小或较大元素的const引用。minmax算法返回一个包含两个或多个元素中最小值和最大值的 pair。 这些算法不接收迭代器参数。还有使用迭代器范围的 min_element、max element和 minmax_element。\nmax(x, y); max({x1, x2, x3, x4}); auto [min1, max1] = minmax({x1, x2, x3, x4}); min_element(vec.begin(), vec.end()); std::clamp是一个小型辅助函数，在中定义，clamp（lo，v, hi）可用于确保值(v)在给定的最小值(lo)和最大值(hi)之间。如果v\u0026lt;10, 它返回对10的引用, 如果v\u0026gt;hi，它返回对h的引用:否则返回对V的引用。\n并行算法 支持并行执行的算法包含选项，接收所谓的执行策略作为第一个参数。执行策略允许指定是否允许算法以并行方式或矢量方式执行。有三类标准执行策略，以及这些类型的三个全局实例，它们全部定义在std:execution 名称空间的头文件中\n例子:\nsort(std::execution::par，begin(myVector)，end(myVector)); 数值处理算法 1.inner_product 中定义的inner_product算法计算两个序列的内积，例如，下面程序中的内积计算为 (1x9)+(2x8)+(3x7)+(4x6):\nvector\u0026lt;int\u0026gt;v1 {1, 2, 3, 4}; vector\u0026lt;int\u0026gt;v2 {9, 8, 7, 6}; cout \u0026lt;\u0026lt;inner_product(cbegin(v1)，cend(v1)，cbegin(v2)，0) \u0026lt;\u0026lt; endl; 输出为70。\n2. iota() 头文件中定义的iota算法会生成指定范围内的序列值，从给定的值开始，并应用operator++来生成每个后续值。下面的例子展示了如何将这个新算法用于整数的 vector，不过要注意这个算法可用于任意实现了operator++的元素类型。\nvector\u0026lt;int\u0026gt; vec(10); iota(begin(vec)，end(vec)，5); for (auto\u0026amp; i : vec) cout\u0026lt;\u0026lt;i \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 输出如下所示: 5 6 7 8 9 10 11 12 13 14 3. gcd 和 lcm gcd算法返回两个整数的最大公约数，而 lcm算法返回两个整数的最小公倍数。\n","permalink":"https://dueplay.github.io/posts/stl%E7%AE%97%E6%B3%95/","summary":"stl算法\n算法把迭代器作为中介从而间接操作容器中的元素，而不直接操作容器本身。所有标准库算法都实现为函数模板的形式，其中模板类型参数一般都是迭代器类型。模板化的函数通常可通过函数参数推导出模板类型，因此通常情况下可以像调用普通函 数(而非模板)那样调用算法。\n简单例子 1.find和find_if\nfind()在某个迭代器范围内查找特定元素。可将其用于任意容器类型。这个算法返回所找到元素的迭代器: 如果没有找到元素，则返回迭代器范围的尾迭代器。注意调用 find()时指定的范围不要求是容器中元素的完整范围，还可以是元素的子集。 注意： 如果 fnd()没有找到元素，那么返回的迭代器等于函数调用中指定的尾迭代器，而不是底层容器的尾迭代器\nauto endIt =cend(myVector); auto it = find(cbegin(myVector),endIt,num); // it == endIt -\u0026gt; not find // c++17 if (auto it = find(cbegin(myVector),endIt,num); it == endIt) { // not find } 一些容器(例如 map和 set)以类方法的方式提供自己的 find()函数。如果容器提供的方法具有与泛型算法同样的功能，那么应该使用容器相应的方法，那样速度更快。比如，泛型算法 find()的复杂度为线性时间，用于 map 迭代器时也是如此; 而 map 中find()方法的复杂度是对数时间。\nfind_if\nfind_if()和 find()类似，区别在于 find _f()接收谓词函数回调作为参数，而不是简单的匹配元素。谓词返回true或false。find_if()算法对范围内的每个元素调用谓词，直到谓词返回ture: 如果返回了true,find if()返回这个元素的迭代器。\nfind_if(cbegin(myVector),endIt,Prec); 2.accumulate\n我们经常需要计算容器中所有元素的总和或其他算术值。acumulate函数就提供了这种功能，该函数在(而非)中定义。通过这个函数的最基本形式可计算指定范围内元素的总和。\n// 总和 int sum = accumulate(cbegin(nums)， cend(nums)， 0); // 给accumulate提供的二元回调。也可以是lambda int product(int num1，int num2) { return numl *num2; } // 计算乘积 double mult = accumulate(cbegin(nums)， cend(nums)，1，product); std:function std:function 在头文件中定义，可用来创建指向函数、函数对象或lambda 表达式的类型; 从根本上说可以指向任何可调用的对象。它被称为多态函数包装器，可以当成函数指针使用，还可用作实现回调的函数的参数。","title":"stl中的算法介绍"},{"content":"unique_ptr 考虑下面的函数，这个函数在堆上分配了一个 Simple 对象，但是不释放这个对象，故意产生内存泄漏。\nvoid leaky() { Simple* mySimplePtr = new Simple(); // BUG! Memory is never released! mySimplePtr-\u0026gt;go(); } 有时你可能认为，代码正确地释放了动态分配的内存。遗憾的是，这种想法几乎总是不正确的。比如这个函数:\nvoid couldBeLeaky() { Simple*mySimplePtr =new Simple(); mySimplePtr-\u0026gt;go(); delete mySimplePtr; } 上面的函数动态分配一个 Simple 对象，使用该对象，然后正确地调用 delete。但是，这个例子仍然可能产生内存泄漏! 如果 go方法抛出一个异常，将永远不会调用 delete，导致内存泄漏。\n这两种情况下应使用 unique_ptr。对象不会显式删除，但实例 unique_ptr离开作用域时(在函数的末尾，或者因为抛出了异常)，就会在其析构函数中自动释放 Simple 对象:\nvoid notLeaky() { auto mySimpleSmartPtr =make unique\u0026lt;Simple\u0026gt;(); mySimpleSmartPtr-\u0026gt;go(); } 这段代码使用 C++14 中的 make_unique和 auto 关键字，所以只需要指定指针的类型，本例中是 Simple,如果Simple构造函数需要参数，就把它们放在make_unique()调用的圆括号中。\n如果编译器不支持make_unique, 可以这种方式创建。\nunique_ptr\u0026lt;Simple\u0026gt; p(new Simple()); 像标准指针一样，仍可以使用*或-\u0026gt;对智能指针进行解引用。\nget()方法可用于直接访问底层指针。这可将指针传递给需要普通指针的函数。例如\nvoid processData(Simple* simple)( /* Use the simple pointer...*/ // 可采用如下方式进行调用: auto mySimpleSmartPtr = make_unique\u0026lt;Simple\u0026gt;(); processData(mySimpleSmartPtr.get()); 可释放unique_ptr 的底层指针，并使用reset()根据需要将其改成另一个指针。\nmySimpleSmartPtr.reset(); // Free resource and set to nullptr mySimpleSmartPtr.reset(new Simple()); // Free resource and set to a new Simple instance 可使用 release()断开 unique_ptr 与底层指针的连接。release方法返回资源的底层指针，然后将智能指针设 为 nullptr。实际上，智能指针失去对资源的所有权，负责在你用完资源时释放资源。\nSimple* simple= mySimpleSmartPtr.release();// Release ownership //Use the simple pointer... delete simple; simple = nullptr; 由于 unique_ptr代表唯一拥有权，因此无法复制它!使用 std::move() 移动语义将一个unique_ptr 移到另一个。这用于显式移动所有权。\nclass Foo { public: Foo(unique ptr\u0026lt;int\u0026gt; data) : mData(move(data)) {} private: unique_ptr\u0026lt;int\u0026gt;mData; }; auto myIntSmartPtr = make unique\u0026lt;int\u0026gt;(42); Foo f(move(myIntSmartPtr)); unique_ptr 适用于存储动态分配的旧式C 风格数组。下例创建了一个 unique_ptr 来保存动态分配的、包含10个整数的C风格数组:\nauto myVariableSizedArray = make_unique\u0026lt;int[]\u0026gt;(10); 自定义 deleter 默认情况下，unique_ptr 使用标准的new 和delete运算符来分配和释放内存。可将此行为改成:\nint* malloc_int(int value) { int*p= (int*)malloc(sizeof(int)); *p=value; return p; } int main() { unique ptr\u0026lt;int，decltype(free)*\u0026gt; myIntSmartPtr(malloc_int(42)，free); return 0; } 这段代码使用 malloc_int()给整数分配内存。unique_ptr 调用标准的 free函数来释放内存。如前所述, 在C++中不应该使用 malloc，而应改用 new。然而，unique_ptr 的这项特性是很有用的，因为还可管理其他类型的资源而不仅是内存。例如，当 unique_ptr 离开作用域时，可自动关闭文件或网络套接字以及其他任何资源。 但是，unique_ptr 的自定义 deleter 的语法有些费解。需要将自定义 deleter 的类型指定为模板类型参数. decltype(free)用于返回 free()类型。模板类型参数应当是函数指针的类型，因此另外附加一个*，如decltype(free)*\nshared_ptr shared_ptr 的用法与 unique_ptr 类似。要创建 shared_ptr，可使用 make_shared()，它比直接创建 shared_ptr更高效。\n更高效原因：\n当使用 std::make_shared 创建 shared_ptr 时，所有需要的内存（包括对象本身和控制块）在一次分配中完成。这减少了内存分配的次数，从而提高了效率。\n而直接使用 std::shared_ptr 构造函数创建对象通常需要两次内存分配，一次用于对象本身，一次用于控制块。\n在直接使用 new 的情况下，在对象构造和控制块分配之间，如果对象构造抛出异常，可能会导致内存泄漏。而 std::make_shared 在分配和构造对象的过程中是异常安全的。\nauto mySimpleSmartPtr = make_shared\u0026lt;Simple\u0026gt;(); std::shared_ptr\u0026lt;Simple\u0026gt; ptr(new Simple()); 与unique_ptr 一样，shared_ptr 也支持 get和reset方法。唯一的区别在于，当调用 reset时，由于引用计数，仅在最后的 shared_ptr销毁或重置时,才释放底层资源。注意,shared ptr 不支持 release。可使用use count()来检索共享同一资源的shared_ptr 实例数量。\n与 unique_ptr 类似，shared_ptr 默认情况下使用标准的 new 和 delete 运算符来分配和释放内存;在 C++17 中存储C风格数组时，使用 new[]和 delete[]。可更改此行为\nshared_ptr\u0026lt;int\u0026gt; myIntSmartPtr(malloc_int(42)， free); 可以看到，不必将自定义 deleter 的类型指定为模板类型参数，这比 unique_ptr 的自定义 deleter 更简便。\n下面的示例使用 shared_ptr 存储文件指针。当 shared_ptr 离开作用域时(此处为脱离作用域时)，会调用 CloseFile函数来自动关闭文件指针。回顾一下，C++中有可以操作文件的面向对象的类。这些类在离开作用域时会自动关闭文件。\nvoid CloseFile(FILE* filePtr) { if (filePtr==nullptr) return; fclose(filePtr); cout \u0026lt;\u0026lt;\u0026#34;File closed.\u0026#34; \u0026lt;\u0026lt; endl; } int main() { FILE* f = fopen(\u0026#34;data.txt\u0026#34;, uw\u0026#34;); // 自定义deleter shared ptr\u0026lt;FILE\u0026gt; filePtr(f, CloseFile); if (filePtr== nullptr) { cerr \u0026lt;\u0026lt; \u0026#34;Error opening file.\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt;\u0026#34;File opened.\u0026#34; \u0026lt;\u0026lt; endl; } //Use filePtr return 0; } 双重删除的问题 如果要创建两个标准的 shared_ptr，并使它们都指向同一个 Simple 对象，如下面的代码所示，在销毁时，两个智能指针将尝试删除同一个对象:\nvoid doubleDelete() { Simple*mySimple=new Simple(); shared ptr\u0026lt;Simple\u0026gt; smartPtrl(mySimple); shared ptr\u0026lt;Simple\u0026gt; smartPtr2(mySimple); } 根据编译器，这段代码可能会崩溃!如果得到了输出，则输出为: Simple constructor called! Simple destructor called! Simple destructor called 只调用一次构造函数，却调用两次析构函数?使用 unique ptr 也会出现同样的问题。然而，根据 C+标准，这是正确的行为。不应该像以上 doubleDelete函数那样创建两个指向同一个对象的 shared_ptr，而是应该建立副本，如下所示:\nvoid noDoubleDelete() { auto smartPtr1 = make_shared\u0026lt;Simple\u0026gt;(); shared ptr\u0026lt;Simple\u0026gt; smartPtr2(smartPtrl); } 这段代码的输出如下所示: Simple constructor called! Simple destructor called! 即使有两个指向同一个Simple对象的shared_ptr，Simple对象也只销毁一次。\nweak_ptr weak_ptr 可包含由 shared_ptr 管理的资源的引用。weak_ptr 不拥有这个资源，所以不能阻止 shared_ptr 释放资源。weak_ptr 销毁时(例如离开作用域时)不会销毁它指向的资源: 然而，它可用于判断资源是否已经被关联的 shared_ptr 释放了。\nweak_ptr 的构造函数要求将一个 shared_ptr 或另一个 weak_ptr 作为参数。\n为了访问 weak_ptr 中保存的指针，需要将 weak_ptr 转换为shared_ptr。有两种方法: 使用 weak_ptr 实例的 lock方法，这个方法返回一个 shared_ptr。如果同时释放了与 weak_ptr 关联的shared_ptr，返回的shared_ptr 是nullptr 创建一个新的 shared_ptr 实例，将 weak_ptr 作为 shared_ptr 造函数的参数。如果释放了与 weak_ptr关联的shared_ptr，将抛出std::bad weak_ptr 异常。\nvoid useResource(weak ptr\u0026lt;Simple\u0026gt;\u0026amp; weakSimple) { auto resource = weakSimple.lock(); if (resource) { cout \u0026lt;\u0026lt;\u0026#34;Resource still alive.\u0026#34; \u0026lt;\u0026lt; endl; }else cout \u0026lt;\u0026lt;\u0026#34;Resource has been freed!\u0026#34; \u0026lt;\u0026lt; endl; } int main() { auto sharedSimple = make_shared\u0026lt;Simple\u0026gt;(); weak_ptr\u0026lt;Simple\u0026gt; weakSimple(sharedSimple); // Try to use the weak ptr. useResource(weakSimple); // Reset the shared ptr. // Since there is only 1 shared ptr to the Simple resource, this will free the resource, even though there is still a weak ptr alive. sharedSimple.reset(); // Try touse the weak ptr a second time. useResource(weakSimple); return 0; } 上述代码的输出如下: Simple constructor called! Resource still alive. Simple destructor called! Resource has been freed!\nmove 1.右值引用 左值(value)是可获取其地址的一个量，例如一个有名称的变量。由于经常出现在赋值语句的左边，因此将其称作左值。另外，所有不是左值的量都是右值(rvalue)，例如字面量、临时对象或临时值。通常右值位于赋值运算符的右边。 int a=4 * 2; 在这条语句中，a 是左值，它具有名称，它的地址为\u0026amp;a。右侧表达式4*2 的结果是右值。它是一个临时值,将在语句执行完毕时销毁。 右值引用是一个对右值(rvalue)的引用。特别地，这是一个当右值是临时对象时才适用的概念。右值引用允许开发者捕获将要销毁的临时对象，并对其资源进行重新利用。\n右值引用的目的是在涉及临时对象时提供可选用的特定函数。由于知道临时对象会被销毁，通过右值引用，某些涉及复制大量值的操作可通过简单地复制指向这些值的指针来实现。\n函数可将\u0026amp;\u0026amp;作为参数说明的一部分(例如 type\u0026amp;\u0026amp;name),以指定右值引用参数。通常,临时对象被当作 const type\u0026amp;，但当函数重载使用了右值引用时，可以解析临时对象，用于该函数重载。\nstd::string str1 = \u0026#34;Hello\u0026#34;; std::string str2 = std::move(str1); // str1 的内容被移动到 str2，而不是复制 std::move 将 str1 转换为右值引用，从而触发移动构造函数，将 str1 的内部数据直接转移给 str2，避免了深度复制。\n假设有一个类 LargeData，它包含大量的数据：\nclass LargeData { public: LargeData() { data = new int[1000000]; // 大量数据 } ~LargeData() { delete[] data; } LargeData(const LargeData\u0026amp; other) { // 拷贝构造函数 data = new int[1000000]; std::copy(other.data, other.data + 1000000, data); } LargeData(LargeData\u0026amp;\u0026amp; other) noexcept { // 移动构造函数 data = other.data; other.data = nullptr; // 将源对象的指针置空 } private: int* data; }; 在这里，移动构造函数通过简单地复制指针 data，而不是复制整个数据数组，实现了高效的资源转移。\nLargeData createLargeData() { return LargeData(); } int main() { LargeData ld = createLargeData(); // 移动构造，不是拷贝 return 0; } 在这个例子中，createLargeData 返回一个临时的 LargeData 对象，通过右值引用和移动语义，临时对象的资源被高效地移动到 ld，避免了大量数据的复制操作。\nstd::move可将左值转换为右值，强迫编译器调用 handleMessage函数的右值引用版本\nhandleMessage(std::move(b)); // Calls handleMessage(string\u0026amp;\u0026amp; value) 因为有名称的变量是左值。因此，在 handleMessage函数中，右值引用参数 message 本身是一个左值，原因是它具有名称! 如果希望将这个左值引用参数，作为右值传递给另一个函数，则需要使用 std:move将左值转换为右值。例如，假设要添加以下函数，使用右值引用参数:\nvoid helper(std::string\u0026amp;\u0026amp; message) 如果按如下方式调用，则无法编译:\nvoid handleMessage(std::string\u0026amp;\u0026amp; message) { helper(message); } helper函数需要右值引用，而 handleMessage函数传递 message，message 具有名称，是左值，导致编译错误。正确的方式是使用std::move():\nvoid handleMessaqe(std::string\u0026amp;\u0026amp; message) { helper(std::move(message)) ; } std::move 的返回的是一个右值引用。\nstd::move 并不真的“移动”对象，而是将一个左值转换为右值引用，允许调用移动构造函数或移动赋值运算符。\nMyClass b(std::move(a)); std::move(a) 将 a 转换为右值引用，触发 MyClass 的移动构造函数。\n错误：\nMyClass a(\u0026#34;Hello\u0026#34;); MyClass\u0026amp;\u0026amp; r = std::move(a); // 右值引用赋给右值引用变量 r，但 r 作为变量名，是一个左值。 MyClass b(r); // 错误：调用的是复制构造函数，而不是移动构造函数 虽然 r 是一个右值引用，但是 r 作为一个具名变量是一个左值，因此 MyClass b(r); 调用了复制构造函数，而不是移动构造函数。\n","permalink":"https://dueplay.github.io/posts/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","summary":"unique_ptr 考虑下面的函数，这个函数在堆上分配了一个 Simple 对象，但是不释放这个对象，故意产生内存泄漏。\nvoid leaky() { Simple* mySimplePtr = new Simple(); // BUG! Memory is never released! mySimplePtr-\u0026gt;go(); } 有时你可能认为，代码正确地释放了动态分配的内存。遗憾的是，这种想法几乎总是不正确的。比如这个函数:\nvoid couldBeLeaky() { Simple*mySimplePtr =new Simple(); mySimplePtr-\u0026gt;go(); delete mySimplePtr; } 上面的函数动态分配一个 Simple 对象，使用该对象，然后正确地调用 delete。但是，这个例子仍然可能产生内存泄漏! 如果 go方法抛出一个异常，将永远不会调用 delete，导致内存泄漏。\n这两种情况下应使用 unique_ptr。对象不会显式删除，但实例 unique_ptr离开作用域时(在函数的末尾，或者因为抛出了异常)，就会在其析构函数中自动释放 Simple 对象:\nvoid notLeaky() { auto mySimpleSmartPtr =make unique\u0026lt;Simple\u0026gt;(); mySimpleSmartPtr-\u0026gt;go(); } 这段代码使用 C++14 中的 make_unique和 auto 关键字，所以只需要指定指针的类型，本例中是 Simple,如果Simple构造函数需要参数，就把它们放在make_unique()调用的圆括号中。\n如果编译器不支持make_unique, 可以这种方式创建。\nunique_ptr\u0026lt;Simple\u0026gt; p(new Simple()); 像标准指针一样，仍可以使用*或-\u0026gt;对智能指针进行解引用。\nget()方法可用于直接访问底层指针。这可将指针传递给需要普通指针的函数。例如\nvoid processData(Simple* simple)( /* Use the simple pointer.","title":"智能指针"},{"content":"catch2用法 定义测试案例 测试案例在 Catch2 中通过 TEST_CASE 宏定义。TEST_CASE 宏接受两个参数：测试案例的名称和一个可选的标签。\n#define CATCH_CONFIG_MAIN // 这行让 Catch 自己提供一个 main() 函数 #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;A test case\u0026#34;, \u0026#34;[tag]\u0026#34;) { REQUIRE(1 == 1); } 如果你有多个测试文件，只需要在一个文件中定义 CATCH_CONFIG_MAIN。\n断言 Catch2 提供了多种断言宏，最常用的是 REQUIRE 和 CHECK：\nREQUIRE：如果断言失败，当前的测试案例会立即停止。 CHECK：即使断言失败，当前的测试案例也会继续运行，允许多个断言失败。 TEST_CASE(\u0026#34;Testing addition\u0026#34;) { REQUIRE(1 + 1 == 2); CHECK(2 + 2 == 4); } 测试固件 测试固件允许你在每个测试案例之前和之后运行一些代码。测试固件允许你设置和清理测试环境，这对于需要在多个测试案例中重用相同的初始化和清理逻辑非常有用。测试固件通过定义一个结构体或类来实现，你可以在其中定义构造函数（用于设置）和析构函数（用于清理）。然后，使用 TEST_CASE_METHOD 宏来指定哪个固件类应该被用于哪个测试案例。\nstruct DatabaseFixture { Database db; DatabaseFixture() : db(\u0026#34;my_database\u0026#34;) { // 初始化代码，比如打开数据库连接 db.connect(); } ~DatabaseFixture() { // 清理代码，比如关闭数据库连接 db.disconnect(); } }; // 一旦定义了测试固件，就可以在 TEST_CASE_METHOD 宏中使用它 TEST_CASE_METHOD(DatabaseFixture, \u0026#34;Test database connection\u0026#34;, \u0026#34;[database]\u0026#34;) { REQUIRE(db.isConnected() == true); } TEST_CASE_METHOD(DatabaseFixture, \u0026#34;Test database query\u0026#34;, \u0026#34;[database]\u0026#34;) { REQUIRE(db.query(\u0026#34;SELECT * FROM users\u0026#34;).size() \u0026gt; 0); } 在上述代码中，每个 TEST_CASE_METHOD 调用都会创建 DatabaseFixture 的一个新实例，这意味着每个测试案例都会开始于一个已连接的数据库状态。测试完成后，析构函数会被调用以断开连接，保证了每个测试都是独立的。\n分节 Catch2 允许你在单个测试案例中定义分节（Section），这些分节可以共享设置代码，但是每个分节会独立运行。\n这意味着在进入每个 SECTION 前，TEST_CASE 中定义的代码会被执行，为每个 SECTION 提供了一个共同的起点或环境。\n#define CATCH_CONFIG_MAIN #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;Testing with shared setup code\u0026#34;, \u0026#34;[example]\u0026#34;) { // 这里是共享的设置代码 int value = 42; SECTION(\u0026#34;Test part 1\u0026#34;) { // 第一个测试部分可以使用共享的设置代码 REQUIRE(value == 42); } SECTION(\u0026#34;Test part 2\u0026#34;) { // 第二个测试部分也可以使用相同的设置代码 value += 58; REQUIRE(value == 100); } } 变量 value 的初始化就是所谓的“设置代码”，它在两个不同的测试节中被共享。每个 SECTION 都独立执行，这意味着每个 SECTION 都会从 TEST_CASE 的开始处执行，包括共享的设置代码。因此，即便是在不同的测试节中，value 也总是从初始值 42 开始。\n参数化测试 Catch2 支持参数化测试，使得你可以用不同的输入重复运行同一测试案例。GENERATE 宏能够为测试案例生成一系列的值。在每次测试迭代中，GENERATE 会提供一个值，然后测试案例会使用这个值执行。这意味着相同的测试逻辑会被重复执行，但每次都使用不同的输入值。\n#define CATCH_CONFIG_MAIN #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;Parameterized tests with GENERATE\u0026#34;, \u0026#34;[example]\u0026#34;) { // 使用 GENERATE 宏生成一系列测试数据 int input = GENERATE(1, 2, 3, 4, 5); // 使用生成的数据执行测试逻辑 REQUIRE(input \u0026lt; 6); } 在这个例子中，GENERATE(1, 2, 3, 4, 5) 会依次为变量 input 生成 1 到 5 的值。对于每个生成的值，REQUIRE(input \u0026lt; 6) 断言都会被执行一次。因此，这个测试案例会被执行五次，每次使用不同的 input 值。\n集成catch2到cmake v2.xx的版本只需要catch2.hpp这个头文件就行了\nv3.xx的版本的用法：链接到Catch2::Catch2WithMain\ncmake_minimum_required(VERSION 3.14) # 确保使用的是 FetchContent 可用的 CMake 版本 project(MyProject VERSION 1.0) include_directories(${PROJECT_SOURCE_DIR}/include) # 包含 FetchContent 模块 include(FetchContent) # 使用 FetchContent_Declare 声明 Catch2 作为外部依赖项 FetchContent_Declare( Catch2 GIT_REPOSITORY https://github.com/catchorg/Catch2.git GIT_TAG v3.3.0 # or a later release ) # 使 Catch2 可用 FetchContent_MakeAvailable(Catch2) # 添加你的项目文件（示例） add_executable(my_project src/main.cpp src/sub.cpp) # 如果你有测试代码，可以像这样设置 enable_testing() # 启用测试 # 添加测试可执行文件 add_executable( my_test test/test1.cpp test/test2.cpp # 添加其他测试文件 ) # 链接 Catch2 到测试可执行文件 target_link_libraries(my_test PRIVATE Catch2::Catch2WithMain) # 为 Catch2 配置测试发现 LIST(APPEND CMAKE_MODULE_PATH ${catch2_SOURCE_DIR}/extras) include(CTest) include(Catch) CATCH_DISCOVER_TESTS(my_test) ","permalink":"https://dueplay.github.io/posts/catch2/","summary":"catch2用法 定义测试案例 测试案例在 Catch2 中通过 TEST_CASE 宏定义。TEST_CASE 宏接受两个参数：测试案例的名称和一个可选的标签。\n#define CATCH_CONFIG_MAIN // 这行让 Catch 自己提供一个 main() 函数 #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;A test case\u0026#34;, \u0026#34;[tag]\u0026#34;) { REQUIRE(1 == 1); } 如果你有多个测试文件，只需要在一个文件中定义 CATCH_CONFIG_MAIN。\n断言 Catch2 提供了多种断言宏，最常用的是 REQUIRE 和 CHECK：\nREQUIRE：如果断言失败，当前的测试案例会立即停止。 CHECK：即使断言失败，当前的测试案例也会继续运行，允许多个断言失败。 TEST_CASE(\u0026#34;Testing addition\u0026#34;) { REQUIRE(1 + 1 == 2); CHECK(2 + 2 == 4); } 测试固件 测试固件允许你在每个测试案例之前和之后运行一些代码。测试固件允许你设置和清理测试环境，这对于需要在多个测试案例中重用相同的初始化和清理逻辑非常有用。测试固件通过定义一个结构体或类来实现，你可以在其中定义构造函数（用于设置）和析构函数（用于清理）。然后，使用 TEST_CASE_METHOD 宏来指定哪个固件类应该被用于哪个测试案例。\nstruct DatabaseFixture { Database db; DatabaseFixture() : db(\u0026#34;my_database\u0026#34;) { // 初始化代码，比如打开数据库连接 db.connect(); } ~DatabaseFixture() { // 清理代码，比如关闭数据库连接 db.","title":"catch2测试框架"},{"content":"overview Lock Manager：锁管理器，利用 2PL 实现并发控制。支持 REPEATABLE_READ、READ_COMMITTED 和 READ_UNCOMMITTED 三种隔离级别，支持 SHARED、EXCLUSIVE、INTENTION_SHARED、INTENTION_EXCLUSIVE 和 SHARED_INTENTION_EXCLUSIVE 五种锁，支持 table 和 row 两种锁粒度，支持锁升级。Project 4 重点部分。 Deadlock Detection：死锁检测，运行在一个 后台线程，每间隔一定时间检测当前是否出现死锁，并挑选合适的事务将其 abort 以解开死锁。 Concurrent Query Execution：修改之前实现的 SeqScan、Insert 和 Delete 算子，加上适当的锁以实现并发的查询。 Lock Manager 首先理一理 Lock Manager 的成员：\ntable_lock_map_：记录 table 和与其相关锁请求的map。 row_lock_map_：记录 row 和与其相关锁请求的map。 这两个 map 的值均为锁请求队列 LockRequestQueue：\nrequest_queue_：实际存放锁请求的队列 cv_ \u0026amp; latch_：条件变量和锁，配合使用可以实现经典的等待资源模型。 upgrading_：正在此资源上尝试锁升级的事务 id。 锁请求以 LockRequest 表示：\ntxn_id_：发起此请求的事务 id。 lock_mode_：请求锁的类型,有S,X,IS,IX,SIX。 oid_：在 table 粒度锁请求中，代表 table id。在 row 粒度锁请求中，表示 row 属于的 table 的 id。 rid_：仅在 row 粒度锁请求中有效。指 row 对应的 rid。 granted_：是否已经对此请求授予锁 on_table_: 锁请求是在表上还是在行上 Lock Manager 的作用:\n为了确保事务操作的正确交错，DBMS 将使用锁管理器 (LM) 来控制何时允许事务访问数据项。LM 的基本思想是它维护一个有关活动事务当前持有的锁的内部数据结构。然后，事务在被允许访问数据项之前向 LM 发出锁定请求。LM 将向调用事务授予锁定、阻止该事务或中止它。\n例如有一个 SeqScan 算子需要扫描某张表，其所在事务就需要对这张表加 S 锁。而加读锁这个动作需要由 Lock Manager 来完成。事务先对向 Lock Manager 发起加 S 锁请求，Lock Manager 对请求进行处理。如果发现此时没有其他的锁与这个请求冲突，则授予其 S 锁并返回。如果存在冲突，例如其他事务持有这张表的 X 锁，则 Lock Manager 会阻塞此请求（即阻塞此事务），直到能够授予 S 锁，再授予并返回。\nLock 判断一个锁请求是否有效\n1.根据请求的是锁表还是锁行的flag判断\n表：支持所有的锁类型\n行：只支持 S 和 X 锁\n2.判断事务隔离级别\nREPEATABLE_READ: The transaction is required to take all locks. All locks are allowed in the GROWING state No locks are allowed in the SHRINKING state READ_COMMITTED: The transaction is required to take all locks. All locks are allowed in the GROWING state Only IS, S locks are allowed in the SHRINKING state READ_UNCOMMITTED: The transaction is required to take only IX, X locks. X, IX locks are allowed in the GROWING state. S, IS, SIX locks are never allowed REPEATABLE_READ：不允许在SHRINKING阶段获取任何锁,否则抛LOCK_ON_SHRINKING异常 READ_COMMITTED: 在SHRINKING阶段只允许IS/S锁, 如果在事务在SHRINKING阶段这个锁请求不是IS/S, 则抛LOCK_ON_SHRINKING异常 READ_UNCOMMITTED: 只允许IX, X锁, 如果不是X/IX则抛LOCK_SHARED_ON_READ_UNCOMMITTED异常,SHRINKING阶段不允许任何锁请求, 如果该事务处于SHRINKING阶段则抛LOCK_ON_SHRINKING异常. 每种隔离级别会带来的问题如下图, 不同的隔离级别是性能与一致性的权衡\n![15-445-4-1](E:\\db资料\\database\\P4 并发控制.assets\\15-445-4-1.png)\n3.如果是锁行,判断行所在的表是否持有相应的锁\n如果在行上请求X锁,则表应该持有X,IX,SIX\n如果在行上请求S锁,则表应该持有任意一种锁\n4.判断锁升级(upgrade)\n请求锁表\n该表已经持有一种锁,又申请锁,则为upgrade的情况 请求锁行\n该行已经持有S或者锁,又申请锁,则为upgrade的情况 是upgrade的话: 根据upgrade_matrix_判断该次锁请求是否与已经持有的锁兼容, 不兼容返回false, 兼容的情况再当前该表该行的锁请求队列中是否有事务upgrade, 如果有则返回false, 对给定资源的锁定只允许一个 txn 升级.\n注意:在不兼容和已经有事务在该资源上upgrade下还需要看下当前请求是否和已经持有的请求相同, 相同则不应该为false.\nLockTable实现思路(LockRow同理)：\n1.判断该lockrequest是否有效\n无效则修改事务txn的状态为终止,并抛出异常\n有效再检查是否为upgrade, 是upgrade且该请求的lock和该txn在该资源上已经持有的lock相同直接返回. 不相同的情况则进行upgrade操作, upgrade操作等同释放当前已经持有的锁，并在 queue 中标记我正在尝试升级,然后再尝试加锁. 也就是先释放此前持有的锁，把升级作为一个新的请求加入队列。\n只允许以下顺序的upgrade, 不能方向upgrade.\n/** * While upgrading, only the following transitions should be allowed: * IS -\u0026gt; [S, X, IX, SIX] * S -\u0026gt; [X, SIX] * IX -\u0026gt; [X, SIX] * SIX -\u0026gt; [X] */ 2.创建出LockRequest加入该表的锁请求队列LockRequestQueue中,upgrade的情况插入到队列第一个未被授予的请求的位置,因为upgrade要比其他请求锁的优先级高,不然直接插入到尾部, FIFO。\n3.尝试获得锁,当前请求在该表的请求队列的条件变量上(cv)等待, 检查该请求是否能被授予, 不能则一直等待.\n条件变量与互斥锁配合使用。首先需要持有锁，并查看是否能够获取资源。这个锁与资源绑定，是用来保证资源的互斥访问。若暂时无法获取资源，则调用条件变量的 wait 函数, 持有的锁将自动释放，并且当前线程被挂起，以节省资源。线程会被阻塞在wait函数中, 允许有多个线程在 wait 同一个cv。\nstd::unique_lock\u0026lt;std::mutex\u0026gt; lock(latch); while (!resource) { cv.wait(lock); } 当其他线程的活动使得资源状态发生改变时，需要调用cv的 notify_all() 或者notify_one()函数。即\n// do something changing the state of resource... cv.notify_all(); notify_all() 可以看作一次广播，会唤醒所有正在此条件变量上阻塞的线程。notify_one()则是唤醒一个阻塞在该cv上上的线程. 线程被唤醒后，其仍处于 wait 函数中。被唤醒的线程在 wait 函数中尝试获取 latch, 注意只有一个线程会获得锁。在成功获取 latch 后，退出 wait 函数，进入循环的判断条件，检查是否能获取资源。若仍不能获取资源，就继续进入 wait 阻塞，释放锁，挂起线程。若能获取资源，则退出循环。\n也可以使用c++中std::wait的另一种重载方法 wait(lock, pred) ,\n这里的谓词pred 为 true，则函数立即返回，并且不会解锁 lock。 如果 pred 为 false，则函数会解锁 lock 并阻塞当前线程，直到其他线程调用 notify_one() 或 notify_all() 来唤醒它。 唤醒后，它会重新获得 lock 并再次检查 pred，如果 pred 变为 true，则函数返回。\nqueue-\u0026gt;cv_.wait(lock, [\u0026amp;]() -\u0026gt; bool { return CouldLockRequestProceed(request, txn, queue, is_upgrade, already_abort); }); CouldLockRequestProceed检查该request能被授予\n该锁请求是否是第一个未被授予的正在waiting的请求, 锁请求会以严格的 FIFO 顺序依次满足,不是则继续等待。\n当前txn是第一个未被授予的,则判断该请求是否与之前已经被授予的锁兼容,不兼容则继续等待。\n兼容矩阵:\n![image-20240603173600578](E:\\db资料\\database\\P4 并发控制.assets\\image-20240603173600578.png)\n都满足则授予该锁请求，并在该事务的lockset中加入对应的资源。\n4.如果该txn在等待CouldLockRequestProceed的时候被终止, 原因可能是死锁检测中将其终止，也可能是外部的一些原因造成终止。因此需要检测是否处于 Aborted 状态将该请求移出该表的请求队列.\n5.该请求成功被授予,通知其他wait在该cv上的其他线程\nUnlock UnLockTable实现思路(UnLockRow同理)：\n1.判断该UnlockRequest是否有效\n首先确保事务确实持有它试图释放的锁，即查询该txn是否持有的锁是啥，在表上获得是啥锁，或者在row上获得的是啥锁。未持有锁则返回false，如果该txn要释放表上的锁必须确保它不是该LockRequestQueue上upgrading的事务，并且要确保该表中所有的row锁已经释放了。否则这个解锁请求是不对的。\n无效则修改事务txn的状态为终止,并抛出异常\n2.该UnlockRequest有效，根据该txn持有的锁和隔离级别更新事务的状态. 注意:如果是由upgrade释放锁不应该更改事务状态.\nREPEATABLE_READ: Unlock S/X 锁应该将事务状态改为SHRINKING\nREAD_COMMITTED和READ_UNCOMMITTED: Unlock X锁应该将事务状态改为SHRINKING\n3.从该表的LockRequestQueue中移除LockRequest,以及从事务的锁集合中移除表id\n4.通知wait在该表的LockRequestQueue其他locktable线程, 如果是由upgrade释放锁不应该通知, 因为upgrade的锁请求要优先处理.\nDeadlock Detection 在阻塞过程中有可能会出现多个事务的循环等待，出现循环等待会造成死锁。在 Bustub 中我们采用一个 background Deadlock Detection 线程来定时检查当前是否出现死锁。\n我们用 wait for 有向图来表示事务之间的等待关系。t1-\u0026gt;t2 即代表 t1 事务正在等待 t2 事务释放资源。当 wait for 图中存在环时，即代表出现死锁，需要挑选事务终止以打破死锁。\n我们并不需要时刻维护 wait for 图，而是在死锁检测线程被唤醒时，根据当前每个资源的请求队列构建 wait for 图，再通过 wait for 图判断是否存在死锁。当判断完成后，将丢弃当前 wait for 图。下次线程被唤醒时再重新构建。\n最常见的有向图环检测算法包括 DFS 和拓扑排序。在这里我们选用 DFS 来进行环检测。构建 wait for 图时要保证搜索的确定性。始终从 tid 较小的节点开始搜索，在选择邻居时，也要优先搜索 tid 较小的邻居。所以可以使用一个map\u0026lt;txn_id_t, std::set\u0026lt;txn_id_t\u0026gt;\u0026gt;来表示waits_for图, 出边数组的方法.\n构建 wait for 图的过程是，遍历 table_lock_map 和 row_lock_map 中所有的请求队列，对于每一个请求队列，再用一个二重循环将所有满足等待关系的一对 tid 加入 wait for 图的边集, 具体就是遍历请求队列, 如果一个请求是已经granted的则加入当前资源已经granted的事务id集合中, 如果一个请求是waiting的, 则遍历当前资源已经granted的事务id集合, 在waits_for图中添加一条waiting-\u0026gt;holder的边。\n然后DFS判断是否出现环，找到一个环，则终止环路径上最年轻的txn（tid 最大的事务），即将此事务的状态设为 Aborted。并且在请求队列中移除此事务，释放其持有的锁，终止其正在阻塞的请求，并调用 cv_.notify_all() 通知正在阻塞的相关事务。然后再在图中将指向这个txn事务的边去除，再进行下一次判断是否有环，因为可能出现多个环。没出现环了，说明现在不会死锁，在出现环时终止了一些txn的情况下需要通过所有的阻塞的线程。\nConcurrent Query Execution 这一部分需要我们将 transaction 应用到之前实现的算子中，以支持并发的查询。\n需修改 SeqScan、Insert 和 Delete 三个算子。为什么其他的算子不需要修改？因为其他算子获取的 tuple 数据均为中间结果，并不是表中实际的数据。而这三个算子是需要与表中实际数据打交道的。其中 Insert 和 Delete 几乎完全一样，与 SeqScan 分别代表着写和读。\nSeqScan 在给row上S锁之前，需要在其table level根据事务隔离级别上也上锁。\n如果隔离级别是 READ_UNCOMMITTED 则无需加锁， 隔离级别为READ_COMMITTED 和REPEATABLE_READ 的情况下判断该txn是否已经在该表上获得了锁，没有则调用LM的LockTable请求锁，请求锁失败则将txn的状态设置为ABORTED并抛出异常。该加什么锁？直观上来说应该直接给表加 S 锁，但实际上会导致 MixedTest 用例失败。实际上需要给表加 IS 锁，再给行加 S 锁。\n在 Next() 函数中，隔离级别为READ_COMMITTED 和REPEATABLE_READ 的情况下判断该行是否已经被Lock，如果没有则向LM申请LockRow。\n这里注意：如果是READ_COMMITTED ，在获取了行锁访问数据后，锁需要立马释放。REPEATABLE_READ 下，在 Commit/Abort 时统一释放，无需手动释放。\n在实现了 Predicate pushdown to SeqScan 之后，有没有可以给表直接加 S 锁的情况？有，当 SeqScan 算子中不存在 Predicate 时，即需要全表扫描时，或许可以直接给表加 S 锁，避免给所有行全部加上 S 锁。\nInsert \u0026amp; Delete 在 Next() 函数中，插入之前，还没有获得IX锁，则为表加上 IX 锁。同样，若获取失败则抛 ExecutionException 异常。\n在InsertTuple真正插入数据到表中时，再获取行锁。其他事务是看不见这一个row直到事务提交时。\n锁在 Commit/Abort 时统一释放，无需手动释放。\n","permalink":"https://dueplay.github.io/posts/bustub-project4-concurrency/","summary":"overview Lock Manager：锁管理器，利用 2PL 实现并发控制。支持 REPEATABLE_READ、READ_COMMITTED 和 READ_UNCOMMITTED 三种隔离级别，支持 SHARED、EXCLUSIVE、INTENTION_SHARED、INTENTION_EXCLUSIVE 和 SHARED_INTENTION_EXCLUSIVE 五种锁，支持 table 和 row 两种锁粒度，支持锁升级。Project 4 重点部分。 Deadlock Detection：死锁检测，运行在一个 后台线程，每间隔一定时间检测当前是否出现死锁，并挑选合适的事务将其 abort 以解开死锁。 Concurrent Query Execution：修改之前实现的 SeqScan、Insert 和 Delete 算子，加上适当的锁以实现并发的查询。 Lock Manager 首先理一理 Lock Manager 的成员：\ntable_lock_map_：记录 table 和与其相关锁请求的map。 row_lock_map_：记录 row 和与其相关锁请求的map。 这两个 map 的值均为锁请求队列 LockRequestQueue：\nrequest_queue_：实际存放锁请求的队列 cv_ \u0026amp; latch_：条件变量和锁，配合使用可以实现经典的等待资源模型。 upgrading_：正在此资源上尝试锁升级的事务 id。 锁请求以 LockRequest 表示：\ntxn_id_：发起此请求的事务 id。 lock_mode_：请求锁的类型,有S,X,IS,IX,SIX。 oid_：在 table 粒度锁请求中，代表 table id。在 row 粒度锁请求中，表示 row 属于的 table 的 id。 rid_：仅在 row 粒度锁请求中有效。指 row 对应的 rid。 granted_：是否已经对此请求授予锁 on_table_: 锁请求是在表上还是在行上 Lock Manager 的作用:","title":"bustub project4 concurrency"},{"content":"实验中给出的 B+ 树接口非常简单，基本只有查询、插入和删除三个接口，内部基本没有给出别的辅助函数，可以让我们自由发挥（无从下手）。因此，任何合法的 B+ 树实现都是允许的。\nB+ 树索引在 Bustub 中的位置如图所示:\nB+树种需要的page都需要使用在 Project 1 中实现的 buffer pool manager 来获取。\nCheckpoint1 Single Thread B+Tree Checkpoint1 分为两个部分：\nTask1: B+Tree pages，B+树中的各种 page。在 Bustub 索引 B+ 树中，所有的节点都是一个 page。包含 leaf page，internal page ，和它们的父类 tree page。 Task2：B+Tree Data Structure (Insertion, Deletion, Point Search)。Checkpoint1 的重点，即 B+树的插入、删除和单点查询。 Task1 B+Tree Pages task1 主要实现leaf page和internal page这两个类，都继承自BPlusTreePage这个父类，实现一些Getter和Setter方法。\n首先介绍一下page的内存布局\n其中，data_ 是实际存放 page 数据的地方，大小为 BUSTUB_PAGE_SIZE，为 4KB。其他的成员是 page 的 metadata。\nB+树中的 tree page 数据均存放在 page 的 data 成员中，也就是B+树中的节点是Page的data数据成员。\nB_PLUS_TREE_PAGE\nheader包括以下数据\nIndexPageType page_type_; // leaf or internal. 4 Byte lsn_t lsn_ // temporarily unused. 4 Byte int size_; // tree page data size(not in byte, in count). 4 Byte int max_size_; // tree page data max size(not in byte, in count). 4 Byte page_id_t parent_page_id_; // 4 Byte page_id_t page_id_; // 4 Byte // 24 Byte in total page data 的 4KB 中，24Byte 用于存放 header，剩下的则用于存放 tree page 的数据，即 KV 对。\nB_PLUS_TREE_INTERNAL_PAGE\n对应 B+ 树中的内部节点。\nMappingType array_[1]; internal page 中没有新的 metadata，header 大小仍为 24B。它唯一的成员是一个大小为 1 的数组。大小为 1 显然不合理，代表只能存放一个 KV 对。但又没法改变它的大小，难道要用 undefined behavior 来越界访问其后的地址？实际上差不多就是这个意思。但这不是 undefined behavior，是一种特殊的写法，叫做 flexible array。\n简单来说就是，当你有一个类，这个类中有一个成员为数组。在用这个类初始化一个对象时，你不能确定该将这个数组的大小设置为多少，但知道这整个对象的大小是多少 byte，你就可以用到 flexible array。flexible array 必须是类中的最后一个成员，并且仅能有一个。在为对象分配内存时，flexible array 会自动填充，占用未被其他变量使用的内存。这样就可以确定自己的长度了。\n例如有一个类 C：\nclass C { int a; // 4 byte int array[1]; // unknown size }; 现在初始化一个 C 的对象，并为其分配了 24 byte 的内存。a 占了 4 byte 内存，那么 array 会尝试填充剩下的内存，大小变为 5。\n实际上这就是 C++ 对象内存布局的一个简单的例子。因此 flexible array 为什么只能有一个且必须放在最后一个就很明显了，因为需要向后尝试填充。\n这个大小为 1 的数组的作用就比较清楚了。利用 flexible array 的特性来自动填充 page data 4KB 减掉 header 24byte 后剩余的内存。剩下的这些内存用来存放 KV 对。\ninternal page 中，KV 对的 K 是能够比较大小的索引，V 是 page id，用来指向下一层的节点。Project 中要求，第一个 Key 为空。主要是因为在 internal page 中，n 个 key 可以将数轴划分为 n+1 个区域，也就对应着 n+1 个 value。实际上你也可以把最后一个 key 当作是空的。\n通过比较 key 的大小选中下一层的节点。实际上等号的位置也可以改变，总之，只要是合法的 B+ 树，即节点大小需要满足最大最小值的限制，各种实现细节都是自由的。\n另外需要注意的是，internal page 中的 key 并不代表实际上的索引值，实际的KV在B+树中都存在leaf page中，这里仅仅是作为一个向导，引导需要插入/删除/查询的 key 找到这个 key 真正所在的 leaf page。\nB_PLUS_TREE_LEAF_PAGE\nleaf page 和 internal page 的内存布局基本一样，只是 leaf page 多了一个成员变量 next_page_id，指向下一个 leaf page（用于 range scan）。因此 leaf page 的 header 大小为 28 Byte。\nleaf page 的 KV 对中，K 是实际的索引，V 是 record id。record id (table_id + slot_id)用于标识表中的某一条数据。leaf page 的 KV 对是一一对应的，不像 internal page 的一个key可以有多个 value 。这里也可以看出来 Bustub 所有的 B+ 树索引，无论是主键索引还是二级索引都是非聚簇索引。\n这里简单介绍一下聚簇索引、非聚簇索引，主键索引、二级索引（非主键索引）的区别。 在聚簇索引里，leaf page 的 value 为表中一条数据的某几个字段或所有字段，一定包含主键字段。而非聚簇索引 leaf page 的 value 是 record id，即指向一条数据的指针。 在使用聚簇索引时，主键索引的 leaf page 包含所有字段，二级索引的 leaf page 包含主键和索引字段。当使用主键查询时，查询到 leaf page 即可获得整条数据。当使用二级索引查询时，若查询字段包含在索引内，可以直接得到结果，但如果查询字段不包含在索引内，则需使用得到的主键字段在主键索引中再次查询，以得到所有的字段，进而得到需要查询的字段，这就是回表的过程。 在使用非聚簇索引时，无论是使用主键查询还是二级索引查询，最终得到的结果都是 record id，需要使用 record id 去查询真正对应的整条记录。 聚簇索引的优点是，整条记录直接存放在 leaf page，无需二次查询，且缓存命中率高，在使用主键查询时性能比较好。缺点则是二级索引可能需要回表，且由于整条数据存放在 leaf page，更新索引的代价很高，页分裂、合并等情况开销比较大。 非聚簇索引的优点是，由于 leaf page 仅存放 record id，更新的代价较低，二级索引的性能和主键索引几乎相同。缺点是查询时均需使用 record id 进行二次查询。\nTask2 B+Tree Data Structure (Insertion, Deletion, Point Search) Search\nB+ 树的节点分为 internal page 和 leaf page，每个 page 上的 key 有序排列。当拿到一个 key 需要查找对应的 value 时，首先需要经由 internal page 递归地向下查找，最终找到 key 所在的 leaf page。这个过程可以简化为一个函数 FindLeafPage()。\nFindLeafPage() 从 root page 开始一层一层的查找。在查找到 leaf page 时直接返回，否则根据 key 在当前 internal page 中找到对应的 child page id，再在child page 中查找。由于 key 是有序的，可以直接进行二分搜索。\ninternal page 中储存 key 和 child page id，那么在拿到 page id 后如何获得对应的 page 指针？用 Project 1 中实现的 buffer pool。\nPage *page = buffer_pool_manager_-\u0026gt;FetchPage(page_id); 在获取到一个 page 后，如何使用这个 page 来存储数据？之前已经提到过，page 的 data_ 字段是实际用于存储数据的 4KB 大小的字节数组。通过 reinterpret_cast 将这个字节数组强制转换为我们要使用的类型，例如 leaf page：\nauto leaf_page = reinterpret_cast\u0026lt;B_PLUS_TREE_LEAF_PAGE_TYPE *\u0026gt;(page-\u0026gt;GetData()) reinterpret_cast 用于无关类型的强制转换，转换方法很简单，原始 bits 不变，只是对这些 bits 用新类型进行了重新的解读。可想而知这种转换非常不安全，需要确保转换后的内存布局仍是合法的。在这里原类型是 byte 数组，新类型是我们需要使用的 tree page。\n我们可以将上面两部封装成一个函数，用于根据page_id获取BPlusTreePage原始的page和page.data。注意这里reinterpret_cast返回的是BPlusTreePage，后续还需要转成其子类leaf和interal page。。\nINDEX_TEMPLATE_ARGUMENTS auto BPLUSTREE_TYPE::FetchBPlusTreePage(page_id_t page_id) -\u0026gt; std::pair\u0026lt;Page *, BPlusTreePage *\u0026gt; { Page *page = buffer_pool_manager_-\u0026gt;FetchPage(page_id); BUSTUB_ASSERT(page != nullptr, \u0026#34;FetchBPlusTreePage(): page != nullptr\u0026#34;); return {page, reinterpret_cast\u0026lt;BPlusTreePage *\u0026gt;(page-\u0026gt;GetData())}; } 找到 leaf page 后，同样是二分查找 key，找到对应的 record id。注意在leaf page中二分查找左边界是0，在internal page中二分查找左边界是1。\n在查找的时候还有一个比较重要且复杂的细节，就是 page unpin 的问题。\n我们在拿到 page id 后，调用 buffer pool 的 FetchPage() 函数来获取对应的 page 指针。要注意的是，在使用完 page 之后，需要将 page unpin 掉，否则最终会导致 buffer pool 中的所有 page 都被 pin 住，buffer pool 满无法进行换入换出，无法从 disk 读取其他的 page。\n比较合适的做法是，在本次操作中，找出 page 最后一次被使用的地方，并在最后一次使用后 unpin。\nInsert\n与 Search 相同，第一步是根据 key 找到需要插入的 leaf page。同样是调用 FindLeafPage()。得到 leaf page 后，将 key 插入 leaf page。当B+树为空时，新建一个leaf page作为root page将其插入。要注意的是：1.插入时仍需保证 key 的有序性，同样可以二分搜索找到合适的位置插入。2.是不允许有重复的key的，当插入重复的key返回false。\n在插入后，需要检查当前 leaf page size 是否等于 max size。若相等，则要进行一次 leaf page 分裂操作。具体步骤为：\n新建一个空的 page， 将原 page 的一半转移到新 page 中，（假如选择将新 page 放在原 page 右侧，则转移原 page 的右半部分） 更新原 page 和新 page 的 next page id， 获取 parent page，将用于区分原 page 和新 page 的 key 插入 parent page 中， 更新 parent page 所有 child page 的父节点指针。 需要给 parent page 插入一个新 key 的原因是，多了一个子节点，自然需要多一个 key 来区分，这个key是右边节点的key0。其中第 4 步是重点。获取 parent page 并不是简单地通过当前 page 的 parent id 来获取，因为 parent page 也可能发生分裂。\n假如我们有一棵 5 阶的 B+ 树。5 阶只是一种常用的说法，代表 B+ 树节点最多能容纳五个 KV 对。对于 leaf page 来说，当 B+ 树处于稳定状态时（插入、删除等操作已经完全结束），最多只能有 4 个 KV 对。对于 internal page，最多有 4 个 key，5 个 value，可以看成是有 5 个 KV 对。\n因此，instruction 中有这么一句话：\nYou should correctly perform splits if insertion triggers the splitting condition (number of key/value pairs AFTER insertion equals to max_size for leaf nodes, number of children BEFORE insertion equals to max_size for internal nodes.).\n在插入后检测 leaf page 是否需要分裂，因为 leaf page 稳定时只有 4 个 KV 对，插入后有 5 个，仍能容纳。在插入前检测 internal page，因为 internal page 稳定时就有 5 个 KV 对，若插入后再检测，插入的第 6 个 KV 对会造成越界。\n实际上这也只是一种约定，并不是强制的规则。\n第 4 步具体操作如下： 1. 根据leaf page的 parent page id 拿到 parent page， 2. 判断 parent page size 是否等于 max size，（插入前检查） 3. 若小于，直接返回 parent page， 4. 否则，分裂当前 internal page。并根据此后需要插入的 key 选择分裂后的两个 page 之一作为 parent page 返回。\n分裂 internal page 的步骤为： 1. 新建一个空的 InternalPage， 2. 将原 page 的一半转移到新 page 中，需要注意原 page 和新 page 的第一个 key 都是无效的， 3. 更新新 page 所有 child page 的父节点指针，指向新 page， 4. 获取 parent page， 5. 将用于区分原 page 和新 page 的 key 插入 parent page 中， 6. 更新 parent page 所有 child page 的父节点指针。\n这里发生了向上的递归，直到遇到安全的父节点或者遇到根节点。在遇到根节点时，若根节点也需要分裂，则除了需要新建一个节点用来容纳原根节点一半的 KV 对，还需要新建一个新的根节点。\n假如有一棵 4 阶的 B+ 树：\nDelete\n同样地，先找到 leaf page。删除 leaf page 中 key 对应的 KV 对后，检查 size 是否小于 min size。如果小于的话，首先尝试从两侧的兄弟节点中偷一个 KV 对。注意只能从兄弟节点，即父节点相同的节点中选取。假如存在一侧节点有富余的 KV 对，则成功偷取，结束操作。若两侧都没有富余的 KV 对，则选择一侧节点与其合并。\n偷取的过程比较简单，从左侧节点偷取时，把左侧节点最后一个 KV 对转移至当前节点第一个 KV 对，从右侧节点偷取时，把右侧节点的 KV 对转移至当前节点最后一个 KV 对。leaf page 和 internal page 的偷取过程基本相同，仅需注意 internal page 偷取后更新子节点的父节点指针。\n稍难的是合并的过程。同样，任选左右侧一兄弟节点进行合并。将一个节点的所有 KV 对转移至另一节点。若合并的是 leaf page，记得更新 next page id。若合并的是 internal page，记得更新合并后 page 的子节点的父节点指针。然后，删除 parent 节点中对应的 key。删除后，再次检查 size 是否小于 min size，形成向上递归。\n需要注意的是，root page 并不受 min size 的限制。但如果 root page 被删到 size 只剩 1，即只有一个 child page 的时候，应将此 child page 设置为新的 root page。\n另外，在合并时，两个 page 合并成一个 page，另一个 page 应该删除，释放资源。删除 page 时，仍是调用 buffer pool 的 DeletePage() 函数。\n和 Insert 类似，Delete 过程也是先向下递归查询 leaf page，不满足 min size 后先尝试偷取，无法偷取则合并，并向上递归地检查是否满足 min size。\n","permalink":"https://dueplay.github.io/posts/bustub-project2/","summary":"实验中给出的 B+ 树接口非常简单，基本只有查询、插入和删除三个接口，内部基本没有给出别的辅助函数，可以让我们自由发挥（无从下手）。因此，任何合法的 B+ 树实现都是允许的。\nB+ 树索引在 Bustub 中的位置如图所示:\nB+树种需要的page都需要使用在 Project 1 中实现的 buffer pool manager 来获取。\nCheckpoint1 Single Thread B+Tree Checkpoint1 分为两个部分：\nTask1: B+Tree pages，B+树中的各种 page。在 Bustub 索引 B+ 树中，所有的节点都是一个 page。包含 leaf page，internal page ，和它们的父类 tree page。 Task2：B+Tree Data Structure (Insertion, Deletion, Point Search)。Checkpoint1 的重点，即 B+树的插入、删除和单点查询。 Task1 B+Tree Pages task1 主要实现leaf page和internal page这两个类，都继承自BPlusTreePage这个父类，实现一些Getter和Setter方法。\n首先介绍一下page的内存布局\n其中，data_ 是实际存放 page 数据的地方，大小为 BUSTUB_PAGE_SIZE，为 4KB。其他的成员是 page 的 metadata。\nB+树中的 tree page 数据均存放在 page 的 data 成员中，也就是B+树中的节点是Page的data数据成员。","title":"bustub project2"},{"content":"buffer pool是负责在内存和磁盘之间移动页面(数据库文件是以页来组织的)。buffer pool的操作对于系统的其他组件是 透明的，也就是说系统只需要使用一个page_id（这是唯一的）去像buffer pool请求这个页面，是不知道这个页是不是已经在内存中了，还是需要从磁盘中读。\n可拓展hash table 第一个任务是需要实现一个可拓展hash table，这个hash table的作用是负责管理page_id到buffer pool中页面id(frame_id)的映射。buffer pool管理N个页面的内存空间，一个页面的内存空间就叫做frame。需要读取一个页面时，就将一个frame分配这个页面，然后用hash table记录这个映射关系。\n在实现之前需要理解一些可拓展哈希表中的概念：[参考文献](Extendible Hashing (Dynamic approach to DBMS) - GeeksforGeeks)\n目录dir：这个容器存储指向桶的指针。每个dir给定一个唯一的id，当扩张发生时id可能随之改变。哈希函数返回这个目录的id，这个id被用来指向合适的桶。dir的数量 = 2^{全局深度} 桶: 存储哈希键。目录指向桶。如果局部深度小于全局深度时，一个桶可能包含不止一个指针指向它。 全局深度：它跟目录相关联。它们表示哈希函数使用的比特位数目去分类这些键。全局深度=目录id的比特位数 局部深度：和全局深度类似，局部深度是跟桶关联，而不是跟目录。当桶溢出发生时，局部深度根据全局深度去决定执行的行为。局部深度通常小于等于全局深度。 桶分裂：当桶的元素超过了特定的大小，那么桶分裂成两个部分。 目录扩容：当桶溢出时，可能会有目录扩容。当溢出桶的局部深度等于全局深度时，目录扩容被执行。 首先需要实现的是Bucket，Bucket采用的std::list\u0026lt;pair\u0026lt;K,V\u0026raquo;来作为存储数据的数据结构，stl可以让我们很方便的实现数据的增删查改。查找一个key可以通过std::find_if或者遍历这个list，插入时需要判断是否超出这个桶的大小。\n有了Bucket，就可以开始实现我们的可拓展hash表，它的全局深度首先被初始化为0，由于桶的数量是2^全局深度，所以在开始时只有一个桶，即dir中只有一个Bucket指针。\n重点是insert操作(插入一个key，value对)的实现。首先是根据hash函数计算出key的dir index，然后再在对应的桶中实现插入。在插入到桶中时可能因为桶已满而插入失败，这时候我们就需要进行目录扩张和桶分裂。需要注意的是：并不是桶满了就需要执行目录的分裂，而是当桶的局部深度=全局深度时，才需要进行桶的分裂。在桶的局部深度小于全局深度时是不需要扩张目录的，此时是有多个指针指向同一个桶，我们只需要再创建一个新桶，然后再将这个已满桶中的元素重新分配即可，创建新桶需要将局部深度+1。在桶扩张时，将新扩张的dir(桶指针)指向同一个桶，当需要时再去创建新的桶。\neg: global_depth = 2, local_depth = 2, dir_size = 2^2 = 4，插入kv到idx = 3 的桶，但这个桶已经满了。则需要执行dir扩张，扩张为原来的2倍，即dir_size = 2^2* \u0026laquo; 1,扩张为8。idx = 3 = 011，3 + old_dir_size = 7 = 111，7的位置则是新建的桶。其他新扩张应该指向之前的桶，等到之间的桶满，再创建。即4指向0指向的桶，等等。\n由于是要支持并发操作的，因此也需要在合适的地方加锁。\n造成死锁的一种情况：当一个函数中已经加锁再去调用另一个需要同一把锁的函数，这会造成死锁。\nlru_k替换策略 在frame中page，在整个buffer pool中的所有frame都被使用时，这时候则需要选择一个victim来替换。常使用的是lru算法，lru_k则是再lru的基础上多加了一个访问k次以上的页，是要比那些小于k次更晚被换出。简单的理解就是，将所有在frame中的页面分为访问小于k次的和大于等于k次的，两种都是采用lru算法，但是是先替换小于k次的页面，小于k次页面的全部不能被替换或者当没有小于k次还需要Evict一个page时，才去Evict一个大于k次的页面。\n不能被替换的page是那些被pin的，也就是还在使用的page。\nstd::vector\u0026lt;LRUKFrameRecord *\u0026gt; frames_ 记录buffer pool中所有frame的一个访问记录，LRUKFrameRecord 是记录一个frame的最多k次访问记录。\n我们可以set来将所有可被Evict的frame分为小于k次的一个set，和大于等于k次的一个set，并且重载LRUKFrameRecord 的operator\u0026lt;，使其访问时间最早的在set的最前面，Evict时则选择set.begind()的frame。不可被Evict的frame不应该出现在set中，不能被lru的机制所Evict。\nSetEvictable这个函数将一个frame设置为可不可被Evict, 一种情况是将不可被Evict设置为可Evict，需要再对应的set中加入；一种是可Evict设置为不可Evict，需要将其在对应的set中移除。\nbuffer_pool_manager_instance bpm则将上面实现的组件协同起来实现整个buffer_pool的逻辑。\nbpm管理着一个std::list\u0026lt;frame_id_t\u0026gt; free_list_, 记录着未被使用的frame，free_list_为空时，则需要用lru_k替换一个frame。\nNewPgImp需要在buffer pool中创建page_id的page，如果free_list_为空时，则需要用lru_k替换一个frame。替换这个frame如果他的状态是dirty的，则需要调用disk_manager将其写回。创建新page后，需要用hash table记录其对应的frame，以及需要记录访问记录以上lru_k替换器来管理。\nFetchPgImp在buffer pool中获取指定page_id的页面，存在则直接获取，同时记录访问和pin++,并且设置不可Evict。若不存在，则需要像newPage一样。\nfetch 和 newpage的区别是：new是在buffer pool中加入一个新的页面，而fetch是获得在buffer pool中已有的页面,没有再尝试evict a frame and read page_id page from disk\n","permalink":"https://dueplay.github.io/posts/bustub-project1/","summary":"buffer pool是负责在内存和磁盘之间移动页面(数据库文件是以页来组织的)。buffer pool的操作对于系统的其他组件是 透明的，也就是说系统只需要使用一个page_id（这是唯一的）去像buffer pool请求这个页面，是不知道这个页是不是已经在内存中了，还是需要从磁盘中读。\n可拓展hash table 第一个任务是需要实现一个可拓展hash table，这个hash table的作用是负责管理page_id到buffer pool中页面id(frame_id)的映射。buffer pool管理N个页面的内存空间，一个页面的内存空间就叫做frame。需要读取一个页面时，就将一个frame分配这个页面，然后用hash table记录这个映射关系。\n在实现之前需要理解一些可拓展哈希表中的概念：[参考文献](Extendible Hashing (Dynamic approach to DBMS) - GeeksforGeeks)\n目录dir：这个容器存储指向桶的指针。每个dir给定一个唯一的id，当扩张发生时id可能随之改变。哈希函数返回这个目录的id，这个id被用来指向合适的桶。dir的数量 = 2^{全局深度} 桶: 存储哈希键。目录指向桶。如果局部深度小于全局深度时，一个桶可能包含不止一个指针指向它。 全局深度：它跟目录相关联。它们表示哈希函数使用的比特位数目去分类这些键。全局深度=目录id的比特位数 局部深度：和全局深度类似，局部深度是跟桶关联，而不是跟目录。当桶溢出发生时，局部深度根据全局深度去决定执行的行为。局部深度通常小于等于全局深度。 桶分裂：当桶的元素超过了特定的大小，那么桶分裂成两个部分。 目录扩容：当桶溢出时，可能会有目录扩容。当溢出桶的局部深度等于全局深度时，目录扩容被执行。 首先需要实现的是Bucket，Bucket采用的std::list\u0026lt;pair\u0026lt;K,V\u0026raquo;来作为存储数据的数据结构，stl可以让我们很方便的实现数据的增删查改。查找一个key可以通过std::find_if或者遍历这个list，插入时需要判断是否超出这个桶的大小。\n有了Bucket，就可以开始实现我们的可拓展hash表，它的全局深度首先被初始化为0，由于桶的数量是2^全局深度，所以在开始时只有一个桶，即dir中只有一个Bucket指针。\n重点是insert操作(插入一个key，value对)的实现。首先是根据hash函数计算出key的dir index，然后再在对应的桶中实现插入。在插入到桶中时可能因为桶已满而插入失败，这时候我们就需要进行目录扩张和桶分裂。需要注意的是：并不是桶满了就需要执行目录的分裂，而是当桶的局部深度=全局深度时，才需要进行桶的分裂。在桶的局部深度小于全局深度时是不需要扩张目录的，此时是有多个指针指向同一个桶，我们只需要再创建一个新桶，然后再将这个已满桶中的元素重新分配即可，创建新桶需要将局部深度+1。在桶扩张时，将新扩张的dir(桶指针)指向同一个桶，当需要时再去创建新的桶。\neg: global_depth = 2, local_depth = 2, dir_size = 2^2 = 4，插入kv到idx = 3 的桶，但这个桶已经满了。则需要执行dir扩张，扩张为原来的2倍，即dir_size = 2^2* \u0026laquo; 1,扩张为8。idx = 3 = 011，3 + old_dir_size = 7 = 111，7的位置则是新建的桶。其他新扩张应该指向之前的桶，等到之间的桶满，再创建。即4指向0指向的桶，等等。\n由于是要支持并发操作的，因此也需要在合适的地方加锁。\n造成死锁的一种情况：当一个函数中已经加锁再去调用另一个需要同一把锁的函数，这会造成死锁。\nlru_k替换策略 在frame中page，在整个buffer pool中的所有frame都被使用时，这时候则需要选择一个victim来替换。常使用的是lru算法，lru_k则是再lru的基础上多加了一个访问k次以上的页，是要比那些小于k次更晚被换出。简单的理解就是，将所有在frame中的页面分为访问小于k次的和大于等于k次的，两种都是采用lru算法，但是是先替换小于k次的页面，小于k次页面的全部不能被替换或者当没有小于k次还需要Evict一个page时，才去Evict一个大于k次的页面。\n不能被替换的page是那些被pin的，也就是还在使用的page。\nstd::vector\u0026lt;LRUKFrameRecord *\u0026gt; frames_ 记录buffer pool中所有frame的一个访问记录，LRUKFrameRecord 是记录一个frame的最多k次访问记录。","title":"bustub project1"},{"content":"概览 需要实现一个数据结构为Trie树的kv存储，Trie一种高效的有序树数据结构，用于检索给定键的值。Trie中的每个节点存储一个key的单个字符，并且可以很多字节点，子节点代表key的下一个字符。key的末尾字符的节点(终端节点)会用一个flag标记这是一个key的结束，并存储相应的val。\n下面这个Trie树，有ab-\u0026gt;1,ac-\u0026gt;“val”，两个kv对，注意val可以是任何类型。\n实现 TrieNode TrieNode类代表树中的单个节点，代表一个key中的单个char。一个TrieNode可以有很多子节点，因此用unordered_map来存储每个子节点的字符和子节点指针的映射。此外还需要一个flag来表示该节点是否是一个key的结尾。为了避免内存泄露，采用智能指针。\nTrieNodeWithValue 该类代表一个key的终端节点，它继承了TrieNode，并且增加了自己特有的属性，即需要存储的val.\n可以有两种方式来创建终端节点：\n插入一个key，创建一个新的终端节点。 插入一个key，将非终端节点转换为终端节点，即将TrieNode转为TrieNodeWithValue。因此需要给该类实现一个TrieNodeWithValue(TrieNode \u0026amp;\u0026amp;trieNode, T value)有参构造，用于将已有的非终端节点转为终端节点，这个构造需要去调用TrieNode的移动构造将trieNode的资源转移到终端节点，包括表示的字符和子节点map。 Trie 成员变量有root节点的指针，指向一个根节点(用字符‘\\0’标识)；为了支持并发，还需要一个读写锁 ReaderWriterLatch latch_\n需要实现增删查三个功能\nInsert 插入一个kv对到Trie中，一个key的每个字符都是一个节点，因此需要做的就是从root节点开始，一层一层的插入新节点，如果有该字符的节点了，我们应该重用它。key最后一个字符需要特殊处理，而不是直接在父节点中插入新节点。\n需要判断是否该结尾字符已经在Trie树中，如果是，再判断这个节点是不是一个终端节点，如果是终端节点，则插入失败，因为不支持重复的key，如果不是终端节点，则需要将非终端的TrieNode转为终端节点TrieNodeWithValue。\n如果结尾字符不在Trie树中，创建新的TrieNodeWithValue，然后插入到父节点中，插入完成。\n同时在Insert操作中，应该是上写锁，返回时应该解锁。\nRemove 移除给定key的val，同时需要删除一些没用节点。首先是根据这个key从root开始一层一层遍历，找到该key的终端节点，没有该key对应的终端节点则直接返回false。找到终端节点后，将其flag设为false，表示这不是一个终端节点，逻辑上删除这个kv。下一步我们需要从该节点开始向上递归的删除那些没有任何子节点的非终端节点，因为这些节点肯定是不再会被用到的，既不是一个key的结尾，也不是一个key的中间节点。实现上可以通过从root开始将遍历到该节点的路径保存，然后在路径中从后往前遍历每个节点，判断是否属于这种情况，是则在其父节点的map中移除。\n同样的在Remove操作中，应该是上写锁，返回时应该解锁。\nGetValue 返回指定key对应的val，注意这个val的类型是任意的，所以这是一个函数模板。还是首先从根节点开始一层一层遍历key的每个字符找到最后一个字符所在的节点，然后不是终端节点或者没有该节点，失败直接返回。有这个key所对应的终端节点，那么返回这个终端节点的val。这样就ok了吗？其实不是，由于val是任意类型的，所以还需要判断这个val是不是我们所要的val类型。要检查这两个类型是否相同，将终端 TrieNode 通过dynamic_cast转为 TrieNodeWithValue。 如果转换结果不是 nullptr，则类型 T 是正确的类型。在类型不匹配时，即使有key所对应的终端节点，也应该失败直接返回。只有在类型匹配时，才正确返回其val。\n同样的在GetValue操作中，应该是上读锁，返回时应该解锁。\nReaderWriterLatch 在c++中可以通过std::shared_mutex mutex_很容易得实现一个读写锁。在bustub中已经有一个实现好的读写锁，上写锁mutex_.lock() ,上读锁mutex_.lock_shared(),对应的解锁操作分别是：mutex_.unlock() 和mutex_.unlock_shared()。\n源码 //===----------------------------------------------------------------------===// // // BusTub // // p0_trie.h // // Identification: src/include/primer/p0_trie.h // // Copyright (c) 2015-2022, Carnegie Mellon University Database Group // //===----------------------------------------------------------------------===// #pragma once #include \u0026lt;memory\u0026gt; #include \u0026lt;stdexcept\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026#34;common/exception.h\u0026#34; #include \u0026#34;common/rwlatch.h\u0026#34; namespace bustub { /** * TrieNode is a generic container for any node in Trie. */ class TrieNode { public: /** * TODO(P0): Add implementation * * @brief Construct a new Trie Node object with the given key char. * is_end_ flag should be initialized to false in this constructor. * * @param key_char Key character of this trie node */ explicit TrieNode(char key_char) : key_char_(key_char), is_end_(false) {} /** * TODO(P0): Add implementation * * @brief Move constructor for trie node object. The unique pointers stored * in children_ should be moved from other_trie_node to new trie node. * * @param other_trie_node Old trie node. */ TrieNode(TrieNode \u0026amp;\u0026amp;other_trie_node) noexcept { key_char_ = other_trie_node.key_char_; // move semantics to transfer the ownership of unique_ptr // from other_trie_node to current one // 将容器中存储的元素全部移动到其他容器中。make_move_iterator返回一个move_iterator，若此迭代器用作输入迭代器，则效果是值被移动，而非复制。 children_ = std::unordered_map\u0026lt;char, std::unique_ptr\u0026lt;TrieNode\u0026gt;\u0026gt;(std::make_move_iterator(other_trie_node.children_.begin()), std::make_move_iterator(other_trie_node.children_.end())); other_trie_node.children_.clear(); } /** * @brief Destroy the TrieNode object. */ virtual ~TrieNode() = default; /** * TODO(P0): Add implementation * * @brief Whether this trie node has a child node with specified key char. * * @param key_char Key char of child node. * @return True if this trie node has a child with given key, false otherwise. */ bool HasChild(char key_char) const { return children_.find(key_char) != children_.end(); } /** * TODO(P0): Add implementation * * @brief Whether this trie node has any children at all. This is useful * when implementing \u0026#39;Remove\u0026#39; functionality. * * @return True if this trie node has any child node, false if it has no child * node. */ bool HasChildren() const { return !children_.empty(); } /** * TODO(P0): Add implementation * * @brief Whether this trie node is the ending character of a key string. * * @return True if is_end_ flag is true, false if is_end_ is false. */ bool IsEndNode() const { return is_end_; } /** * TODO(P0): Add implementation * * @brief Return key char of this trie node. * * @return key_char_ of this trie node. */ char GetKeyChar() const { return key_char_; } /** * TODO(P0): Add implementation * * @brief Insert a child node for this trie node into children_ map, given the * key char and unique_ptr of the child node. If specified key_char already * exists in children_, return nullptr. If parameter `child`\u0026#39;s key char is * different than parameter `key_char`, return nullptr. * * Note that parameter `child` is rvalue and should be moved when it is * inserted into children_map. * * The return value is a pointer to unique_ptr because pointer to unique_ptr * can access the underlying data without taking ownership of the unique_ptr. * Further, we can set the return value to nullptr when error occurs. * * @param key Key of child node * @param child Unique pointer created for the child node. This should be * added to children_ map. * @return Pointer to unique_ptr of the inserted child node. If insertion * fails, return nullptr. */ std::unique_ptr\u0026lt;TrieNode\u0026gt; *InsertChildNode(char key_char, std::unique_ptr\u0026lt;TrieNode\u0026gt; \u0026amp;\u0026amp;child) { if (HasChild(key_char) || child-\u0026gt;GetKeyChar() != key_char) { return nullptr; } children_[key_char] = std::move(child); return \u0026amp;(children_[key_char]); } /** * TODO(P0): Add implementation * * @brief Get the child node given its key char. If child node for given key * char does not exist, return nullptr. * * @param key Key of child node * @return Pointer to unique_ptr of the child node, nullptr if child * node does not exist. */ std::unique_ptr\u0026lt;TrieNode\u0026gt; *GetChildNode(char key_char) { if (!HasChild(key_char)) { return nullptr; } return \u0026amp;(children_.find(key_char)-\u0026gt;second); } /** * @brief Given a key char, if this child node already exists, return it. * If not exist, insert a new node into children map and then return it. * @param key_char Key of child node * @return Pointer to unique_ptr of the child node */ std::unique_ptr\u0026lt;TrieNode\u0026gt; *GetOrCreateChildNode(char key_char) { if (!HasChild(key_char)) { return InsertChildNode(key_char, std::make_unique\u0026lt;TrieNode\u0026gt;(key_char)); } return GetChildNode(key_char); } /** * TODO(P0): Add implementation * * @brief Remove child node from children_ map. * If key_char does not exist in children_, return immediately. * * @param key_char Key char of child node to be removed */ void RemoveChildNode(char key_char) { if (!HasChild(key_char)) { return; } children_.erase(key_char); } /** * TODO(P0): Add implementation * * @brief Set the is_end_ flag to true or false. * * @param is_end Whether this trie node is ending char of a key string */ void SetEndNode(bool is_end) { is_end_ = is_end; } protected: /** Key character of this trie node */ char key_char_; /** whether this node marks the end of a key */ bool is_end_{false}; /** A map of all child nodes of this trie node, which can be accessed by each * child node\u0026#39;s key char. */ std::unordered_map\u0026lt;char, std::unique_ptr\u0026lt;TrieNode\u0026gt;\u0026gt; children_; }; /** * TrieNodeWithValue is a node that marks the ending of a key, and it can * hold a value of any type T. */ template \u0026lt;typename T\u0026gt; class TrieNodeWithValue : public TrieNode { private: /* Value held by this trie node. */ T value_; public: /** * TODO(P0): Add implementation * * @brief Construct a new TrieNodeWithValue object from a TrieNode object and * specify its value. This is used when a non-terminal TrieNode is converted * to terminal TrieNodeWithValue. * * The children_ map of TrieNode should be moved to the new TrieNodeWithValue * object. Since it contains unique pointers, the first parameter is a rvalue * reference. * * You should: * 1) invoke TrieNode\u0026#39;s move constructor to move data from TrieNode to * TrieNodeWithValue. * 2) set value_ member variable of this node to parameter `value`. * 3) set is_end_ to true * * @param trieNode TrieNode whose data is to be moved to TrieNodeWithValue * @param value */ TrieNodeWithValue(TrieNode \u0026amp;\u0026amp;trieNode, T value) : TrieNode(std::move(trieNode)), value_(value) { is_end_ = true; } /** * TODO(P0): Add implementation * * @brief Construct a new TrieNodeWithValue. This is used when a new terminal * node is constructed. * * You should: * 1) Invoke the constructor for TrieNode with the given key_char. * 2) Set value_ for this node. * 3) set is_end_ to true. * * @param key_char Key char of this node * @param value Value of this node */ TrieNodeWithValue(char key_char, T value) : TrieNode(key_char), value_(value) { is_end_ = true; } /** * @brief Destroy the Trie Node With Value object */ ~TrieNodeWithValue() override = default; /** * @brief Get the stored value_. * * @return Value of type T stored in this node */ T GetValue() const { return value_; } }; /** * Trie is a concurrent key-value store. Each key is a string and its * corresponding value can be any type. */ class Trie { private: /* Root node of the trie */ std::unique_ptr\u0026lt;TrieNode\u0026gt; root_; /* Read-write lock for the trie */ ReaderWriterLatch latch_; /** * * @brief Helper function to find the terminal node corresponding to the key * @param key Key used to traverse the trie and find correct node * @return the TrieNode if found, otherwise return nullptr */ std::unique_ptr\u0026lt;TrieNode\u0026gt; *Find(const std::string \u0026amp;key) { if (key.empty()) { return nullptr; } auto curr_node = \u0026amp;root_; for (const char \u0026amp;c : key) { if ((*curr_node)-\u0026gt;HasChild(c)) { curr_node = (*curr_node)-\u0026gt;GetChildNode(c); } else { return nullptr; } } return curr_node; } public: /** * TODO(P0): Add implementation * * @brief Construct a new Trie object. Initialize the root node with \u0026#39;\\0\u0026#39; * character. */ Trie() : root_(std::make_unique\u0026lt;TrieNode\u0026gt;(\u0026#39;\\0\u0026#39;)) {} /** * TODO(P0): Add implementation * * @brief Insert key-value pair into the trie. * * If the key is an empty string, return false immediately. * * If the key already exists, return false. Duplicated keys are not allowed * and you should never overwrite value of an existing key. * * When you reach the ending character of a key: * 1. If TrieNode with this ending character does not exist, create new * TrieNodeWithValue and add it to parent node\u0026#39;s children_ map. * 2. If the terminal node is a TrieNode, then convert it into * TrieNodeWithValue by invoking the appropriate constructor. * 3. If it is already a TrieNodeWithValue, * then insertion fails and returns false. Do not overwrite existing data with * new data. * * You can quickly check whether a TrieNode pointer holds TrieNode or * TrieNodeWithValue by checking the is_end_ flag. If is_end_ == false, then * it points to TrieNode. If is_end_ == true, it points to TrieNodeWithValue. * * @param key Key used to traverse the trie and find the correct node * @param value Value to be inserted * @return True if insertion succeeds, false if the key already exists */ template \u0026lt;typename T\u0026gt; bool Insert(const std::string \u0026amp;key, T value) { if (key.empty()) { return false; } latch_.WLock(); auto curr_node = \u0026amp;root_; for (size_t i = 0; i \u0026lt; key.size() - 1; i++) { curr_node = (*curr_node)-\u0026gt;GetOrCreateChildNode(key[i]); } char terminal_key = key[key.size() - 1]; auto terminal_node = (*curr_node)-\u0026gt;GetChildNode(terminal_key); if (terminal_node == nullptr) { // case 1: create new terminal TrieNode auto terminal_child = std::make_unique\u0026lt;TrieNodeWithValue\u0026lt;T\u0026gt;\u0026gt;(terminal_key, value); (*curr_node)-\u0026gt;InsertChildNode(terminal_key, std::move(terminal_child)); latch_.WUnlock(); return true; } if (!(*terminal_node)-\u0026gt;IsEndNode()) { // case 2 convert TrieNode into TrieNodeWithValue auto converted_node = std::make_unique\u0026lt;TrieNodeWithValue\u0026lt;T\u0026gt;\u0026gt;(std::move(*(*terminal_node)), value); (*curr_node)-\u0026gt;RemoveChildNode(terminal_key); (*curr_node)-\u0026gt;InsertChildNode(terminal_key, std::move(converted_node)); latch_.WUnlock(); return true; } // case 3 duplicate key is not allowed latch_.WUnlock(); return false; } /** * TODO(P0): Add implementation * * @brief Remove key value pair from the trie. * This function should also remove nodes that are no longer part of another * key. If key is empty or not found, return false. * * You should: * 1) Find the terminal node for the given key. * 2) If this terminal node does not have any children, remove it from its * parent\u0026#39;s children_ map. * 3) Recursively remove nodes that have no children and are not terminal node * of another key. * * @param key Key used to traverse the trie and find the correct node * @return True if the key exists and is removed, false otherwise */ bool Remove(const std::string \u0026amp;key) { if (key.empty()) { return false; } latch_.WLock(); auto *node = Find(key); if (node == nullptr || !(*node)-\u0026gt;IsEndNode()) { latch_.WUnlock(); return false; } // logically delete (*node)-\u0026gt;SetEndNode(false); // find lineage from root to terminal node std::vector\u0026lt;std::unique_ptr\u0026lt;TrieNode\u0026gt; *\u0026gt; traverses; // unique_ptr\u0026#39;s pointer,因为unique_ptr不能复制到vector中 auto *curr = \u0026amp;root_; traverses.push_back(curr); for (const char c : key) { curr = (*curr)-\u0026gt;GetChildNode(c); traverses.push_back(curr); } for (size_t i = traverses.size() - 1; i \u0026gt;= 1; i--) { auto child_node = traverses[i]; auto parent_node = traverses[i - 1]; if (!(*child_node)-\u0026gt;IsEndNode() \u0026amp;\u0026amp; !(*child_node)-\u0026gt;HasChildren()) { // remove nodes that has no children and is not terminal node. // 一个非终端节点且没有任何子节点，是需要被物理删除的 (*parent_node)-\u0026gt;RemoveChildNode((*child_node)-\u0026gt;GetKeyChar()); } else { break; } } latch_.WUnlock(); return true; } /** * TODO(P0): Add implementation * * @brief Get the corresponding value of type T given its key. * If key is empty, set success to false. * If key does not exist in trie, set success to false. * If the given type T is not the same as the value type stored in * TrieNodeWithValue (ie. GetValue\u0026lt;int\u0026gt; is called but terminal node holds * std::string), set success to false. * * To check whether the two types are the same, dynamic_cast * the terminal TrieNode to TrieNodeWithValue\u0026lt;T\u0026gt;. If the casted result * is not nullptr, then type T is the correct type. * * @param key Key used to traverse the trie and find the correct node * @param success Whether GetValue is successful or not * @return Value of type T if type matches */ template \u0026lt;typename T\u0026gt; T GetValue(const std::string \u0026amp;key, bool *success) { latch_.RLock(); *success = false; auto terminal_node = Find(key); if (terminal_node == nullptr || !(*terminal_node)-\u0026gt;IsEndNode()) { latch_.RUnlock(); return {}; } auto *node = terminal_node-\u0026gt;get(); auto *casted_node = dynamic_cast\u0026lt;TrieNodeWithValue\u0026lt;T\u0026gt; *\u0026gt;(node); if (casted_node == nullptr) { // type T incompatible latch_.RUnlock(); return {}; } *success = true; latch_.RUnlock(); return casted_node-\u0026gt;GetValue(); } }; } // namespace bustub ","permalink":"https://dueplay.github.io/posts/bustub-project0/","summary":"概览 需要实现一个数据结构为Trie树的kv存储，Trie一种高效的有序树数据结构，用于检索给定键的值。Trie中的每个节点存储一个key的单个字符，并且可以很多字节点，子节点代表key的下一个字符。key的末尾字符的节点(终端节点)会用一个flag标记这是一个key的结束，并存储相应的val。\n下面这个Trie树，有ab-\u0026gt;1,ac-\u0026gt;“val”，两个kv对，注意val可以是任何类型。\n实现 TrieNode TrieNode类代表树中的单个节点，代表一个key中的单个char。一个TrieNode可以有很多子节点，因此用unordered_map来存储每个子节点的字符和子节点指针的映射。此外还需要一个flag来表示该节点是否是一个key的结尾。为了避免内存泄露，采用智能指针。\nTrieNodeWithValue 该类代表一个key的终端节点，它继承了TrieNode，并且增加了自己特有的属性，即需要存储的val.\n可以有两种方式来创建终端节点：\n插入一个key，创建一个新的终端节点。 插入一个key，将非终端节点转换为终端节点，即将TrieNode转为TrieNodeWithValue。因此需要给该类实现一个TrieNodeWithValue(TrieNode \u0026amp;\u0026amp;trieNode, T value)有参构造，用于将已有的非终端节点转为终端节点，这个构造需要去调用TrieNode的移动构造将trieNode的资源转移到终端节点，包括表示的字符和子节点map。 Trie 成员变量有root节点的指针，指向一个根节点(用字符‘\\0’标识)；为了支持并发，还需要一个读写锁 ReaderWriterLatch latch_\n需要实现增删查三个功能\nInsert 插入一个kv对到Trie中，一个key的每个字符都是一个节点，因此需要做的就是从root节点开始，一层一层的插入新节点，如果有该字符的节点了，我们应该重用它。key最后一个字符需要特殊处理，而不是直接在父节点中插入新节点。\n需要判断是否该结尾字符已经在Trie树中，如果是，再判断这个节点是不是一个终端节点，如果是终端节点，则插入失败，因为不支持重复的key，如果不是终端节点，则需要将非终端的TrieNode转为终端节点TrieNodeWithValue。\n如果结尾字符不在Trie树中，创建新的TrieNodeWithValue，然后插入到父节点中，插入完成。\n同时在Insert操作中，应该是上写锁，返回时应该解锁。\nRemove 移除给定key的val，同时需要删除一些没用节点。首先是根据这个key从root开始一层一层遍历，找到该key的终端节点，没有该key对应的终端节点则直接返回false。找到终端节点后，将其flag设为false，表示这不是一个终端节点，逻辑上删除这个kv。下一步我们需要从该节点开始向上递归的删除那些没有任何子节点的非终端节点，因为这些节点肯定是不再会被用到的，既不是一个key的结尾，也不是一个key的中间节点。实现上可以通过从root开始将遍历到该节点的路径保存，然后在路径中从后往前遍历每个节点，判断是否属于这种情况，是则在其父节点的map中移除。\n同样的在Remove操作中，应该是上写锁，返回时应该解锁。\nGetValue 返回指定key对应的val，注意这个val的类型是任意的，所以这是一个函数模板。还是首先从根节点开始一层一层遍历key的每个字符找到最后一个字符所在的节点，然后不是终端节点或者没有该节点，失败直接返回。有这个key所对应的终端节点，那么返回这个终端节点的val。这样就ok了吗？其实不是，由于val是任意类型的，所以还需要判断这个val是不是我们所要的val类型。要检查这两个类型是否相同，将终端 TrieNode 通过dynamic_cast转为 TrieNodeWithValue。 如果转换结果不是 nullptr，则类型 T 是正确的类型。在类型不匹配时，即使有key所对应的终端节点，也应该失败直接返回。只有在类型匹配时，才正确返回其val。\n同样的在GetValue操作中，应该是上读锁，返回时应该解锁。\nReaderWriterLatch 在c++中可以通过std::shared_mutex mutex_很容易得实现一个读写锁。在bustub中已经有一个实现好的读写锁，上写锁mutex_.lock() ,上读锁mutex_.lock_shared(),对应的解锁操作分别是：mutex_.unlock() 和mutex_.unlock_shared()。\n源码 //===----------------------------------------------------------------------===// // // BusTub // // p0_trie.h // // Identification: src/include/primer/p0_trie.h // // Copyright (c) 2015-2022, Carnegie Mellon University Database Group // //===----------------------------------------------------------------------===// #pragma once #include \u0026lt;memory\u0026gt; #include \u0026lt;stdexcept\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026#34;common/exception.","title":"bustub project0"},{"content":"文件目录结构 $ tree . ├── add.c ├── div.c ├── head.h ├── main.c ├── mult.c └── sub.c # 指定使用的 cmake 的最低版本，可选，非必须，如果不加可能会有警告 cmake_minimum_required(VERSION 3.0) # 定义工程名称，并可指定工程的版本、工程描述、web主页地址、支持的语言 project(CALC) # 定义工程会生成一个可执行程序，语法add_executable(可执行程序名 源文件名称) add_executable(app add.c div.c main.c mult.c sub.c) # 定义变量，语法: set(VAR VALUE [CACHE TYPE DOCSTRING [FORCE]]).[]里是可选的 # eg.将文件名对应字符串存起来。 # 方式1: 各个源文件之间使用空格间隔 # set(SRC_LIST add.c div.c main.c mult.c sub.c) # 方式2: 各个源文件之间使用分号 ; 间隔 set(SRC_LIST add.c;div.c;main.c;mult.c;sub.c) add_executable(app ${SRC_LIST}) # 指定c++标准 # 使用g++时: $ g++ *.cpp -std=c++11 -o app # C++标准对应有一宏叫做DCMAKE_CXX_STANDARD，在CMake中想要指定C++标准有两种方式： # 在cmakelists.txt中通过 set 命令指定 # 增加-std=c++11 set(CMAKE_CXX_STANDARD 11) # 增加-std=c++14 set(CMAKE_CXX_STANDARD 14) # 增加-std=c++17 set(CMAKE_CXX_STANDARD 17) # 在执行 cmake 命令的时候指定出这个宏的值，-D表示定义宏 #增加-std=c++11 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=11 #增加-std=c++14 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=14 #增加-std=c++17 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=17 # 指定输出的路径，在CMake中指定可执行程序输出的路径，也对应一个宏，叫做EXECUTABLE_OUTPUT_PATH，它的值还是通过set命令进行设置 set(HOME /home/gxj/Linux/Sort) set(EXECUTABLE_OUTPUT_PATH ${HOME}/bin) # 第一行：定义一个变量用于存储一个绝对路径 # 第二行：将拼接好的路径值设置给EXECUTABLE_OUTPUT_PATH宏 # 如果这个路径中的子目录不存在，会自动生成，无需自己手动创建 # 使用相对路径时，./表示生成的makefile所在目录 # 搜索文件 # 如果一个项目里边的源文件很多，在编写CMakeLists.txt文件的时候不可能将项目目录的各个文件一一罗列出来，这样太麻烦也不现实。所以，在CMake中为我们提供了搜索文件的命令，可以使用aux_source_directory命令或者file命令。 # 使用aux_source_directory 命令可以查找某个路径下的所有源文件，命令格式为： aux_source_directory(\u0026lt; dir \u0026gt; \u0026lt; variable \u0026gt;) dir：要搜索的目录 variable：将从dir目录下搜索到的源文件列表存储到该变量中 # 搜索 src 目录下的源文件 aux_source_directory(${CMAKE_CURRENT_SOURCE_DIR}/src SRC_LIST) add_executable(app ${SRC_LIST}) # 使用file 命令 (当然，除了搜索以外通过 file 还可以做其他事情) file(GLOB/GLOB_RECURSE 变量名 要搜索的文件路径和文件类型) GLOB: 将指定目录下搜索到的满足条件的所有文件名生成一个列表，并将其存储到变量中。 GLOB_RECURSE：递归搜索指定目录，将搜索到的满足条件的文件名生成一个列表，并将其存储到变量中。 搜索当前目录的src目录下所有的源文件，并存储到变量中 file(GLOB MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) file(GLOB MAIN_HEAD ${CMAKE_CURRENT_SOURCE_DIR}/include/*.h) CMAKE_CURRENT_SOURCE_DIR 宏表示当前访问的 CMakeLists.txt 文件所在的路径。 要搜索的文件路径和类型可加双引号，也可不加: file(GLOB MAIN_HEAD \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/src/*.h\u0026#34;) # 包含头文件 # 在编译项目源文件的时候，很多时候都需要将源文件对应的头文件路径指定出来，这样才能保证在编译过程中编译器能够找到这些头文件，并顺利通过编译。在CMake中设置要包含的目录也很简单，通过include_directories命令 include_directories(headpath) # 指定就是头文件的路径为项目根目录下面的include include_directories(${PROJECT_SOURCE_DIR}/include) PROJECT_SOURCE_DIR宏对应的值就是我们在使用cmake命令时，后面紧跟的目录，一般是工程的根目录。 # 制作动态库或静态库，源代码并不需要将他们编译生成可执行程序，而是生成一些静态库或动态库提供给第三方使用，下面来是在cmake中生成这两类库文件的方法。 # 在cmake中，如果要制作静态库，需要使用的命令如下：静态库名字分为三部分：lib+库名字+.a，此处只需要指定出库的名字就可以了 add_library(库名称 STATIC 源文件1 [源文件2] ...) # eg include_directories(${PROJECT_SOURCE_DIR}/include) file(GLOB SRC_LIST \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp\u0026#34;) add_library(calc STATIC ${SRC_LIST}) # 要制作动态库，需要使用的命令如下，动态库名字分为三部分：lib+库名字+.so，此处只需要指定出库的名字就可以了，另外两部分在生成该文件的时候会自动填充。 add_library(库名称 SHARED 源文件1 [源文件2] ...) add_library(calc SHARED ${SRC_LIST}) # 指定库输出的路径 # 方式1 - 适用于动态库 对于生成的库文件来说和可执行程序一样都可以指定输出路径。由于在Linux下生成的动态库默认是有执行权限的，所以可以按照生成可执行程序的方式去指定它生成的目录： # 设置动态库生成路径，其实就是通过set命令给EXECUTABLE_OUTPUT_PATH宏设置了一个路径，这个路径就是可执行文件生成的路径 set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) add_library(calc SHARED ${SRC_LIST}) # 方式2 - 都适用 由于在Linux下生成的静态库默认不具有可执行权限，所以在指定静态库生成的路径的时候就不能使用EXECUTABLE_OUTPUT_PATH宏了，而应该使用LIBRARY_OUTPUT_PATH，这个宏对应静态库文件和动态库文件都适用。 # 设置动态库/静态库生成路径 set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) # 生成动态库 #add_library(calc SHARED ${SRC_LIST}) # 生成静态库 add_library(calc STATIC ${SRC_LIST}) # 包含库文件 # 链接静态库的命令如下：参数1：指定出要链接的静态库的名字，可以是全名 libxxx.a，也可以是掐头（lib）去尾（.a）之后的名字 xxx。参数2-N：要链接的其它静态库的名字 link_libraries(\u0026lt;static lib\u0026gt; [\u0026lt;static lib\u0026gt;...]) 如果该静态库不是系统提供的（自己制作或者使用第三方提供的静态库）可能出现静态库找不到的情况，此时可以将静态库的路径也指定出来： link_directories(\u0026lt;lib path\u0026gt;) # 包含静态库路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 链接静态库 link_libraries(calc) # 链接动态库，使用 target_link_libraries 命令就可以链接动态库，也可以链接静态库文件。 target_link_libraries( \u0026lt;target\u0026gt; \u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt; \u0026lt;item\u0026gt;... [\u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt; \u0026lt;item\u0026gt;...]...) target：指定要加载动态库的文件的名字该文件可能是一个源文件,or动态库文件or可执行文件 PRIVATE|PUBLIC|INTERFACE：动态库的访问权限，默认为PUBLIC 如果各个动态库之间没有依赖关系，无需做任何设置，三者没有没有区别，一般无需指定，使用默认的 PUBLIC 即可。 PUBLIC：在public后面的库会被Link到前面的target中，并且里面的符号也会被导出，提供给第三方使用。 PRIVATE：在private后面的库仅被link到前面的target中，并且终结掉，第三方不能感知你调了啥库 INTERFACE：在interface后面引入的库不会被链接到前面的target中，只会导出符号。 动态库的链接和静态库是完全不同的： 静态库会在生成可执行程序的链接阶段被打包到可执行程序中，所以可执行程序启动，静态库就被加载到内存中了。 动态库在生成可执行程序的链接阶段不会被打包到可执行程序中，当可执行程序被启动并且调用了动态库中的函数的时候，动态库才会被加载到内存 因此，在cmake中指定要链接的动态库的时候，应该将命令写到生成了可执行文件之后： # 添加并指定最终生成的可执行程序名 add_executable(app ${SRC_LIST}) # 指定可执行程序要链接的动态库名字 target_link_libraries(app pthread) app: 对应的是最终生成的可执行程序的名字 pthread：这是可执行程序要加载的动态库，这个库是系统提供的线程库，全名为libpthread.so，在指定的时候一般会掐头（lib）去尾（.so）。 # 链接第三方动态库，假设在测试文件main.cpp中既使用了自己制作的动态库libcalc.so又使用了系统提供的线程库，此时CMakeLists.txt文件可以这样写：、 cmake_minimum_required(VERSION 3.0) project(TEST) file(GLOB SRC_LIST ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) include_directories(${PROJECT_SOURCE_DIR}/include) add_executable(app ${SRC_LIST}) target_link_libraries(app pthread calc) pthread、calc都是可执行程序app要链接的动态库的名字。当可执行程序app生成之后并执行该文件，会提示有如下错误信息： error while loading shared libraries: libcalc.so: cannot open shared object file: No such file or directory 这是因为可执行程序启动之后，去加载calc这个动态库，但是不知道这个动态库被放到了什么位置，所以就加载失败了，在 CMake 中可以在生成可执行程序之前，通过命令指定出要链接的动态库的位置，指定静态库位置使用的也是这个命令： link_directories(path) 修改之后的CMakeLists.txt文件应该是这样的： cmake_minimum_required(VERSION 3.0) project(TEST) file(GLOB SRC_LIST ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) # 指定源文件或者动态库对应的头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 指定要链接的动态库的路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加并生成一个可执行程序 add_executable(app ${SRC_LIST}) # 指定要链接的动态库 target_link_libraries(app pthread calc) # 日志，在CMake中可以用message显示一条消息 message([STATUS|WARNING|AUTHOR_WARNING|FATAL_ERROR|SEND_ERROR] \u0026#34;message to display\u0026#34; ...) (无) ：重要消息 STATUS ：非重要消息 WARNING：CMake 警告, 会继续执行 AUTHOR_WARNING：CMake 警告 (dev), 会继续执行 SEND_ERROR：CMake 错误, 继续执行，但是会跳过生成的步骤 FATAL_ERROR：CMake 错误, 终止所有处理过程 CMake的命令行工具会在stdout上显示STATUS消息，在stderr上显示其他所有消息。CMake的GUI会在它的log区域显示所有消息。 CMake警告和错误消息的文本显示使用的是一种简单的标记语言。文本没有缩进，超过长度的行会回卷，段落之间以新行做为分隔符。 # 输出一般日志信息 message(STATUS \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 输出警告信息 message(WARNING \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 输出错误信息 message(FATAL_ERROR \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 变量操作 # 追加 -使用set拼接 如果使用set进行字符串拼接，对应的命令格式如下： set(变量名1 ${变量名1} ${变量名2} ...) 将从第二个参数开始往后所有的字符串进行拼接，最后将结果存储到第一个参数中，如果第一个参数中原来有数据会对原数据就行覆盖。 # eg set(TEMP \u0026#34;hello,world\u0026#34;) file(GLOB SRC_1 ${PROJECT_SOURCE_DIR}/src1/*.cpp) file(GLOB SRC_2 ${PROJECT_SOURCE_DIR}/src2/*.cpp) # 追加(拼接),将src1，src2，temp拼接为一个str存到src1中 set(SRC_1 ${SRC_1} ${SRC_2} ${TEMP}) message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) # 使用list拼接 list(APPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) list命令的功能比set要强大，字符串拼接只是它的其中一个功能，所以需要在它第一个参数的位置指定出我们要做的操作，APPEND表示进行数据追加，后边的参数和set就一样了。 # 追加(拼接),APPEND后面同set的参数一致 list(APPEND SRC_1 ${SRC_1} ${SRC_2} ${TEMP}) message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) 使用set命令可以创建一个list。一个在list内部是一个由分号;分割的一组字符串。例如，set(var a b c d e)命令将会创建一个list:a;b;c;d;e，但是最终打印变量值的时候得到的是abcde。 set(tmp1 a;b;c;d;e) set(tmp2 a b c d e) message(${tmp1}) message(${tmp2}) 输出的结果: abcde abcde # 字符串移除 在当前这么目录有五个源文件，其中main.cpp是一个测试文件。如果我们想要把计算器相关的源文件生成一个动态库给别人使用，那么只需要add.cpp、div.cp、mult.cpp、sub.cpp这四个源文件就可以了。此时，就需要将main.cpp从搜索到的数据中剔除出去，想要实现这个功能，也可以使用list list(REMOVE_ITEM \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; [\u0026lt;value\u0026gt; ...]) 通过上面的命令原型可以看到删除和追加数据类似，只不过是第一个参数变成了REMOVE_ITEM。 cmake_minimum_required(VERSION 3.0) project(TEST) set(TEMP \u0026#34;hello,world\u0026#34;) file(GLOB SRC_1 ${PROJECT_SOURCE_DIR}/*.cpp) # 移除前日志 message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) # 移除 main.cpp list(REMOVE_ITEM SRC_1 ${PROJECT_SOURCE_DIR}/main.cpp) # 移除后日志 message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) 可以看到，在第8行把将要移除的文件的名字指定给list就可以了。但是一定要注意通过 file 命令搜索源文件的时候得到的是文件的绝对路径（在list中每个文件对应的路径都是一个item，并且都是绝对路径），那么在移除的时候也要将该文件的绝对路径指定出来才可以，否是移除操作不会成功。 关于list命令还有其它功能，但是并不常用，在此就不一一进行举例介绍了。 获取 list 的长度。 list(LENGTH \u0026lt;list\u0026gt; \u0026lt;output variable\u0026gt;) LENGTH：子命令LENGTH用于读取列表长度 \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;output variable\u0026gt;：新创建的变量，用于存储列表的长度。 读取列表中指定索引的的元素，可以指定多个索引 list(GET \u0026lt;list\u0026gt; \u0026lt;element index\u0026gt; [\u0026lt;element index\u0026gt; ...] \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;element index\u0026gt;：列表元素的索引 从0开始编号，索引0的元素为列表中的第一个元素； 索引也可以是负数，-1表示列表的最后一个元素，-2表示列表倒数第二个元素，以此类推 当索引（不管是正还是负）超过列表的长度，运行会报错 \u0026lt;output variable\u0026gt;：新创建的变量，存储指定索引元素的返回结果，也是一个列表。 将列表中的元素用连接符（字符串）连接起来组成一个字符串 list (JOIN \u0026lt;list\u0026gt; \u0026lt;glue\u0026gt; \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;glue\u0026gt;：指定的连接符（字符串） \u0026lt;output variable\u0026gt;：新创建的变量，存储返回的字符串 查找列表是否存在指定的元素，若果未找到，返回-1 list(FIND \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;value\u0026gt;：需要再列表中搜索的元素 \u0026lt;output variable\u0026gt;：新创建的变量 如果列表\u0026lt;list\u0026gt;中存在\u0026lt;value\u0026gt;，那么返回\u0026lt;value\u0026gt;在列表中的索引 如果未找到则返回-1。 将元素追加到列表中 list (APPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) 在list中指定的位置插入若干元素 list(INSERT \u0026lt;list\u0026gt; \u0026lt;element_index\u0026gt; \u0026lt;element\u0026gt; [\u0026lt;element\u0026gt; ...]) 将元素插入到列表的0索引位置 list (PREPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) 将列表中最后元素移除 list (POP_BACK \u0026lt;list\u0026gt; [\u0026lt;out-var\u0026gt;...]) 将列表中第一个元素移除 list (POP_FRONT \u0026lt;list\u0026gt; [\u0026lt;out-var\u0026gt;...]) 将指定的元素从列表中移除 list (REMOVE_ITEM \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; [\u0026lt;value\u0026gt; ...]) 将指定索引的元素从列表中移除 list (REMOVE_AT \u0026lt;list\u0026gt; \u0026lt;index\u0026gt; [\u0026lt;index\u0026gt; ...]) 移除列表中的重复元素 list (REMOVE_DUPLICATES \u0026lt;list\u0026gt;) 列表翻转 list(REVERSE \u0026lt;list\u0026gt;) 列表排序 list (SORT \u0026lt;list\u0026gt; [COMPARE \u0026lt;compare\u0026gt;] [CASE \u0026lt;case\u0026gt;] [ORDER \u0026lt;order\u0026gt;]) COMPARE：指定排序方法。有如下几种值可选： STRING:按照字母顺序进行排序，为默认的排序方法 FILE_BASENAME：如果是一系列路径名，会使用basename进行排序 NATURAL：使用自然数顺序排序 CASE：指明是否大小写敏感。有如下几种值可选： SENSITIVE: 按照大小写敏感的方式进行排序，为默认值 INSENSITIVE：按照大小写不敏感方式进行排序 ORDER：指明排序的顺序。有如下几种值可选： ASCENDING:按照升序排列，为默认值 DESCENDING：按照降序排列 # 宏定义 #ifdef DEBUG printf(\u0026#34;我是一个程序猿, 我不会爬树...\\n\u0026#34;); #endif 为了让测试更灵活，我们可以不在代码中定义所需定义的宏，而是在测试的时候去把它定义出来，其中一种方式就是在gcc/g++命令中去指定 $ gcc test.c -DDEBUG -o app 在gcc/g++命令中通过参数 -D指定出要定义的宏的名字，这样就相当于在代码中定义了一个宏，其名字为DEBUG。 在CMake中我们也可以做类似的事情，对应的命令叫做add_definitions: add_definitions(-D宏名称) # 自定义 DEBUG 宏 add_definitions(-DDEBUG) add_executable(app ./test.c) # cmake预定义宏 宏\t功能 PROJECT_SOURCE_DIR\t使用cmake命令后紧跟的目录，一般是工程的根目录 PROJECT_BINARY_DIR\t执行cmake命令的目录 CMAKE_CURRENT_SOURCE_DIR\t当前处理的CMakeLists.txt所在的路径 CMAKE_CURRENT_BINARY_DIR\ttarget 编译目录 EXECUTABLE_OUTPUT_PATH\t重新定义目标二进制可执行文件的存放位置 LIBRARY_OUTPUT_PATH\t重新定义目标链接库文件的存放位置 PROJECT_NAME\t返回通过PROJECT指令定义的项目名称 CMAKE_BINARY_DIR\t项目实际构建路径，假设在build目录进行的构建，那么得到的就是这个目录的路径 执行cmake # 在CMakeLists.txt所在目录执行 $ cmake . # 在build目录执行 $ cmake .. CMake 3.11 FetchContent模块 FetchContent 是 CMake 3.11 及以上版本中引入的一个功能，它允许你在构建时自动从外部获取依赖项，而不需要手动下载或预先安装它们。\n编写cmake： cmake_minimum_required(VERSION 3.14) # 确保使用了足够新的 CMake 版本 project(MyProject VERSION 1.0) # 包含 FetchContent 模块 include(FetchContent) # 声明 GoogleTest 作为外部依赖项 FetchContent_Declare( googletest GIT_REPOSITORY https://github.com/google/googletest.git GIT_TAG release-1.10.0 # GIT_TAG 参数可以是分支名或标签，不是必须的，但它是推荐的做法，不指定下载默认分支 ) # 使外部依赖项（GoogleTest）可用 FetchContent_MakeAvailable(googletest) # 添加你的项目文件（替换为你的源文件） add_executable(my_project main.cpp) # 定义一个测试目标 enable_testing() # 添加测试可执行文件 add_executable( my_test tests/test1.cpp tests/test2.cpp ) # 链接 GoogleTest 到测试可执行文件 target_link_libraries( my_test gtest_main ) # 包含 GoogleTest 的测试 include(GoogleTest) gtest_discover_tests(my_test) 在这个示例中：\n使用 FetchContent_Declare 声明了 GoogleTest 作为一个外部依赖项，指定了其 Git 仓库地址和要使用的标签（在这个例子中是 release-1.10.0）。 通过 FetchContent_MakeAvailable 自动下载（如果需要的话）、配置和构建 GoogleTest。 创建了两个可执行文件目标：一个是主项目 my_project，另一个是测试项目 my_test。 my_test 测试可执行文件链接了 GoogleTest，并使用 gtest_discover_tests 自动发现和注册 GoogleTest 测试。 第二步：编写测试 在 tests 目录下创建测试文件（例如，test1.cpp 和 test2.cpp），并使用 GoogleTest 编写测试。\n第三步：构建和运行测试 创建一个构建目录并进入：\nmkdir build \u0026amp;\u0026amp; cd build 使用 CMake 配置项目并构建：\ncmake --build . 运行测试：\nctest 使用catch2 v3.x版本的测试cmake cmake_minimum_required(VERSION 3.14) # 确保使用的是 FetchContent 可用的 CMake 版本 project(MyProject VERSION 1.0) include_directories(${PROJECT_SOURCE_DIR}/include) # 包含 FetchContent 模块 include(FetchContent) # 使用 FetchContent_Declare 声明 Catch2 作为外部依赖项 FetchContent_Declare( Catch2 GIT_REPOSITORY https://github.com/catchorg/Catch2.git GIT_TAG v3.3.0 # or a later release ) # 使 Catch2 可用 FetchContent_MakeAvailable(Catch2) # 添加你的项目文件（示例） add_executable(my_project src/main.cpp src/sub.cpp) # 如果你有测试代码，可以像这样设置 enable_testing() # 启用测试 # 添加测试可执行文件 add_executable( my_test test/test1.cpp src/sub.cpp # 添加其他测试文件 ) # 链接 Catch2 到测试可执行文件 target_link_libraries(my_test PRIVATE Catch2::Catch2WithMain) # 为 Catch2 配置测试发现 LIST(APPEND CMAKE_MODULE_PATH ${catch2_SOURCE_DIR}/extras) include(CTest) include(Catch) CATCH_DISCOVER_TESTS(my_test) ","permalink":"https://dueplay.github.io/posts/cmake/","summary":"文件目录结构 $ tree . ├── add.c ├── div.c ├── head.h ├── main.c ├── mult.c └── sub.c # 指定使用的 cmake 的最低版本，可选，非必须，如果不加可能会有警告 cmake_minimum_required(VERSION 3.0) # 定义工程名称，并可指定工程的版本、工程描述、web主页地址、支持的语言 project(CALC) # 定义工程会生成一个可执行程序，语法add_executable(可执行程序名 源文件名称) add_executable(app add.c div.c main.c mult.c sub.c) # 定义变量，语法: set(VAR VALUE [CACHE TYPE DOCSTRING [FORCE]]).[]里是可选的 # eg.将文件名对应字符串存起来。 # 方式1: 各个源文件之间使用空格间隔 # set(SRC_LIST add.c div.c main.c mult.c sub.c) # 方式2: 各个源文件之间使用分号 ; 间隔 set(SRC_LIST add.c;div.c;main.c;mult.c;sub.c) add_executable(app ${SRC_LIST}) # 指定c++标准 # 使用g++时: $ g++ *.cpp -std=c++11 -o app # C++标准对应有一宏叫做DCMAKE_CXX_STANDARD，在CMake中想要指定C++标准有两种方式： # 在cmakelists.","title":"cmake Tutorial"},{"content":"为什么使用Protocol Buffer? 想象一下我们需要序列化/反序列化一个数据结构，有几种可行的方法：\n将原始内存数据结构保存为二进制形式。 但这是一种脆弱的方法，因为它要求读取端必须遵守完全相同的内存布局，并禁止数据格式的扩展。 编写我们自己的编码策略，例如以冒号为分隔的字符串“12:3:-23:67”，这需要我们编写编码和解析代码，这也带来了运行时开销。 将数据序列化为 XML 形式。 这是广泛使用的人类可读格式。 然而，XML 由于冗长而需要大量的存储空间。 Protocol Buffer ：灵活、高效、自动化的解决方案 定义Message syntax = \u0026#34;proto3\u0026#34;; // 版本 // 相当于c++中的namespace package tutorial; // 相当于c++中的class/struct message Person { // optional 修饰符表明该字段可能被设置，也可能不被设置。当从未设置的字段中检索值时，return系统默认值，整数为0，字符串为空等。 optional string name = 1; optional int32 id = 2; optional string email =3; // 对于枚举类型，默认值是枚举类型中定义的第一个值 enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { optional string number = 1; optional PhoneType type = 2; } // repeated 修饰符相当于数组 repeated PhoneNumber phones = 4; } message AddressBook { repeated Person people = 1; } protobuf buffer message格式定义非常接近 C/C++ 中的类/结构定义。 有相当多的原始数据类型可用，例如int32、string，并且我们可以嵌套自定义数据类型，例如嵌套在PhoneNumber中的PhoneType，以及嵌套在AddressBook中的Person。\n编译Message 安装protocol buffer.在Ubuntu 22.04 LTS,通过下面方式安装\n$ sudo apt install -y protobuf-compiler 检查它的版本是否是最新的\n$ protoc --version libprotoc 3.12.4 现在我们可以将 protobuf message 格式编译成 cpp 文件。 让编译器为我们生成代码。\n$ ls addressbook.proto $ protoc --experimental_allow_proto3_optional --cpp_out=. addressbook.proto // 编译到当前目录 $ ls addressbook.pb.cc addressbook.pb.h addressbook.proto 编译器为我们生成了addressbook.ph.h和addressbook.ph.cc。 代码里包含很多我们上面刚刚定义的消息格式的 getter 和 setter 函数。\n常用的message方法 在所有版本的 protobuf 中都有一些常用的方法。\nbool IsInitialized() const: checks if all the required fields have been set. string DebugString() const: returns a human-readable representation of the message, particularly useful for debugging. void CopyFrom(const Person\u0026amp; from): overwrites the message with the given message’s values. void Clear(): clears all the elements back to the empty state. bool SerializeToString(string* output) const: serializes the message and stores the bytes in the given string. Note that the bytes are binary, not text; we only use the string class as a convenient container. bool ParseFromString(const string\u0026amp; data): parses a message from the given string. bool SerializeToOstream(ostream* output) const: writes the message to the given C++ ostream. bool ParseFromIstream(istream* input): parses a message from the given C++ istream. 例子 一个简单的程序，将新的地址信息附加到数据文件中。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;addressbook.pb.h\u0026#34; void PromptForAddress(tutorial::Person *person) { std::cout \u0026lt;\u0026lt; \u0026#34;Enter person ID number: \u0026#34;; int id; std::cin \u0026gt;\u0026gt; id; person-\u0026gt;set_id(id); std::cin.ignore(256, \u0026#39;\\n\u0026#39;); std::cout \u0026lt;\u0026lt; \u0026#34;Enter name: \u0026#34;; getline(std::cin, *person-\u0026gt;mutable_name()); std::cout \u0026lt;\u0026lt; \u0026#34;Enter email address (blank for none): \u0026#34;; std::string email; getline(std::cin, email); if (!email.empty()) { person-\u0026gt;set_email(email); } while(true) { std::cout \u0026lt;\u0026lt; \u0026#34;Enter a phone number (or leave blank to finish): \u0026#34;; std::string number; getline(std::cin, number); if (number.empty()) { break; } tutorial::Person::PhoneNumber *phone_number = person-\u0026gt;add_phones(); phone_number-\u0026gt;set_number(number); std::cout \u0026lt;\u0026lt; \u0026#34;Is this a mobile, home, or work phone? \u0026#34;; std::string type; getline(std::cin, type); if (type == \u0026#34;mobile\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::MOBILE); } else if (type == \u0026#34;home\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::HOME); } else if (type == \u0026#34;work\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::WORK); } else { std::cout \u0026lt;\u0026lt; \u0026#34;Unknown phone type. Using default.\u0026#34; \u0026lt;\u0026lt; std::endl; } } } // 从文件中读取整个地址簿，根据用户输入添加一个人，然后将其写回到同一文件中。 int main(int argc, char* argv[]) { // 验证我们链接的库的版本是否与我们编译的header的版本兼容。 GOOGLE_PROTOBUF_VERIFY_VERSION; if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage : \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; ADDRESSBOOK_FILE\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } tutorial::AddressBook address_book; std::fstream ifs(argv[1], std::ios::in | std::ios::binary); if (!ifs) { std::cout \u0026lt;\u0026lt; argv[1] \u0026lt;\u0026lt; \u0026#34;: File not found. Creating a new file.\u0026#34; \u0026lt;\u0026lt; std::endl; } else if (!address_book.ParseFromIstream(\u0026amp;ifs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to parse address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } // Add an address. PromptForAddress(address_book.add_people()); // Write the new address book back to disk. std::fstream ofs(argv[1], std::ios::out | std::ios::binary | std::ios::trunc); if (!address_book.SerializeToOstream(\u0026amp;ofs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to serialize address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } // 可选: 删除 libprotobuf 分配的所有全局对象。 google::protobuf::ShutdownProtobufLibrary(); return 0; } 读二进制文件中的消息\n读上面写的数据文件并展示里面包含的所有信息.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;addressbook.pb.h\u0026#34; void ListPeople(tutorial::AddressBook\u0026amp; address_book) { for (int i = 0; i \u0026lt; address_book.people_size(); i++) { const tutorial::Person\u0026amp; person = address_book.people(i); std::cout \u0026lt;\u0026lt; \u0026#34;Person ID: \u0026#34; \u0026lt;\u0026lt; person.id() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Name: \u0026#34; \u0026lt;\u0026lt; person.name() \u0026lt;\u0026lt; std::endl; if (person.has_email()) { std::cout \u0026lt;\u0026lt; \u0026#34; email address: \u0026#34; \u0026lt;\u0026lt; person.email() \u0026lt;\u0026lt; std::endl; } for (int j = 0; j \u0026lt; person.phones_size(); j++) { const tutorial::Person::PhoneNumber\u0026amp; phone_number = person.phones(j); switch (phone_number.type()) { case tutorial::Person::MOBILE: std::cout \u0026lt;\u0026lt; \u0026#34; Mobile phone #: \u0026#34;; break; case tutorial::Person::HOME: std::cout \u0026lt;\u0026lt; \u0026#34; Home phone #: \u0026#34;; break; case tutorial::Person::WORK: std::cout \u0026lt;\u0026lt; \u0026#34; Work phone #: \u0026#34;; break; } std::cout \u0026lt;\u0026lt; phone_number.number() \u0026lt;\u0026lt; std::endl; } } } // 从文件中读取整个地址簿并打印其中的所有信息。 int main(int argc, char* argv[]) { // 验证我们链接的库的版本是否与我们编译的header的版本兼容。 GOOGLE_PROTOBUF_VERIFY_VERSION; if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage : \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; ADDRESSBOOK_FILE\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } tutorial::AddressBook address_book; std::fstream ifs(argv[1], std::ios::in | std::ios::binary); if (!address_book.ParseFromIstream(\u0026amp;ifs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to parse address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } ListPeople(address_book); // 可选: 删除 libprotobuf 分配的所有全局对象。 google::protobuf::ShutdownProtobufLibrary(); return 0; } 编译运行 $ g++ -std=c++14 writer.cpp addressbook.pb.cc -o writer -lpthread -lprotobuf $ g++ -std=c++14 reader.cpp addressbook.pb.cc -o reader -lpthread -lprotobuf ","permalink":"https://dueplay.github.io/posts/protocol-buffer/","summary":"为什么使用Protocol Buffer? 想象一下我们需要序列化/反序列化一个数据结构，有几种可行的方法：\n将原始内存数据结构保存为二进制形式。 但这是一种脆弱的方法，因为它要求读取端必须遵守完全相同的内存布局，并禁止数据格式的扩展。 编写我们自己的编码策略，例如以冒号为分隔的字符串“12:3:-23:67”，这需要我们编写编码和解析代码，这也带来了运行时开销。 将数据序列化为 XML 形式。 这是广泛使用的人类可读格式。 然而，XML 由于冗长而需要大量的存储空间。 Protocol Buffer ：灵活、高效、自动化的解决方案 定义Message syntax = \u0026#34;proto3\u0026#34;; // 版本 // 相当于c++中的namespace package tutorial; // 相当于c++中的class/struct message Person { // optional 修饰符表明该字段可能被设置，也可能不被设置。当从未设置的字段中检索值时，return系统默认值，整数为0，字符串为空等。 optional string name = 1; optional int32 id = 2; optional string email =3; // 对于枚举类型，默认值是枚举类型中定义的第一个值 enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { optional string number = 1; optional PhoneType type = 2; } // repeated 修饰符相当于数组 repeated PhoneNumber phones = 4; } message AddressBook { repeated Person people = 1; } protobuf buffer message格式定义非常接近 C/C++ 中的类/结构定义。 有相当多的原始数据类型可用，例如int32、string，并且我们可以嵌套自定义数据类型，例如嵌套在PhoneNumber中的PhoneType，以及嵌套在AddressBook中的Person。","title":"Protocol Buffer的使用"},{"content":"知识点中转站！\n分布式 Raft：\n论文 翻译 Paxos：\nOpenACID Blog 最终一致性：\nDDIA 线性一致性：\nDDIA PingCAP：Raft与线性一致性 线性一致性与可串行化 CAP 定理：\nCAP定理没有帮助 顺序：\nDDIA 全序广播：\nDDIA 2PC：\nDDIA 3PC：\nDDIA ","permalink":"https://dueplay.github.io/posts/database-and-distributed-system-tags/","summary":"知识点中转站！\n分布式 Raft：\n论文 翻译 Paxos：\nOpenACID Blog 最终一致性：\nDDIA 线性一致性：\nDDIA PingCAP：Raft与线性一致性 线性一致性与可串行化 CAP 定理：\nCAP定理没有帮助 顺序：\nDDIA 全序广播：\nDDIA 2PC：\nDDIA 3PC：\nDDIA ","title":"Database and Distributed System TAGS"},{"content":"安装 ubuntu系统默认的shell是bash，可以使用echo $SHELL命令来查看当前使用的shell，zsh是bash的一个替代品，它的功能更加强大和丰富，可以使用cat /etc/shells来查看支持的shell\n如果结果中没有zsh的话就需要使用下面的命令来安装一下：\nsudo apt install zsh -y 安装字体 这里安装powerlevel10k主题推荐使用的MesloLGS-Nerd字体。\n一般在初次安装配置主题的时候会默认提示安装，但是如果没有正常安装的话也可以使用下面的内容来手动安装一下： MesloLGS字体ttf文件下载地址：\nwget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Italic.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold%20Italic.ttf 安装完成之后在系统设置或者各个软件比如终端或者VSCode上把字体设置为MesloLGS NF就可以了。\n# 将下载的字体拷贝至truetype sudo cp ttf/*.ttf /usr/share/fonts/truetype/ # 安装fontconfig sudo apt install fontconfig # 刷新字体缓存 fc-cache -fv 安装Oh-My-Zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 慢或者失败的小伙伴可以换成国内源:\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh 下载之后给install.sh添加执行权限：\nchmod +x install.sh 然后还需要修改一下安装脚本中的远程仓库地址：\n打开install.sh文件，找到以下部分：\n# Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} 将中间两行修改为下面这样，使用gitee镜像：\nREPO=${REPO:-mirrors/ohmyzsh} REMOTE=${REMOTE:-https://gitee.com/${REPO}.git} 然后保存退出，再执行一下，一般就应该安装好了。\n将系统默认shell切换为zsh\n# 切换默认shell chsh -s $(which zsh) # 确认是否切换成功 echo $SHELL 安装Zsh主题和插件 # powerlevel10k主题 git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k # zsh-autosuggestions自动提示插件 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions # zsh-syntax-highlighting语法高亮插件 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # 配置powerlevel10k，选择各种样式 p10k configure 在~/.zshrc文件启用插件和主题\n# 修改主题 ZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; # 启用插件 plugins=( git zsh-autosuggestions zsh-syntax-highlighting ) [参考文档](Linux终端环境配置 | GeekHour)\n","permalink":"https://dueplay.github.io/posts/zsh/","summary":"安装 ubuntu系统默认的shell是bash，可以使用echo $SHELL命令来查看当前使用的shell，zsh是bash的一个替代品，它的功能更加强大和丰富，可以使用cat /etc/shells来查看支持的shell\n如果结果中没有zsh的话就需要使用下面的命令来安装一下：\nsudo apt install zsh -y 安装字体 这里安装powerlevel10k主题推荐使用的MesloLGS-Nerd字体。\n一般在初次安装配置主题的时候会默认提示安装，但是如果没有正常安装的话也可以使用下面的内容来手动安装一下： MesloLGS字体ttf文件下载地址：\nwget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Italic.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold%20Italic.ttf 安装完成之后在系统设置或者各个软件比如终端或者VSCode上把字体设置为MesloLGS NF就可以了。\n# 将下载的字体拷贝至truetype sudo cp ttf/*.ttf /usr/share/fonts/truetype/ # 安装fontconfig sudo apt install fontconfig # 刷新字体缓存 fc-cache -fv 安装Oh-My-Zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 慢或者失败的小伙伴可以换成国内源:\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh 下载之后给install.sh添加执行权限：\nchmod +x install.sh 然后还需要修改一下安装脚本中的远程仓库地址：\n打开install.sh文件，找到以下部分：\n# Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} 将中间两行修改为下面这样，使用gitee镜像：\nREPO=${REPO:-mirrors/ohmyzsh} REMOTE=${REMOTE:-https://gitee.com/${REPO}.git} 然后保存退出，再执行一下，一般就应该安装好了。\n将系统默认shell切换为zsh","title":"zsh安装与配置"},{"content":"配置 Docker 使用 WSL 2 安装和设置 WSL 2 后，你需要确保 Docker Desktop 配置为使用 WSL 2。这可以通过 Docker Desktop 的设置进行：\n打开 Docker Desktop。 进入 Settings（设置）\u0026gt; General（常规）。 确认 “Use the WSL 2 based engine”（使用基于 WSL 2 的引擎）选项已经被选中。 docker使用 1. 管理镜像 拉取镜像：\ndocker pull [options] \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 例如：docker pull ubuntu:20.04\n列出镜像：\ndocker images 构建镜像：\ndocker build -t \u0026lt;image_name\u0026gt;:\u0026lt;tag\u0026gt; . 例如：docker build -t myapp:latest .\nlatest为默认tag，.表示目录\n删除镜像：\ndocker rmi \u0026lt;image\u0026gt; 例如：docker rmi myapp:latest\n2. 管理容器 运行容器：\ndocker run [options] \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 例如：docker run -d --name webserver -p 80:80 nginx\n参数解释：\n-d 选项代表 \u0026ldquo;detached mode\u0026rdquo;，也就是让 Docker 容器在后台运行。这意味着命令行将不会被阻塞在容器日志输出上，用户可以继续在同一个命令行窗口中执行其他命令。如果不使用 -d，容器的标准输出将会显示在当前终端上，且终端会一直被占用直到容器停止。\n--name 选项用来给你的容器指定一个名称，在这个例子中容器的名称被指定为 webserver。这个名称可以用于 Docker 的各种命令来引用容器，比如启动、停止、删除容器等操作。如果不指定 --name，Docker 会自动生成一个随机的名称。\n--privileged 选项给予容器额外的权限，让容器几乎拥有宿主机相同级别的权限。这通常用于容器内需要执行一些特权操作的场景，如直接访问硬件设备、加载内核模块等。使用这个选项时需要谨慎，因为它降低了容器和宿主机之间的隔离度，增加了安全风险。\n-v 或 --volume 选项可以挂载卷，这是一种将宿主机的目录或数据卷连接到容器中的方式。这使得你可以保持数据的持久性和数据共享，同时也可以用于在容器与宿主机之间传递配置文件或其他数据。\n-v [host_path]:[container_path]:[options]\n[host_path]: 宿主机上的文件系统路径，可以是绝对路径也可以是相对路径。如果该路径不存在，Docker 会自动为你创建这个目录（在使用 Docker Desktop for Windows 或 Docker Desktop for Mac 时，你可能需要额外配置共享目录权限）。 [container_path]: 容器内的挂载点，必须是绝对路径。 [options]: 可选，用于设置挂载方式，如 ro (只读)，rw (读写，默认)。 查看运行中的容器：\ndocker ps 用 docker ps -a 查看所有容器（包括未运行的）。\n停止容器：\ndocker stop \u0026lt;container_id_or_name\u0026gt; 例如：docker stop webserver\n启动容器：\ndocker start \u0026lt;container_id_or_name\u0026gt; 删除容器：\ndocker rm \u0026lt;container_id_or_name\u0026gt; 使用 -f 选项来强制删除运行中的容器：docker rm -f \u0026lt;container_id_or_name\u0026gt;\n查看容器日志：\ndocker logs \u0026lt;container_id_or_name\u0026gt; 进入运行中的容器：\ndocker exec -it \u0026lt;container_id_or_name\u0026gt; bash （对于不包含 bash 的容器，可能需要使用 sh）\n3. 网络管理 列出网络：\ndocker network ls 创建网络：\ndocker network create \u0026lt;network_name\u0026gt; 连接容器到网络：\ndocker network connect \u0026lt;network_name\u0026gt; \u0026lt;container_id_or_name\u0026gt; 断开容器与网络的连接：\ndocker network disconnect \u0026lt;network_name\u0026gt; \u0026lt;container_id_or_name\u0026gt; 4. 数据卷和持久化数据 创建卷：\ndocker volume create \u0026lt;volume_name\u0026gt; 挂载卷到容器： 使用 docker run 命令时，添加 -v 参数：\ndocker run -d -v \u0026lt;volume_name\u0026gt;:\u0026lt;container_path\u0026gt; \u0026lt;image\u0026gt; 查看所有卷：\ndocker volume ls 删除卷：\ndocker volume rm \u0026lt;volume_name\u0026gt; 每个命令都可能带有许多选项，可以通过查看 Docker 文档或运行 docker command --help 来获取更详细的信息。\n例子 1.Dockerfile\n# 每个 Dockerfile 都必须从一个已有的镜像开始。 FROM ubuntu:20.04 # label标签是用来添加元数据的，比如作者、邮箱等信息。 LABEL maintainer=\u0026#34;name@example.com\u0026#34; # RUN 指令用于执行命令行命令。 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y nginx # CMD 指令提供了容器的默认执行命令。Dockerfile 中只能有一个 CMD 指令，如果列出多个，则只有最后一个生效。 CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] # 或者不要[],CMD nginx -g daemin off # EXPOSE 指令用于指定容器在运行时监听的端口。 EXPOSE 80 # 设置环境变量。 ENV NGINX_VERSION 1.14 # ADD 和 COPY 都是用来从构建环境复制文件到镜像中。COPY 是纯粹的复制，而 ADD 提供了更多功能（例如，自动解压缩压缩文件）。 # COPY src dst COPY ./index.html /var/www/html/ ADD archive.tar /usr/src/app/ # VOLUME创建一个可以从本地主机或其他容器挂载的挂载点。 VOLUME /var/log/nginx # 设置工作目录 WORKDIR /usr/share/nginx/html # 设置用户 USER nginx 2.构建image\n# 构建 docker build -t hello-docker . # 查看有哪些镜像 docker images docker image ls 3.运行image\n# 运行 docker run --name xxx image_name # 进入容器 docker exec -it 容器id或name bash # 查看运行的容器 docker ps # 停止容器 docker stop xxx # 删除容器 docker rm xxx # 启动容器 docker start xxx ","permalink":"https://dueplay.github.io/posts/docker/","summary":"配置 Docker 使用 WSL 2 安装和设置 WSL 2 后，你需要确保 Docker Desktop 配置为使用 WSL 2。这可以通过 Docker Desktop 的设置进行：\n打开 Docker Desktop。 进入 Settings（设置）\u0026gt; General（常规）。 确认 “Use the WSL 2 based engine”（使用基于 WSL 2 的引擎）选项已经被选中。 docker使用 1. 管理镜像 拉取镜像：\ndocker pull [options] \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 例如：docker pull ubuntu:20.04\n列出镜像：\ndocker images 构建镜像：\ndocker build -t \u0026lt;image_name\u0026gt;:\u0026lt;tag\u0026gt; . 例如：docker build -t myapp:latest .\nlatest为默认tag，.表示目录\n删除镜像：\ndocker rmi \u0026lt;image\u0026gt; 例如：docker rmi myapp:latest\n2. 管理容器 运行容器：\ndocker run [options] \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 例如：docker run -d --name webserver -p 80:80 nginx","title":"Docker的使用"},{"content":"chrono库主要包含三种类型的类：时间间隔duration、时钟clocks、时间点time point\n1.duration 用来记录时间长度，可以表示几秒、几分钟、几个小时的时间间隔\n// duration的定义，定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Rep, class Period = std::ratio\u0026lt;1\u0026gt; \u0026gt; class duration; //表示Rep个Period，一个period是一个ratio类，默认为1s // ratio的定义，定义于头文件 \u0026lt;ratio\u0026gt; template\u0026lt; std::intmax_t Num, std::intmax_t Denom = 1 \u0026gt; class ratio; // 代表 Num / Denom 秒，分母默认为1，ratio\u0026lt;2\u0026gt;代表一个时钟周期是2秒 为了方便使用，在标准库中定义了一些常用的时间间隔,定义如下\n纳秒：using std::chrono::nanoseconds = duration\u0026lt;Rep*/*Rep至少 64 位的有符号整数类型*/*, std::nano\u0026gt;; std::nano 为 ratio\u0026lt;1,10e9\u0026gt; 微秒：std::chrono::microseconds\tduration\u0026lt;Rep*/*至少 55 位的有符号整数类型*/*, std::micro\u0026gt; 毫秒：std::chrono::milliseconds\tduration\u0026lt;Rep*/*至少 45 位的有符号整数类型*/*, std::milli\u0026gt; 秒： std::chrono::seconds\tduration\u0026lt;Rep*/*至少 35 位的有符号整数类型*/*\u0026gt; 分钟：std::chrono::minutes\tduration\u0026lt;Rep*/*至少 29 位的有符号整数类型*/*, std::ratio\u0026lt;60\u0026gt;\u0026gt; std::chrono::minutes m(1);//表示1m 小时：std::chrono::hours\tduration\u0026lt;Rep*/*至少 23 位的有符号整数类型*/*, std::ratio\u0026lt;3600\u0026gt;\u0026gt; 构造函数\n// 1. 拷贝构造函数 duration( const duration\u0026amp; ) = default; // 2. 通过指定时钟周期的类型来构造对象 template\u0026lt; class Rep2 \u0026gt; constexpr explicit duration( const Rep2\u0026amp; r ); // 3. 通过指定时钟周期类型，和时钟周期长度来构造对象 template\u0026lt; class Rep2, class Period2 \u0026gt; constexpr duration( const duration\u0026lt;Rep2,Period2\u0026gt;\u0026amp; d ); // 还重载了以下操作符 operator=; operator+; operator-; operator++; operator++(int); operator--; operator--(int); +=,-=,*=,/=,%=; //获取时间间隔的时钟周期个数 constexpr rep count() const; example\nstd::chrono::hour h(2);// h表示2小时的时间间隔对象 std::chrono::millisecond ms{3};// ms表示3毫秒 std::chrono::duration\u0026lt;int,ratio\u0026lt;60\u0026gt;\u0026gt; ten_m(3); // 3个60秒 std::chrono::duration\u0026lt;double,ratio\u0026lt;1,1000\u0026gt;\u0026gt; ms_(5.5); // 5.5个1ms，也计是5.5ms std::chrono::minute t1(1); std::chrono::second t2(20); std::chrono::second t3 = t1 - t2;//1m - 30s = 30s,t3为30s duration的加减运算有一定的规则，当两个duration时钟周期不相同的时候，会先统一成一种时钟，然后再进行算术运算，统一的规则如下：假设有ratio\u0026lt;x1,y1\u0026gt; 和 ratio\u0026lt;x2,y2\u0026gt;两个时钟周期，首先需要求出x1，x2的最大公约数X，然后求出y1，y2的最小公倍数Y，统一之后的时钟周期ratio为ratio\u0026lt;X,Y\u0026gt;。分子求公约，分母求公倍。因为是x1 / y1 - x2 / y2,就通分呗，化为 X/Y,x1/y1可以表示为多少个 X/Y， x2 / y2同理。\nratio\u0026lt;9, 7\u0026gt;和ratio\u0026lt;6, 5\u0026gt;，统一之后的时钟周期ratio\u0026lt;3, 35\u0026gt;，一个ratio\u0026lt;9, 7\u0026gt;就表示为15个ratio\u0026lt;3, 35\u0026gt;，而ratio\u0026lt;6, 5\u0026gt;可表示为14个ratio\u0026lt;3, 35\u0026gt;。单位就统一了。\n2.时间点 time point 一个表示时间点的类，定义如下\n该类通常配合clock一起使用\n// 定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Clock, class Duration = typename Clock::duration \u0026gt; class time_point; // Clock：此时间点time_point在此时钟Clock上计量 // 用于计量从纪元起时间的 std::chrono::duration 类型，表示从clock时间持续duration段时间的时间点 // 构造函数 // 1. 构造一个以新纪元(epoch，即：1970.1.1)作为值的对象，需要和时钟类一起使用，不能单独使用该无参构造函数 time_point(); // 2. 构造一个对象，表示一个时间点，这个时间点为从epoch开始持续d这么一个时间间隔，需要和时钟类一起使用，不能单独使用该构造函数 explicit time_point( const duration\u0026amp; d ); // 3. 拷贝构造函数，构造与t相同时间点的对象，使用的时候需要指定模板参数 template\u0026lt; class Duration2 \u0026gt; time_point( const time_point\u0026lt;Clock,Duration2\u0026gt;\u0026amp; t ); //用来获得1970年1月1日到time_point对象中记录的时间点经过的时间间隔（duration），函数原型如下： duration time_since_epoch() const; // 此外还有很多重载operator 3.时钟Clock chrono库中提供了获取当前的系统时间的时钟类，包含的时钟一共有三种：\nsystem_clock：系统的时钟，系统的时钟可以修改，甚至可以网络对时，因此使用系统时间计算时间差可能不准。 steady_clock：是固定的时钟，相当于秒表。开始计时后，时间只会增长并且不能修改，适合用于记录程序耗时 high_resolution_clock：和时钟类 steady_clock 是等价的，精度更高（是它的别名）。\n每个时钟类内部成员有time_point、duration、Rep、Period等信息，基于这些信息来获取当前时间，以及实现time_t和time_point之间的相互转换。\n在使用chrono提供的时钟类的时候，不需要创建类对象，直接调用类的静态方法就可以得到想要的时间了。\n3.1system_clock 定义\nstruct system_clock { // using 定义别名 using rep = long long; using period = ratio\u0026lt;1, 10\u0026#39;000\u0026#39;000\u0026gt;; // 100 纳秒 using duration = chrono::duration\u0026lt;rep, period\u0026gt;;//时间间隔为rep*period 100纳秒 using time_point = chrono::time_point\u0026lt;system_clock\u0026gt;; //时间点通过系统时钟做了初始化 static constexpr bool is_steady = false; _NODISCARD static time_point now() noexcept { // get current time，返回表示当前时间的时间点。 return time_point(duration(_Xtime_get_ticks())); } _NODISCARD static __time64_t to_time_t(const time_point\u0026amp; _Time) noexcept { // convert to __time64_t，将 time_point 时间点类型转换为 std::time_t 类型 return duration_cast\u0026lt;seconds\u0026gt;(_Time.time_since_epoch()).count(); } _NODISCARD static time_point from_time_t(__time64_t _Tm) noexcept { // convert from __time64_t，将 std::time_t 类型转换为 time_point 时间点类型 return time_point{seconds{_Tm}}; } }; example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; int main() { // 新纪元1970.1.1时间 std::chrono::system_clock::time_point epoch; std::chrono::duration\u0026lt;int,std::ratio\u0026lt;60 * 60 * 24\u0026gt;\u0026gt; day(1); // 新纪元1970.1.1时间 + 1天 std::chrono::system_clock::time_point ppt(day); using day_t = std::chrono::duration\u0026lt;int, std::ratio\u0026lt;60 * 60 * 24\u0026gt;\u0026gt;; // 新纪元1970.1.1时间 + 10天 // std::chrono::time_point需要指定模板参数 std::chrono::time_point\u0026lt;std::chrono::system_clock,day_t\u0026gt; t(day_t(10)); // 系统当前时间 // std::chrono::system_clock::time_point = chrono::time_point\u0026lt;system_clock\u0026gt; std::chrono::system_clock::time_point today = std::chrono::system_clock::now(); // 转换为time_t时间类型 time_t tm = std::chrono::system_clock::to_time_t(today); std::cout \u0026lt;\u0026lt; \u0026#34;今天的日期是: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm); time_t tm1 = std::chrono::system_clock::to_time_t(today+day); std::cout \u0026lt;\u0026lt; \u0026#34;明天的日期是: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm1); time_t tm2 = std::chrono::system_clock::to_time_t(epoch); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm2); time_t tm3 = std::chrono::system_clock::to_time_t(ppt); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间+1天: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm3); time_t tm4 = std::chrono::system_clock::to_time_t(t); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间+10天: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm4); } 3.2 steady_clock 想要获取程序耗时的时长，可以使用syetem_clock，因为这个时间可以跟随系统的设置发生变化。\nsteady_clock相当于秒表，只要启动就会进行时间的累加，并且不能被修改，\n定义\nstruct steady_clock { // wraps QueryPerformanceCounter using rep = long long;// 通过long long整形来记录时钟周期的个数 using period = nano;// 时钟周期为1纳秒 using duration = nanoseconds; // 时间间隔为1ns using time_point = chrono::time_point\u0026lt;steady_clock\u0026gt;; // 通过steady_clock对时间点进行初始化 static constexpr bool is_steady = true; // get current time _NODISCARD static time_point now() noexcept { // doesn\u0026#39;t change after system boot const long long _Freq = _Query_perf_frequency(); const long long _Ctr = _Query_perf_counter(); static_assert(period::num == 1, \u0026#34;This assumes period::num == 1.\u0026#34;); const long long _Whole = (_Ctr / _Freq) * period::den; const long long _Part = (_Ctr % _Freq) * period::den / _Freq; return time_point(duration(_Whole + _Part)); } }; example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; int main() { // 获取开始时间点 std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); // 需要获取程序耗时的代码段 std::cout \u0026lt;\u0026lt; \u0026#34;print 1000 stars ....\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; 1000; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;*\u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; // 获取结束时间点 std::chrono::steady_clock::time_point last = std::chrono::steady_clock::now(); // 计算差值，是一个时间间隔 auto dt = last - start; // dt.count()返回时间间隔中有多少个时钟周期 std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() \u0026lt;\u0026lt; \u0026#34;纳秒\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() / (double)1000000 \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; std::endl; } 3.3 high_resolution_clock high_resolution_clock提供的时钟精度比system_clock要高，它也是不可以修改的。在底层源码中，这个类其实是steady_clock类的别名\nusing high_resolution_clock = steady_clock; 因此使用方式和steady_clock是一样的\n4.转换函数 4.1duration_cast duration_cast是chrono库提供的一个模板函数，这个函数不属于duration类。通过这个函数可以对duration类对象内部的时钟周期Period，和周期次数的类型Rep进行修改。\n定义如下：\ntemplate \u0026lt;class ToDuration, class Rep, class Period\u0026gt; constexpr ToDuration duration_cast (const duration\u0026lt;Rep,Period\u0026gt;\u0026amp; dtn); // 返回目标类型ToDuration的时间间隔 注意：\n如果是对时钟周期进行转换：源时钟周期必须能够整除目的时钟周期（比如：小时到分钟）。 如果是对时钟周期次数的类型进行转换：低等类型默认可以向高等类型进行转换（比如：int 转 double）。 如果时钟周期和时钟周期次数类型都变了，根据第二点进行推导（也就是看时间周期次数类型）。 以上条件都不满足，那么就需要使用 duration_cast 进行显示转换，比如小的时钟周期转大的时钟周期。\nexample\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; void f(){ std::cout \u0026lt;\u0026lt; \u0026#34;print 1000 stars ....\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; 1000; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;*\u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; } int main() { // 获取开始时间点 std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); // 需要获取程序耗时的代码段 f(); // 获取结束时间点 std::chrono::steady_clock::time_point last = std::chrono::steady_clock::now(); // 计算差值，是一个为多少ns的时间间隔 auto dt = last - start; // dt.count()返回时间间隔中有多少个时钟周期 std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() \u0026lt;\u0026lt; \u0026#34;纳秒\u0026#34; \u0026lt;\u0026lt; std::endl; // 转换 // 整数时长：时钟周期纳秒转毫秒，小转大，并且是int转int，所以不能直接转，要求 duration_cast auto int_ms = std::chrono::duration_cast\u0026lt;std::chrono::milliseconds\u0026gt;(dt); // 小数时长：int转double，符合第二点，虽然是小转大但不要求 duration_cast std::chrono::duration\u0026lt;double, std::ratio\u0026lt;1, 1000\u0026gt;\u0026gt; fp_ms = dt; std::cout \u0026lt;\u0026lt; \u0026#34;f() took \u0026#34; \u0026lt;\u0026lt; fp_ms.count() \u0026lt;\u0026lt; \u0026#34; ms, \u0026#34; \u0026lt;\u0026lt; \u0026#34;or \u0026#34; \u0026lt;\u0026lt; int_ms.count() \u0026lt;\u0026lt; \u0026#34; whole milliseconds\\n\u0026#34;\u0026lt;\u0026lt; std::endl; } 4.2 time_point_cast time_point_cast也是chrono库提供的一个模板函数，这个函数不属于time_point类。函数的作用是对时间点进行转换，因为不同的时间点对象内部的时钟周期Period，和周期次数的类型Rep可能也是不同的，一般情况下它们之间可以进行隐式类型转换，也可以通过该函数显示的进行转换。\n定义：\ntemplate \u0026lt;class ToDuration, class Clock, class Duration\u0026gt; time_point\u0026lt;Clock, ToDuration\u0026gt; time_point_cast(const time_point\u0026lt;Clock, Duration\u0026gt; \u0026amp;t); example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; // 定义别名 using Clock = std::chrono::high_resolution_clock; using Ms = std::chrono::milliseconds; using Sec = std::chrono::seconds; template\u0026lt;class Duration\u0026gt; using TimePoint = std::chrono::time_point\u0026lt;Clock, Duration\u0026gt;;//clock类型为high_resolution_clock void print_ms(const TimePoint\u0026lt;Ms\u0026gt;\u0026amp; time_point) { std::cout \u0026lt;\u0026lt; time_point.time_since_epoch().count() \u0026lt;\u0026lt; \u0026#34; ms\\n\u0026#34;; } int main() { TimePoint\u0026lt;Sec\u0026gt; time_point_sec(Sec(6)); // 无精度损失, 可以进行隐式类型转换 TimePoint\u0026lt;Ms\u0026gt; time_point_ms(time_point_sec); print_ms(time_point_ms); // 6000 ms time_point_ms = TimePoint\u0026lt;Ms\u0026gt;(Ms(6789)); // error，会损失精度，不允许进行隐式的类型转换 TimePoint\u0026lt;Sec\u0026gt; sec(time_point_ms); // 显示类型转换,会损失精度。6789 truncated to 6000 time_point_sec = std::chrono::time_point_cast\u0026lt;Sec\u0026gt;(time_point_ms); print_ms(time_point_sec); // 6000 ms } ","permalink":"https://dueplay.github.io/posts/chrono/","summary":"chrono库主要包含三种类型的类：时间间隔duration、时钟clocks、时间点time point\n1.duration 用来记录时间长度，可以表示几秒、几分钟、几个小时的时间间隔\n// duration的定义，定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Rep, class Period = std::ratio\u0026lt;1\u0026gt; \u0026gt; class duration; //表示Rep个Period，一个period是一个ratio类，默认为1s // ratio的定义，定义于头文件 \u0026lt;ratio\u0026gt; template\u0026lt; std::intmax_t Num, std::intmax_t Denom = 1 \u0026gt; class ratio; // 代表 Num / Denom 秒，分母默认为1，ratio\u0026lt;2\u0026gt;代表一个时钟周期是2秒 为了方便使用，在标准库中定义了一些常用的时间间隔,定义如下\n纳秒：using std::chrono::nanoseconds = duration\u0026lt;Rep*/*Rep至少 64 位的有符号整数类型*/*, std::nano\u0026gt;; std::nano 为 ratio\u0026lt;1,10e9\u0026gt; 微秒：std::chrono::microseconds\tduration\u0026lt;Rep*/*至少 55 位的有符号整数类型*/*, std::micro\u0026gt; 毫秒：std::chrono::milliseconds\tduration\u0026lt;Rep*/*至少 45 位的有符号整数类型*/*, std::milli\u0026gt; 秒： std::chrono::seconds\tduration\u0026lt;Rep*/*至少 35 位的有符号整数类型*/*\u0026gt; 分钟：std::chrono::minutes\tduration\u0026lt;Rep*/*至少 29 位的有符号整数类型*/*, std::ratio\u0026lt;60\u0026gt;\u0026gt; std::chrono::minutes m(1);//表示1m 小时：std::chrono::hours\tduration\u0026lt;Rep*/*至少 23 位的有符号整数类型*/*, std::ratio\u0026lt;3600\u0026gt;\u0026gt; 构造函数","title":"chrono库的使用"},{"content":"Git Local 1.Check the Version $ git --version 2.Configure Git 我们通常会将 git 配置为我们在 github 上注册的用户名/电子邮件/密码。global 关键字会为系统中的每个版本库设置配置。我们可以去掉 global 关键字，只对当前仓库进行配置。\n# 配置 $ git config --global user.name \u0026#34;Dueplay\u0026#34; $ git config --global user.email \u0026#34;2289535823@qq.com\u0026#34; $ git config --global user.password \u0026#34;your passwd\u0026#34; # 查看配置 $ git config user.name Dueplay $ git config user.email 2289535823@qq.com $ git config user.password hello123 3. Initialize Git 创建一个新的 repo，并如下初始化 git 以跟踪一个文件夹：\n$ mkdir myproject \u0026amp;\u0026amp; cd myproject $ git init 在myproject有个隐藏文件夹 .git ，这是 git 为我们存储所有跟踪信息的地方。\n4. Check Status $ git status On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) index.html nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) 5.暂存新的改变到工作区 在Git中，\u0026ldquo;暂存\u0026rdquo;（Staging）指的是将工作目录中的修改或新文件添加到Git的索引中（也称为暂存区），以便随后commit这些更改。暂存的主要目的是允许选择性地commit文件而不是全部文件的修改，通过使用暂存区，可以控制哪些修改被包含在下次commit中。\n在 git 中，每个文件都可能处于两个阶段中的一个：\n已跟踪\u0026ndash;git 会主动监控该文件的任何更改，并将其作为 repo 的一部分 未跟踪\u0026ndash;虽然文件存在，但 git 会 \u0026ldquo;忽略 \u0026ldquo;它的存在和变化\n# $ git add index.html # $ git restore --staged [filename] 6.Commit Changes $ git commit -m \u0026#34;First release of Git Helloworld Project\u0026#34; 可以跳过暂存阶段，一步到位地comiit变更。不建议这样做\ngit commit -a -m [commit message] git tag 用于给 Git 中的commit打上标签（tag），这些标签通常用于标识某个特殊的commit，比如软件版本发布。标签提供了一个稳定的引用，使得方便地回溯到某个特定的commit，常用的命令选项有\n• -a：用于创建一个带注释的标签 • -m：指定标签的注释信息 • -l：列出已有的标签 7. Commit History $ git log # 精简log $ git log --oneline 8.Help git有这么多的标志选项和命令\ngit help \u0026ndash;all 会显示所有可用的 git 命令。\ngit [command] -help 会显示该命令可设置的所有标志，而 git [command] \u0026ndash;help 则会打开该命令的手册。(单\u0026ndash;和双\u0026ndash;）\n9.Git Branch 创建新分支\n$ git branch hello-world-image 查看这个仓库所有可用的分支\n$ git branch hello-world-image * master 如果我们切换master主分支，新快照就不是主分支的一部分。我们在另一个分支中的新更改不会影响主分支。\n通过 checkout 命令从主分支转移到新创建的分支：\n$ git checkout hello-world-image Switched to branch \u0026#39;hello-world-image\u0026#39; 创建和切换到新分支可一步完成\n$ git checkout -b hello-world-image 删除分支\ngit branch -d \u0026lt;branch-name\u0026gt; 如果分支有未合并的更改，Git会拒绝删除，并提醒先合并或解决冲突。当然也可以强制删除分支，包括未合并的修改。\ngit branch -D \u0026lt;branch-name\u0026gt; 注意，无法删除主分支、当前所在分支或非分支的内容\n10.Merge Branch git merge 是 Git 中用于合并不同分支的命令。将两个或多个分支的历史和更改集成到一个新的commit中的过程。合并操作通常用于将一个分支的变更合并到另一个分支，以确保这两个分支包含了相同的代码更改。假设我们对 hello-world-image 分支中的新开发非常满意，决定将其合并回主分支。注意master上是没有新提交的。\n既然要合并到主分支，我们首先要确保自己是站在主分支上的：\n$ git checkout master Switched to branch \u0026#39;master\u0026#39; # 使用merge合并分支，将指定分支中的更改合并到当前分支master $ git merge hello-world-image Updating 2daa287..c31a2c0 Fast-forward img_hello_world.png | Bin 0 -\u0026gt; 48630 bytes 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 img_hello_world.png 我们看到 git 说这次合并是 \u0026ldquo;Fast-forward\u0026rdquo;，因为它没有发现这两个分支有任何冲突，合并进行得很顺利。\n然而，生活并不总是一帆风顺。有时会发生合并冲突。\n假设现在我们回到 hello-world-image，在 index.html 中添加一行新内容。同时，我们在主分支中删除 index.html 中的一行，并在两个分支中都提交更改。\n现在，当我们尝试将此提交与主分支合并时，这种叫做Three-way Merge，冲突就会发生：\n$ git merge hello-world-image Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. 我们可以打开 index.html，看看 git 对冲突发生的原因和方式做了哪些标记：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello World!\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;bluestyle.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello world!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is the first file in my new Git Repo.\u0026lt;/p\u0026gt; \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD ======= \u0026lt;p\u0026gt;A old line in our file!\u0026lt;/p\u0026gt; \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; hello-world-image \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 我们可以选择保留 \u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD 至 ======= 之间的所有内容，或者保留 ======= 至 \u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; hello-world-image 之间的所有内容。\n在对 index.html 中的冲突部分做出选择后，我们将文件暂存并提交，以结束这次合并操作。\n$ git add index.html $ git commit -m \u0026#34;after fix the conflict\u0026#34; [master bdfc2b1] after fix the conflict 这样就完成了两个冲突分支的合并，通过 -d 标志，我们可以删除合并后的分支，以保持工作区的整洁：\n$ git branch -d hello-world-images Deleted branch hello-world-image (was 9e7a8ee). --no-ff 选项用于强制创建一个新的合并commit，即使可以执行快速前进合并，这样可以保留每个分支的独立历史\ngit merge --no-ff \u0026lt;branch-name\u0026gt; 要执行Fast-forward 合并：\ngit merge --ff \u0026lt;branch-name\u0026gt; 11.Revert revert 命令用于删除之前的提交，并将删除内容变成新的提交，而不修改日志。\n首先，我们要检查哪个提交是我们想要返回的：（使用 \u0026ndash;oneline 关键字显示简洁的 git 日志）\n$ git log --oneline bdfc2b1 (HEAD -\u0026gt; master) fix conflicts: 9e7a8ee add a line 17fd1f5 remove a line 5ec2abb a small change c31a2c0 Added image to Hello World 2daa287 Another changes 48d7a59 First release of Git Helloworld Project $ git revert 9e7a8ee --no-edit 12.Reset 用于将分支的 HEAD 指针和工作目录重置到指定的commit，可以选择是否保留未commit的更改，reset 会将 repo 全部移回之前的提交，会删除该提交和最新版本之间的所有更改。\n现在，假设我们添加了两个文件 file1.txt、file2.txt 和 file3.txt，并将它们包含在两个不同的提交中：\n$ touch file1.txt file2.txt file3.txt $ git add file1.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file1\u0026#34; $ git add file2.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file2\u0026#34; $ git add file3.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file3\u0026#34; $ git log --oneline 327ae72 (HEAD -\u0026gt; master) Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... 现在我们不需要文件 2 和文件 3，但希望保留文件 1。我们可以分别revert最近的 2 次提交，或者reset回添加 file1 的提交。\n$ git reset cf9f3bf $ git log cf9f3bf (HEAD -\u0026gt; master) Add file1 ...(more)... 警告：通常情况下，乱动版本库的提交历史是很危险的，尤其是在与他人合作时。\n如果我们知道 git 的提交哈希值，就有办法撤销reset。在前面的例子中，即使我们reset回 file1 的提交，我们仍然可以返回，因为我们知道上次添加文件 3 的提交哈希值是 327ae72。\n$ git reset 327ae72 $ git log 327ae72 (HEAD -\u0026gt; master) Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... reset其实有三个主要的选项：--soft、--mixed 和 --hard，对应于不同的重置模式\ngit reset \u0026ndash;soft ：回退 HEAD 指针到指定的commit，但保留所有的更改。即不会修改工作目录或暂存区，所有的更改都被标记为未commit的更改，可以直接重新commit\ngit reset \u0026ndash;mixed ：默认的reset模式。回退 HEAD 指针到指定的commit，并且重置暂存区，但保留工作目录中的更改。即未commit的更改会保留在工作目录，但不会被标记为暂存区的更改，需要重新add并commit\ngit reset \u0026ndash;hard ：最彻底的reset模式。回退 HEAD 指针到指定的commit，重置暂存区，并删除工作目录中未commit的更改，慎用这个玩意，因为它会永久性地删除未commit的更改\n13.Amend commit \u0026ndash;amend 可用于修改最近的提交，并交换更改其提交信息。\n它将暂存区域的改动与最新提交结合起来，并从中创建一个新提交，取代最新提交。\n例如，我们对 README.md 稍作改动，想要提交，但在提交信息中输入了不少错别字。\n$ git add README.md $ git commit -m \u0026#34;Upated: RMEADE.md (ugly typos)\u0026#34; $ git log --oneline b0dfb07 (HEAD -\u0026gt; master) Upated: RMEADE.md (ugly typos) 327ae72 Add file3 ...(more)... 我们的错别字让 git 历史看起来很糟糕。使用amend修改提交语句\n$ git commit --amend -m \u0026#34;Update: README.md (beautiful)\u0026#34; $ git log --oneline d4bf700 (HEAD -\u0026gt; master) Update: README.md (beautiful) 327ae72 Add file3 ...(more)... 14.stash git stash 是一个用于保存当前工作目录和暂存区的临时状态的命令。允许在切换分支、应用补丁或执行其他操作之前，将当前的修改存储起来，以便稍后重新应用，非常非常实用，常见的使用场景如\n\\1. 保存当前工作目录和暂存区的状态 git stash save \u0026#34;Work in progress\u0026#34; \\2. 切换到其他分支进行操作 git checkout other-branch \\3. 在其他分支进行操作 # 在 other-branch 上进行一些操作 \\4. 切回原始分支并恢复 stash git checkout original-branch git stash apply 或者，如果想同时删除 stash，可以使用：\ngit stash pop 此外，还有一些其他常用命令\ngit stash list # 显示 Git 存储库中所有存储的列表，以及有关每个存储的一些信息 git stash branch \u0026lt;branch-name\u0026gt; # 将更改应用到不同的分支 2.Git Remote 首先需要创建一个新的 github 仓库，然后上传我们目前正在开发的本地仓库，以便同步。\n为了方便起见，我们将远程仓库也命名为 myproject。\n1.与远程仓库同步 在本地项目仓库中，我们需要添加一个远程跟踪链接：\ngit remote add origin https://github.com/Dueplay/myproject.git 通过 git remote -v 检查是否与 github 上的 repo 远程同步\n$ git remote -v origin\thttps://github.com/[username]/myproject.git (fetch) origin\thttps://github.com/[username]/myproject.git (push) 然后，我们就可以将所有本地开发的内容推送到远程版本库：\ngit push：将本地更改推送到远程仓库的命令，完整格式 ：git push \u0026lt;remote\u0026gt; 是远程仓库的名称，通常是 \u0026ldquo;origin\u0026rdquo; 或其他你设置的别名。 \u0026lt;branch\u0026gt; 是本地分支的名称，它将被推送到远程仓库的同名分支。 \u0026ndash;set-upstream（或者简写为 -u）: 这部分告诉Git为本地分支与远程分支建立关联关系。关联关系的作用是在将来的推送或拉取操作中，Git会自动识别要使用的远程分支。设置关联关系后，你就可以使用git push和git pull而不需要每次都指定远程仓库和分支,只需输入 git push，Git 将自动使用关联的远程和分支。\n$ git push --set-upstream origin master Enumerating objects: 34, done. Counting objects: 100% (34/34), done. Delta compression using up to 8 threads Compressing objects: 100% (33/33), done. Writing objects: 100% (34/34), 49.37 KiB | 12.34 MiB/s, done. Total 34 (delta 17), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (17/17), done. To https://github.com/[username]/myproject.git * [new branch] master -\u0026gt; master Branch \u0026#39;master\u0026#39; set up to track remote branch \u0026#39;master\u0026#39; from \u0026#39;origin\u0026#39;. /*你的本地 master 分支现在已设置为跟踪远程仓库 \u0026#39;origin\u0026#39; 上的远程 master 分支*/ 现在，我们已将本地所有开发成果上传到远程版本库\n2.拉取远程仓库新东西到本地 现在，假设远程 repo 上出现了新情况。在此，我们将模拟这种情况，直接从 github 上的 README.md 中移除一行并提交。\n我们如何更新本地版本库以包含这些更改呢？\n我们有两个选择：\nfetch + merge pull 从第一个组合开始。我们首先需要使用 fetch 从远程下载所有新更改\n$ git fetch origin remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (1/1), done. remote: Total 3 (delta 2), reused 2 (delta 2), pack-reused 0 Unpacking objects: 100% (3/3), 689 bytes | 344.00 KiB/s, done. From https://github.com/[username]/myproject d4bf700..6d4ad42 master -\u0026gt; origin/master # 现在我们有了来自远程的新改动，可以检查一下 git 状态了： $ git status On branch master Your branch is behind \u0026#39;origin/master\u0026#39; by 1 commit, and can be fast-forwarded. (use \u0026#34;git pull\u0026#34; to update your local branch) 我们看到本地仓库比上游主仓库晚提交了 1 次，即 README.md 上的一行改动。我们可以使用 git diff 命令仔细检查具体的差异\n$ git diff origin/master diff --git a/README.md b/README.md index f3fa9a9..cf28200 100644 --- a/README.md +++ b/README.md @@ -3,3 +3,5 @@ Hello World repository for Git tutorial This is an example repository for the Git tutoial on https://www.w3schools.com This repository is built step by step in the tutorial. + +a new line 合并提交\n$ git merge origin/master Updating d4bf700..6d4ad42 Fast-forward README.md | 2 -- 1 file changed, 2 deletions(-) $ git status On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;. 现在我们的本地 git 已经是最新的了。\n上述方法可行，但有点繁琐。其实我们可以用 pull 命令一步完成更新，它是 fetch 和 merge 的结合。\n让我们把从远程 github 上的 README.md 中删除的新行添加回去，并尝试把更改拉入本地 git。\n$ git pull origin remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (3/3), done. remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 696 bytes | 232.00 KiB/s, done. From https://github.com/[username]/myproject 6d4ad42..b2bb9ae master -\u0026gt; origin/master Updating 6d4ad42..b2bb9ae Fast-forward README.md | 2 ++ 1 file changed, 2 insertions(+) 可以看到我们已经更新了远程主分支：\n$ git log --oneline b2bb9ae (HEAD -\u0026gt; master, origin/master) Add back a new line from github directly 6d4ad42 Remove the new line README.md GitHub directly d4bf700 Update: README.md (beautiful) 327ae72 Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... git pull 和 git fetch 都是用于从远程仓库获取更新的 Git 命令，但区别为\ngit fetch origin • 从远程仓库获取更新的信息，但并不自动合并或更新本地工作目录， 只是把远程分支的引用和相关对象（commit、tree等）下载到本地，需要手动合并或者在需要的时候将远程分支的变更整合到本地分支上 git pull origin master • 从远程仓库获取更新的信息，并尝试将本地工作目录自动合并到获取的更新中 • git pull 实际上包含了 git fetch，比如在执行 git fetch 之后，立即执行 git merge 也可以将远程分支的更改合并到当前本地分支 3.推送本地新修改到远程 现在，我们将通过 push 命令为远程仓库做出贡献。\n让我们在 README.md 中再添加一行，然后尝试更新远程版本库。\n$ git commit -a -m \u0026#34;Update readme locally and try push\u0026#34; [master f8986b8] Update readme locally and try push 1 file changed, 1 insertion(+) $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 1 commit. (use \u0026#34;git push\u0026#34; to publish your local commits) Git 显示我们比远程主分支早提交 1 次。让我们把更改推送到远程仓库。\n$ git push origin 4.Remote Branch Pull 可以通过github图形用户界面直接在远程仓库创建一个新分支。我们从主分支创建了一个名为 secondary 的新分支，并对 README.md 做了一些修改，直接在 github 上提交。\n我们可以将新分支拉到本地 git 并检查它：\n$ git pull remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (3/3), done. remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 697 bytes | 232.00 KiB/s, done. From https://github.com/[username]/myproject * [new branch] secondary -\u0026gt; origin/secondary Already up to date. 我们可以像往常一样通过 git 分支查看新分支。但默认情况下，它只显示本地分支。我们需要使用 -a 标志来查看所有本地和远程分支，或者使用 -r 标志来查看远程分支。\n$ git branch // only local branches * master $ git branch -a * master remotes/origin/master remotes/origin/secondary $ git branch -r origin/master origin/secondary 删除远程仓库中的分支\ngit push origin --delete \u0026lt;branch-name\u0026gt; 5.将本地分支推送到远程 我们也可以将本地新分支的变更推送到远程 repo。\n$ git checkout -b local-new-branch ... (do some changes to README.md) ... $ git commit -a -m \u0026#34;Update from local-new-branch\u0026#34; [local-new-branch 40e9ee3] Update: local-new-branch 1 file changed, 2 insertions(+) $ git push origin local-new-brancch Enumerating objects: 5, done. Counting objects: 100% (5/5), done. Delta compression using up to 8 threads Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 334 bytes | 334.00 KiB/s, done. Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (2/2), completed with 2 local objects. remote: remote: Create a pull request for \u0026#39;local-new-branch\u0026#39; on GitHub by visiting: remote: https://github.com/[username]/myproject/pull/new/local-new-branch remote: To https://github.com/[username]/myproject.git * [new branch] local-new-branch -\u0026gt; local-new-branch 现在，如果我们访问 github 远程仓库，就会发现有一个新推送的分支，名为 local-new-branch\n6.Merge Into Master 如上所述，在 github repo 页面上，我们希望将本地-新分支中的更改合并到主分支中。网页上有 \u0026quot; Compare \u0026amp; Pull Request.\u0026ldquo;选项。\n我们可以点击它并创建一个pull request请求。\n因为这是我们自己的 repo，所以我们是 \u0026ldquo;权威\u0026rdquo;，可以直接点击 \u0026ldquo;Merge pull request \u0026ldquo;将更改合并到主分支。\n但在现实生活中，拉取请求通常需要经过代码审查和测试流程，并由合作者验证。如果获得批准，拉取请求才会通过并被合并。\n7.clone and fork $ git clone [the repo url] [the folder path we want to clone into] 8.Git Ignore 我们并不一定希望 git 追踪本地仓库中的每一个文件。可能有一些日志文件、临时文件或个人文件不应该被纳入 git 工作流。\n为了解决这个问题，我们可以在 git 仓库中创建一个 .gitignore 文件，这样 git 就会忽略其中指定的文件。不过，.gitignore 文件本身会被 git 追踪。\n常见的用法包括\ncommand Description blank lines are ignored # something lines start with # is comment and ignored name All name files and folders name/ All folders called name name.file All name.file in repo *.file any file with extension .file !*.file negate any previous ignore on this file 8.remove origin 使用下面命令可将指向仓库的远程 URL 先去除，就能添加其他仓库的地址\ngit remote remove origin git remote add origin https://github.com/xxx ","permalink":"https://dueplay.github.io/posts/git/","summary":"Git Local 1.Check the Version $ git --version 2.Configure Git 我们通常会将 git 配置为我们在 github 上注册的用户名/电子邮件/密码。global 关键字会为系统中的每个版本库设置配置。我们可以去掉 global 关键字，只对当前仓库进行配置。\n# 配置 $ git config --global user.name \u0026#34;Dueplay\u0026#34; $ git config --global user.email \u0026#34;2289535823@qq.com\u0026#34; $ git config --global user.password \u0026#34;your passwd\u0026#34; # 查看配置 $ git config user.name Dueplay $ git config user.email 2289535823@qq.com $ git config user.password hello123 3. Initialize Git 创建一个新的 repo，并如下初始化 git 以跟踪一个文件夹：\n$ mkdir myproject \u0026amp;\u0026amp; cd myproject $ git init 在myproject有个隐藏文件夹 .","title":"Git Tutorial"},{"content":"ssh方式A主机免密登录B\n1.首先在A主机上执行命令\nssh-keygen -t rsa 会在执行命令的当前用户的家目录下的.ssh中生成公钥和私钥，id_rsa和id_rsa.pub分别存放私钥和公钥。\n2.将公钥加入到B主机的~/.ssh/authorized_keys文件中\nscp方式or手动复制粘贴。\nscp ~/.ssh/id_rsa.pub root@B主机ip:~/ B主机上执行：\ncat ~/id_rsa.pub\u0026gt;\u0026gt;~/.ssh/authorized_keys 3.如果不能登录检查以下注意的点和检查/etc/ssh/sshd_config，确保以下配置打开。\nRSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 需要注意的几点： 1、确保A机器私钥文件名是id_rsa，否则会因为识别不到私钥文件而不会执行免密rsa登录；\n2、确保B机器上.ssh/authorized_keys文件的属性是600，否则要使用命令、\nchmod 600 ~/.ssh/authorized_keys 更改属性。 3、authorized_keys存放的目录需要与登录用户对应，比如使用root用户登录，则是在/home/root/.ssh/authorized_keys\n","permalink":"https://dueplay.github.io/posts/ssh%E6%96%B9%E5%BC%8Fa%E4%B8%BB%E6%9C%BA%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95b/","summary":"ssh方式A主机免密登录B\n1.首先在A主机上执行命令\nssh-keygen -t rsa 会在执行命令的当前用户的家目录下的.ssh中生成公钥和私钥，id_rsa和id_rsa.pub分别存放私钥和公钥。\n2.将公钥加入到B主机的~/.ssh/authorized_keys文件中\nscp方式or手动复制粘贴。\nscp ~/.ssh/id_rsa.pub root@B主机ip:~/ B主机上执行：\ncat ~/id_rsa.pub\u0026gt;\u0026gt;~/.ssh/authorized_keys 3.如果不能登录检查以下注意的点和检查/etc/ssh/sshd_config，确保以下配置打开。\nRSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 需要注意的几点： 1、确保A机器私钥文件名是id_rsa，否则会因为识别不到私钥文件而不会执行免密rsa登录；\n2、确保B机器上.ssh/authorized_keys文件的属性是600，否则要使用命令、\nchmod 600 ~/.ssh/authorized_keys 更改属性。 3、authorized_keys存放的目录需要与登录用户对应，比如使用root用户登录，则是在/home/root/.ssh/authorized_keys","title":"配置ssh免密登录"},{"content":"一、gcc编译流程 源文件-\u0026gt;预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接-\u0026gt;可执行文件\n1.预处理：cpp，宏替换，头文件展开，去掉注释。gcc -E hello.c -o hello.i\n2.编译：将.c文件通过gcc编译成汇编语言文件。gcc -S hello.i -o hello.s\n3.汇编：将汇编文件通过汇编器as变成二进制文件。gcc -c hello.s -o hello.o\n4.链接：将hello.o中所调用的库文件通过链接器ld链接到一起，成可执行文件。gcc hello.o -o hello\n一步到位：gcc hello.c -o hello 或gcc -o hello hello.c\n生成目标文件（.o文件）gcc -c hello.c -o hello.o（不写-o就默认生成hello.o）\n二、库的制作 1.静态库 ​\t将源文件编译成目标文件 gcc -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库 ar rcs libmath.a add.o sub.o div.o mul.o\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名\n2.动态库 ​\t将源文件编译成目标文件 gcc -fpic -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库gcc -shared add.o sub.o div.o mul.o -o libmath.so\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名（链接器ld）\n3.加载动态库时报错 ​\t系统加载可执行代码时候, 能够知道其所依赖的库的名字, 但是还需要知道所依赖的库的绝对路径。此时就需要系统动态载入器ldd。\n​\t在~/.bashrc文件中添加你的动态库的路径（配置环境变量LD_LIBRARY_PATH）\n​ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:库路径\n​\n","permalink":"https://dueplay.github.io/posts/%E5%88%B6%E4%BD%9Cc%E5%BA%93/","summary":"一、gcc编译流程 源文件-\u0026gt;预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接-\u0026gt;可执行文件\n1.预处理：cpp，宏替换，头文件展开，去掉注释。gcc -E hello.c -o hello.i\n2.编译：将.c文件通过gcc编译成汇编语言文件。gcc -S hello.i -o hello.s\n3.汇编：将汇编文件通过汇编器as变成二进制文件。gcc -c hello.s -o hello.o\n4.链接：将hello.o中所调用的库文件通过链接器ld链接到一起，成可执行文件。gcc hello.o -o hello\n一步到位：gcc hello.c -o hello 或gcc -o hello hello.c\n生成目标文件（.o文件）gcc -c hello.c -o hello.o（不写-o就默认生成hello.o）\n二、库的制作 1.静态库 ​\t将源文件编译成目标文件 gcc -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库 ar rcs libmath.a add.o sub.o div.o mul.o\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名\n2.动态库 ​\t将源文件编译成目标文件 gcc -fpic -c add.c sub.c div.","title":"gcc和c库的制作"},{"content":"一、目录 1./bin：可执行二进制文件的目录，绿色是可执行文件，\n输入命名./date，date可执行文件执行。cat命令，查看文本文件内容，ctrl+c退出。\n2./boot：linux启动时用到的文件。reboot：重启。\n3./dev：存放设备文件，一切皆文件。\nsudo cat mice鼠标移动，输出。\nsudo临时获得一次管理员权限，cat是查看文件，mice是鼠标文件。\n4./etc：os相关的一些配置文件。cat passwd查看密码。\n5./home：用户的家目录会存在这。Linux系统支持多用户访问。~表示当前用户的家目录。\n6./lib：系统使用的函数库的目录。\n7./root：系统管理员的家目录。普通用户的家目录：/home/cookie。\n切换成管理员账户，sudu su。退出 exit。\n切换普通用户：su 用户名。退出 exit。\ncookie（用户名）@（at在）主机名：当前工作目录$(普通用户)#（管理员）\ncd空格 回车：回到当前用户的“家”目录，宿主目录，这个用户的所有数据。不是home。\ncd空格 - 回到上次工作目录。\n8./tmp：一般用户或正在执行的程序临时存放文件的目录。\n9./usr：unix system resource，应用程序存放目录。\n二、文件类型 linux下不以后缀名区分文件类型。ls -l 查看文件详细信息。\n普通文件-\n目录文件d\n套接字文件s\n软链接文件l\n字符设备文件c\n块设备文件b\n管道文件p\n第一个为文件类型，后面9个，三个一组，r可读，w可写，x可执行。分别为文件所有者权限，所属组权限，其他人的权限。数字2代表硬链接计数。第一个cookie为文件所有者，第二个是所属组。文件所占用的空间大小（byte），最后一次修改时间，文件名。\ngedit 文件名：用记事本编辑文件。\n三、命令 命令格式：命令 -可选 参数\n查看帮助文档：ls \u0026ndash;help；man 1 xxx：1是标准命令，2是系统调用，3是库函数\nctrl+p/n 上/下一条命令\nctrl+u 清空\nctrl+b 光标向前移动一个字符\nctrl+a 光标移动到最前\nctrl+e 光标移动到最后\n通配符：ls std*.h ls std??.h *代表一堆，？代表一个字符。\n输出重定向：\u0026gt;\n追加\u0026raquo;\n删除：rm -f强制删 ；rm -r 递归删（无敌），删目录时必须用这个。\n建立链接文件ln\n查看或合并文件内容：cat，合并要借助重定向。\n拷贝文件：cp 文件名 目录/新名字\n拷贝目录，cp -a保留原有文件格式，创建时间没变；cp -r递归的拷贝，重新创建新的。\n移动文件：mv（移动文件和改名作用） mv 文件名 目录（目录不存在则把文件名改为目录的名字）\nfile：查看文件类型。\n归档管理（压缩打包）：tar zcvf（gzip格式压缩） xxx.tar.gz（压缩包名） yyy1 yyy2 yyy3（yyy为打包材料）\ntar.gz可以不加，但不直观。 z是gzip方式压缩，c是创建，v是展示压缩列表啥东西被打包了，f是指定压缩文件名。\ntar jcvf（bzip2格式压缩） xxx.tar.bz2（压缩包名） yyy1 yyy2 yyy3（yyy为打包材料）\n解压：tar z(j)xvf 压缩包名\n查看命令位置：which ls\n修改文件权限：r：4 w：2 x：1\n7==rwx 5==w-x\nchmod 755 file1\n修改目录里面的所有文件的权限\nchmod 777 dir -R：将dir里面的文件权限全部改为rwx\n查看进程：ps aux\n杀掉经常：kill -9 进程id\ngcc 编译流程 源代码通过编译器编译生成汇编代码\n汇编代码通过汇编器翻译为机器码，生成目标文件\n链接器将目标文件与任何必需的库文件（如标准库）组合在一起，解析符号引用，生成最终的可执行文件。\n单步执行编译过程 运行预处理器，生成预处理后的代码\ngcc -E hello.c 运行编译器，生成汇编代码hello.s文件\ngcc -S hello.c 运行汇编器，生成目标文件hello .o文件\ngcc -c hello.s 运行链接器ld，链接目标文件到可执行文件,默认输出为a.out(assembler汇编程序的输出)\nld hello.o 在ld hello.o时，发生以下错误\nld: warning: cannot find entry symbol _start; defaulting to 0000000000401000 ld: hello.o: in function `main\u0026#39;: hello.c:(.text+0x13): undefined reference to `puts\u0026#39; 未找到入口符号（entry symbol）：ld 发出警告说它找不到程序的入口点 _start，并默认使用了一个地址。在大多数情况下，可执行文件的入口点应该是 main 函数。你可以通过指定入口点来解决这个问题。 puts 函数的未定义引用：ld 报告了 undefined reference to 'puts' 错误，这表示程序引用了 puts 函数，但没有找到该函数的定义。你需要链接标准C库以解决这个问题。 要解决这两个问题，你可以使用以下命令：\nld hello.o -e main -lc\n-e main：指定程序的入口点是 main 函数。 -lc：链接标准的C库（libc）以解决对 puts 等标准C库函数的引用问题。 -static：静态链接，不使用动态链接库。生成文件很大\nmake 启用多线程编译，以加速编译过程。\nmake -j（无数字）： 优点：尽可能快的编译速度，特别是在资源充足的环境下。 缺点：可能会过载系统，尤其是在资源有限的机器上，影响其他应用或导致系统不稳定。 make -jN（N为数字，如 make -j4）： 优点：可以精确控制并行作业的数量，适当的选择可以优化编译速度和系统稳定性的平衡。 缺点：需要手动确定最佳的作业数，可能不适应所有环境。 make -j$(nproc)： 优点：自动化地选择并行作业数，通常等于CPU核心数，适合大多数情况，既快速又不会过载系统。 缺点：在某些特殊情况下，如高度依赖磁盘I/O的项目，可能并不是最佳选择，因为磁盘I/O可能成为瓶颈。 vim 1.全选文本剪切和删除\n在normal模式（Esc），\nggvG将光标移到文件的开头，然后选择整个文件。\nx 剪切选中的文本\nd删除选中的文本\n2.剪切行：按下 dd 键。这将删除并剪切当前行。\nyy 来复制当前行，然后使用 p 将其粘贴、\n3.set nowrap 超出屏幕一行的文字不会换行\nset wrap 取消不换行的设置\nset nu 显示行号\n4.修改单个单词 cw ciw\n5.全部格式化 gg=G\nobjdump查看二进制文件 查看目标文件反汇编代码 -d反汇编的意思Disassembly\nobjdump -d xx.o strace追踪执行的系统调用 strace的输出位标准错误输出\n主要的系统调用：execve, read, write\nstrace -f gcc a.c (gcc 会启动其他进程)\n可以管道给编辑器 vim - 编辑器里还可以 %!grep (细节/技巧) strace ls |\u0026amp; grep -e read -e write 可以实现系统调用的过滤等，-e read -e write只输出包含read，write的行\ngrep反向匹配：使用 -v 选项查找不匹配模式的行。\n使用 -o 选项只显示匹配的文本，而不是整行。\n输出重定向 标准输入（STDIN）：通常表示为数字 0， 标准输出（STDOUT）：通常表示为数字 1，是大多数程序输出其执行结果的默认位置。 标准错误（STDERR）：表示为数字 2，用于输出错误信息。 在命令行中，\u0026gt; 符号用于重定向输出。2\u0026gt;\u0026amp;1 的意思是将标准错误（2）重定向到标准输出（1）的同一位置。这通常用于将程序的所有输出（包括错误和正常信息）合并到一个流中，便于进一步处理或记录。\n# 标准输出重定向到file.txt command \u0026gt; file.txt # 等同于command 1\u0026gt; file.txt， 1通常省略 command \u0026gt; file.txt 2\u0026gt;\u0026amp;1 # 有的时候我们不想看到输出信息，也不想保存输出信息，可以考虑dev下的null设备文件，所有写进去的数据都会被丢弃。 command \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 这里的 command 可以是任何命令、脚本或程序。这个命令做了以下两件事：\n\u0026gt; file.txt 将 command 的标准输出重定向到 file.txt。如果 file.txt 不存在，它将被创建；如果已存在，它将被覆盖。 2\u0026gt;\u0026amp;1 将 command 的标准错误重定向到标准输出的地方，即 file.txt。 结果，无论 command 生成的是标准输出还是错误输出，所有内容都会被写入 file.txt。\n这种重定向在脚本编写和日志记录中非常有用，特别是当你需要捕获和分析一个命令的所有输出（包括错误）时。\n一个\u0026gt;符号表示清空文件重新写入，两个\u0026gt;符号表示往文件的后面追加。\ntop top 命令是 Linux 和 Unix 系统中常用的性能监控工具，用于实时显示系统的任务管理器，提供关于系统总体性能和各个进程的详细信息。\n默认情况下，top 命令会显示以下信息：\n系统总体信息：\nuptime：系统运行时间。 用户数量：当前登录的用户数量。 负载平均值：系统在1分钟、5分钟和15分钟内的平均负载。 任务信息：任务的总数、正在运行的任务、睡眠的任务、停止的任务和僵尸任务的数量。 CPU使用率：包括用户空间、系统空间、空闲时间和其他详细信息。 内存使用情况：物理内存和交换内存的总量、使用量和可用量。 每个进程的详细信息：\n在 top 命令界面中，可以使用以下快捷键进行操作：\nq：退出 top。 h：显示帮助信息。 k：杀死一个进程。按 k，然后输入进程ID（PID）并按回车键，接着输入信号类型（默认是 15，表示正常终止）。 r：重新调整一个进程的优先级。按 r，然后输入进程ID（PID）并按回车键，接着输入新的优先级值（-20到19）。 u：按用户过滤进程。按 u，然后输入用户名。 P：按CPU使用率排序。 M：按内存使用率排序。\n-p:仅监视指定的进程ID。\ntop -p 1234 -u:按指定用户显示进程。\ntop -u username diskpart diskpart list disk select disk X # 替换 X 为你的目标磁盘编号 create partition primary size=102400 # 创建一个主分区，大小为100GB format fs=ntfs quick format fs=fat32 unit=4096 quick assign letter=D exit # 列出磁盘上的分区 list partition # 选择新创建的分区 select partition Y detail partition # 查看disk详细信息 detail disk tmux 终端复用工具\n# 安装 sudo apt install tmux # 在当前终端开一个tmux终端 tmux # 退出tmux回到终端 ctrl+b d # 新建一个新tmux并命令为ping tmux new -s ping # 查看有几个tmux tmux ls 0: 1 windows (created Thu Nov 30 21:01:43 2023) ping: 1 windows (created Thu Nov 30 21:05:51 2023) # 回到tmux0 tmux attach -t 0 # 在tmux0中切换到tmux ping中 tmux switch -t ping # 关掉tmux0 tmux kill-seesion -t 0 # 关掉tmux ping tmux kill-session -t ping netcat 检查版本：\nreadlink -f $(which nc) # $(...): 这是命令替换的语法。它执行括号里的命令，并将输出替换到外部命令中。 结果会有两种：\n/bin/nc.traditional: 默认 GNU 基础版本，一般系统自带。 /bin/nc.openbsd: openbsd 版本，强大很多。 都可以用 apt-get install nc-traditional 或者 apt-get install nc-openbsd 来选择安装。不管是 gnu 版本还是 openbsd 版本，都有新老的区别，主要是传送文件时 stdin 发生 EOF 了，老版本会自动断开，而新的 gnu/openbsd 还会一直连着\n端口测试\n你在服务器 A主机（192.168.1.2） 上面 8080 端口启动了一个服务，有没有通用的方法检测服务的 TCP 端口是否启动成功？或者在 B 主机上能不能正常访问该端口？\n进一步，如果而 A 主机上用 netstat -an 发现端口成功监听了，你在 B 主机上的客户端却无法访问，那么到底是服务错误还是网络无法到达呢？我们当然可以在 B 主机上用 telnet 探测一下：\ntelnet 192.168.1.2 8080 但 telnet 并不是专门做这事情的，还需要额外安装，所以我们在 B 主机上用 netcat：\nnc -vz 192.168.1.2 8080 即可，v 的意思是显示多点信息（verbose），z 代表不发送数据。那么如果 B 主机连不上 A 主机的 8080 端口，此时你就该检查网络和安全设置了，如果连的上那么再去查服务日志去。\nnc 命令后面的 8080 可以写成一个范围进行扫描：\nnc -v -v -w3 -z 192.168.1.2 8080-8083 两次 -v 是让它报告更详细的内容，-w3 是设置扫描超时时间为 3 秒。\n传输测试\n你在配置 iptable 或者安全组策略，禁止了所有端口，但是仅仅开放了 8080 端口，你想测试一下该设置成功与否怎么测试？安装个 nginx 改下端口，外面再用 chrome 访问下或者 telnet/curl 测试下？？还是 python -m 启动简单 http 服务 ？其实不用那么麻烦，在需要测试的 A 主机上：\nnc -l -p 8080 这样就监听了 8080 端口，然后在 B 主机上连接过去：\nnc 192.168.1.2 8080 两边就可以会话了，随便输入点什么按回车，另外一边应该会显示出来，注意，openbsd 版本 netcat 用了 -l 以后可以省略 -p 参数，写做：nc -l 8080 ，但在 GNU netcat 下面无法运行，所以既然推荐写法是加上 -p 参数，两个版本都通用。\nnc 命令作为客户端时可以使用 -p 选项指定使用哪个端口号连接服务器。\n老版本的 nc 只要 CTRL+D 发送 EOF 就会断开，新版本一律要 CTRL+C 结束，不管是服务端还是客户端只要任意一边断开了，另一端也就结束了，但是 openbsd 版本的 nc 可以加一个 -k 参数让服务端持续工作。\n那么你就可以先用 nc 监听 8080 端口，再远端检查可用，然后又再次随便监听个 8081 端口，远端检测不可用，说明你的安全策略配置成功了，完全不用安装任何累赘的服务。\n测试 UDP 会话\n两台主机 UDP 数据发送不过去，问题在哪呢？你得先确认一下两台主机之间 UDP 可以到达，这时候没有 nginx 给你用了，怎么测试呢？用 python 写个 udp 的 echo 服务？？ netcat 又登场了，在 A 主机上：\nnc -u -l -p 8080 监听 udp 的 8080 端口，然后 B 主机上连上去：\nnc -u 192.168.1.2 8080 然后像前面测试 tcp 的方法进行检测，结束了 CTRL+C 退出，看看一边输入消息另外一边能否收到。\n文件传输\n你在一台 B 主机上想往 A 主机上发送一个文件怎么办？不能用 scp / szrz 的话？继续 python 写个 http 上传？装个 ftpd 服务？不用那么麻烦，在 A 主机上监听端口：\nnc -l -p 8080 \u0026gt; image.jpg 然后再 B 主机上：\nnc 192.168.1.2 8080 \u0026lt; image.jpg netcat 嘛，就是用于通过网络把东西 cat 过去，注意，老版本 GNU / OpenBSD 的 netcat 在文件结束（标准输入碰到 EOF），发送文件一端就会关闭连接，而新版本不会，你需要再开个窗口到 A 主机上看看接收下来的文件尺寸和源文件比较一下判断传输是否结束。\n当传输完成后，你再任意一端 CTRL+C 结束它。对于新版 OpenBSD 的 netcat 有一个 -N 参数，可以指明 stdin 碰到 EOF 就关闭连接（和老版本一致），我们写作：\n/bin/nc.openbsd -N 192.168.1.2 8080 \u0026lt; image.jpg 你机器上的 nc 命令有可能指向 /bin/nc.traditional 或者 /bin/nc.openbsd 任意一个，这里显示指明调用 openbsd 版本的 netcat。\n这样在 openbsd 新版本的 netcat 中使用 -N参数，就不需要再开个终端去手工检查传输是否完成，传输结束了就会自动退出。其实 GNU 版本的 netcat 也有可以加个 -q0 参数，达到和 openbsd 版本 -N 的效果：\n/bin/nc.traditional -q0 192.168.1.2 8080 \u0026lt; image.jpg 只不过是 Linux 下面最新的 GNU netcat，对应 Windows 版本 没有该参数，所以从 Windows 传文件过去时，少不了再开个终端看一下进度，如果是 Linux 端发送就没问题了。通过管道协作，搭配 tar 命令，还可以方便的传一整个目录过去。\n使用 netcat 这个系统默认安装的工具进行文件传输，可以算作你保底的手段，当 scp/ftp 都没法使用的情况下，你的一个杀手锏。\n网速吞吐量测试\n最简单的方法，GNU 版本的 netcat 加上 -v -v 参数后，结束时会统计接收和发送多少字节，那么此时 A 主机上显示运行 GNU 版本的 nc 监听端口：\n/bin/nc.traditional -v -v -n -l -p 8080 \u0026gt; /dev/null 加 n 的意思是不要解析域名，避免解析域名浪费时间造成统计误差，然后 B 主机上：\ntime nc -n 192.168.1.2 8080 \u0026lt; /dev/zero 回车后执行十秒钟按 CTRL+C 结束，然后在 A 主机那里就可以看到接收了多少字节了，此时根据 time 的时间自己做一下除法即可得知，注意 GNU 的 netcat 统计的数值是 32 位 int，如果传输太多就回环溢出成负数了。\n对于 OpenBSD 版本的 nc 我们可以用管道搭配 dd 命令进行统计，服务端运行：\nnc -l -p 8080 \u0026gt; /dev/null 客户端运行 dd 搭配 nc：\ndd if=/dev/zero bs=1MB count=100 | /bin/nc.openbsd -n -N 192.168.1.2 8080 结束以后会有结果出来，注意这里使用了 -N 代表 stdin 碰到 EOF 后就关闭连接，这里凡是写 nc 命令的地方，代表 GNU/OpenBSD 任意版本的 netcat 都可以，显示的指明路径，就代表必须使用特定版本的 netcat，上条命令等效的 GNU 版本是：\ndd if=/dev/zero bs=1MB count=100 | /bin/nc.traditional -n -q0 192.168.1.2 8080 其实上面两种方法都把建立连接的握手时间以及 TCP 窗口慢启动的时间给计算进去了，不是特别精确，最精确的方式是搭配 pv 命令（监控统计管道数据的速度），在 A 主机运行：\nnc -l -p 8080 | pv 然后再 B 主机运行：\nnc 192.168.1.2 8080 \u0026lt; /dev/zero 此时 A 主机那端持续收到 B 主机发送过来的数据并通过管道投递给 pv 命令后，你就能看到实时的带宽统计了，pv 会输出一个实时状态：\n353MiB 0:00:15 [22.4MiB/s] [ \u0026lt;=\u0026gt; ] 让你看到最新的带宽吞吐量，这是最准确的吞吐量测试方法，在不需要 iperf 的情况下，直接使用 nc 就能得到一个准确的数据。\n系统后门\n假设你用串口登录到 A 主机，上面十分原始，包管理系统都没有，sshd/telnetd 都跑不起来，这时候你想用 B 主机通过网络登录 A 主机有没有办法？\nGNU 版本的 netcat 有一个 -e 参数，可以在连接建立的时候执行一个程序，并把它的标准输入输出重定向到网络连接上来，于是我们可以在 A 主机上 -e 一下 bash：\n/bin/nc.traditional -l -p 8080 -e /bin/bash 按回车打开系统后门，然后再 B 主机那里照常：\nnc 192.168.1.2 8080 你就可以在 B 主机上登录 A 主机的 shell 了，操作完成 CTRL+C 结束。\n对于 openbsd 版本的 netcat，-e 命令被删除了，没关系，我们可以用管道来完成，和刚才一样，在 A 主机上：\nmkfifo /tmp/f cat /tmp/f | /bin/bash 2\u0026gt;\u0026amp;1 | /bin/nc.openbsd -l -p 8080 \u0026gt; /tmp/f 然后 B 主机和刚才一样：\nnc 192.168.1.2 8080 即可访问，用完注意将 /tmp/f 这个 fifo 文件删除。\nps 查看每个进程的更多信息，包括用户ID、CPU和内存使用、启动时间等\nps -aux 显示指定用户的所有进程\nps -u [username] 显示进程树\nps -ejH ps 命令本身不支持实时更新，但可以结合 watch 命令实现这一功能：\nwatch ps aux 按CPU或内存使用排序：将进程按CPU或内存使用量降序排序\nps aux --sort=-pcpu ps aux --sort=-pmem netstat 查看当前系统上所有 TCP 和 UDP 端口的监听状态，并显示关联到这些端口的进程信息\nnetstat -tulnp -n (Numeric)： 显示原始的数字地址和端口号，而不是尝试解析主机名、服务名或端口名。这加快了命令的执行速度并减少了命令可能因解析而失败的情况\n-p (Program)： 显示哪个进程正在使用指定的套接字。这对于确定哪个应用程序正在监听或建立特定的网络连接特别有用。注意，这个选项通常需要 root 权限才能看到所有信息。\nlsof lsof 命令是 Linux 系统的扩展工具，它的含义是 list opened filedesciptor （列出已经打开的文件描述符）。\n默认情况下，系统是不存在这个命令的，需要安装一下\nsudo apt install lsof 默认情况下，lsof 的输出比较多，我们可以使用 grep 命令过滤我们想要查看的进程打开的 fd 信息，如：\nlsof -i | grep process 或者使用 lsof -p pid 也能过滤出指定的进程打开的 fd 信息.\nsocket 也是一种 fd，如果需要仅显示系统的网络连接信息，使用的是 -i 选项即可.\n和 netstat 命令一样，lsof -i 默认也会显示 ip 地址（hostname）和端口号的别名，我们只要使用 -n 和 -P 选项就能相对应地显示 ip 地址和端口号了，综合起来就是 lsof -Pni\nfind # 按名称查找文件：在指定目录及其子目录中搜索名为 filename.txt 的文件。 find /path/to/search -name filename.txt # 按类型查找文件： find /path -type f 查找所有文件。 find /path -type d 查找所有目录。 # 按修改时间查找文件 find /path -mtime +10 查找 10 天前修改的文件。 find /path -mtime -10 查找最近 10 天内修改的文件。 -mmin -10：搜索最近 10 分钟内修改的文件。 # 按大小查找文件 find /path -size +50M 查找大于 50 MB 的文件。 在找到的文件上执行命令 find /path -type f -exec rm {}\\; 删除指定路径下的所有文件。 将测试与逻辑操作符相结合： find /path \\( -name \u0026#34;*.txt\u0026#34; -or -name \u0026#34;*.pdf\u0026#34; \\) 查找所有 .txt 和 .pdf 文件。 tcpdump tcpdump 是 Linux 系统提供一个非常强大的抓包工具，对排查网络问题非常有用。使用之前需要安装\nsudo apt install tcpdump 如果要使用 tcpdump 命令必须具有 sudo 权限。\ntcpdump 常用的选项有：\n-i : 指定要捕获的目标网卡名，网卡名可以使用ifconfig查看；如果要抓所有网卡的上的包，可以使用 any 关键字。\n## 抓取网卡ens33上的包 tcpdump -i ens33 ## 抓取所有网卡上的包 tcpdump -i any -X : 以 ASCII 和十六进制的形式输出捕获的数据包内容，减去链路层的包头信息；-XX 以 ASCII 和十六进制的形式输出捕获的数据包内容，包括链路层的包头信息。\n-n : 不要将 ip 地址显示成别名的形式；-nn 不要将 ip 地址和端口以别名的形式显示。\n-S 以绝对值显示包的 ISN 号（包序列号），默认以上一包的偏移量显示。\n-vv 抓包的信息详细地显示；-vvv 抓包的信息更详细地显示。\n-w 将抓取的包的原始信息（不解析，也不输出）写入文件中，后跟文件名：\ntcpdump -i any -w filename -r 从利用 -w 选项保存的包文件中读取数据包信息。\n除了可以使用选项以外，tcpdump 还支持各种数据包过滤的表达式，常见的形式如下：\n# 仅显示经过端口 8888 上的数据包（包括tcp:8888和udp:8888） tcpdump -i any \u0026#39;port 8888\u0026#39; # 仅显示经过端口是 tcp:8888 上的数据包 tcpdump -i any \u0026#39;tcp port 8888\u0026#39; # 仅显示从源端口是 tcp:8888 的数据包 tcpdump -i any \u0026#39;tcp src port 8888\u0026#39; # 仅显示源端口是 tcp:8888 或目标端口是 udp:9999 的包 tcpdump -i any \u0026#39;tcp src port 8888 or udp dst port 9999\u0026#39; # 仅显示地址是127.0.0.1 且源端口是 tcp:9999 的包 ，以 ASCII 和十六进制显示详细输出， # 不显示 ip 地址和端口号的别名 tcpdump -i any \u0026#39;src host 127.0.0.1 and tcp src port 9999\u0026#39; -XX -nn -vv 实例1.\n使用nc模拟服务端监听1234端口\nnc -v -l 127.0.0.1 1234 tcpdump 捕获port 1234上的数据包\nsudo tcpdump -i any \u0026#39;port 1234\u0026#39; -XX -nn -vv -S 使用nc模拟客户端连接服务器\nnc -v 127.0.0.1 1234 通过tcpdump的输出可以看到三次握手的过程：客户端先给服务器发送一个 SYN，然后服务器应答一个 SYN + ACK，应答的序列号是递增 1 的，表示应答哪个请求，接着客户端再应答一个 ACK。\n![image-20240118104321204](E:\\db资料\\Note\\some command.assets\\image-20240118104321204.png)\n实例二：连接一个不存在的侦听端口\n实例一演示的是正常的 TCP 连接三次握手过程捕获到的数据包。假如我们连接的服务器 ip 地址存在，但监听端口号不存在 ![image-20240118104754153](E:\\db资料\\Note\\some command.assets\\image-20240118104754153.png)\n抓包数据如下：\n![image-20240118104716795](E:\\db资料\\Note\\some command.assets\\image-20240118104716795.png)\n这个时候客户端发送 SYN，服务器应答 ACK+RST，这个应答包会导致客户端的 connect 连接失败返回。\ngdb 前提：\n1.在编译时需要-g选项使程序带有调试符号信息。\nstrip 命令移除掉某个程序中的调试信息：在程序测试没问题后，需要发布到生产环境或者正式环境，会生成不 带调试符号信息的程序，以减小程序体积或提高程序执行效率。\n2.建议关闭编译器的程序的优化选项。编译器的程序的优化选项一般有五个级别，从 O0~O4（注意第一个O0，是字母 O 加上数字 0）， O0 表示不优化（关闭优化），从 O1~O4 优化级别越来越高，O4 最大。关闭优化的目的是为了调试的时候，符号文件显示的调试变量等能与源代码完全对应起来。\n调试程序目标程序 # 使用 gdb 启动一个程序进行调试，也就是说这个程序还没有启动 gdb ./your_program # 查看各个命令帮助 help cmd # 设置命令行参数,单个命令行参数之间含有空格，可以使用引号将参数包裹起来 set args arg1 arg2 arg3 # 如果想清除掉已经设置好的命令行参数，使用 set args 不加任何参数即可 # 也可以在启动时设置参数 gdb --args ./your_program arg1 arg2 arg3 #查看设置的命令行参数 show args #运行 run # 简写r ❯ db.cpp:79 zsh: command not found: db.cpp:79 ❯ create_table_executor.cpp:24 zsh: command not found: create_table_executor.cpp:24 ❯ table.cpp:53 # 查看当前断点，当前执行语句附近的代码 list # 简写l # 第一次输入 list 命令，会显示断点处前后的代码，继续输入 list指令会以递增行号的形式继续显示剩下的代码行，一直到文件结束为止。 list 指令可以往前和往后显示代码，命令分别是 list + 和 list - # 开启TUI（Text User Interface）模式。GDB的TUI模式提供了一个文本界面，可以在调试时显示源代码、汇编代码、寄存器状态和GDB输出. 1.gdbtui -q 需要调试的程序名 2.直接使用 gdb 调试代码,使用Ctrl + X，然后按A可以在TUI模式和常规模式之间切换。在TUI模式中，可以使用方向键上下滚动代码,Ctrl + X,然后按o可在让焦点在源码和命令之前切换。 layout src #显示源代码窗口,src,reg,asm src : the source window cmd : the command window asm : the disassembly window regs : the register display # 将代码窗口的高度扩大5行代码 winheight src + 5 # 将代码窗口的高度减小4代码 winheight src - 4 # print可以输出变量值，也可以输出特定表达式计算结果值，甚至可以输出一些函数的执行结果值 p var # 打印变量的值。想输出该指针指向的对象的值，在变量名前面加上 * 解引用即可 # 将这个错误码对应的文字信息打印出来 p strerror(errno) # 修改变量的值 p i=1000 # print 输出变量值时可以指定输出格式，命令使用格式如下： print /format variable format 常见的取值有： o octal 八进制显示 x hex 十六进制显示 d decimal 十进制显示 # 输出一个变量的类型 ptype variable # 使输出更易读 set print pretty on # 关闭off #监视某一个变量或内存地址的值是否发生变化。发送变化时，gdb 就会中断下来。监视某个变量或者某个内存地址会产生一个“watch point”（观察点）。 watch 变量名或内存地址 # 需要注意的是：当设置的观察点是一个局部变量时。局部变量无效后，观察点也会失效 # display 命令监视的变量或者内存地址，每次程序中断下来都会自动输出这些变量或内存的值 display 变量名 info display delete display 编号 # 断点操作 b [函数名] # eg: b main b [文件名]:[行号] b [行号] # 当前文件 b [位置] if [条件] #在条件满足时触发断点 b [文件名]:[行号] thread [线程ID] # 只有当指定的线程达到该断点时，程序才会停止 # 列出所有断点 info breakpoints # 简写info b # 禁用和启用断点，如果 disable 和 enable 命令不加断点编号，则分别表示禁用和启用所有断点 disable [断点号] enable [断点号] # 删除断点 delete [断点号] delete # 删除全部断点 # 设置临时断点 tbreak [位置] #简写tb，该断点触发一次后自动删除。 # 断点触发后的操作 # 1.继续执行程序：当程序在断点处暂停时，使用此命令继续执行。 continue # c # 逐行执行：在断点处执行下一行代码（不进入函数内部）。 next # n #单步执行：执行下一行代码，如果是函数调用，则进入函数内部。 step # s # 在这样的代码func3(func1(1, 2), func2(8, 9))输入s，会先进入哪个函数呢？ # 函数调用方式，我们常用的函数调用方式有 __cdecl、__stdcall，C++ 的非静态成员函数的调用方式是__thiscall，这些调用方式，函数参数的传递本质上是函数参数的入栈的过程，而这三种调用方式参数的入栈顺序都是从右往左的，所以，这段代码中并没有显式标明函数的调用方式，所以采用默认__cdecl 方式。 # 所以输入 step 先进入的是 func2()，当从 func2() 返回时再次输入step 命令会接着进入 func1()，当从 func1 返回时，此时两个参数已经计算出来了，这时候会最终进入 func3() # 在某个函数中调试一会儿后，我们不需要再一步步执行到函数返回处，我们希望直接执行完当前函数并回到上一层调用处， finish # 与 finish 命令类似的还有return 命令，return 命令作用是在当前位置结束当前函数的执行，并返回到上一层调用，还可以指定该函数的返回值。二者的区别：finish 命令会执行函数到正常退出该函数；而 return 命令是立即结束执行当前函数并返回，也就是说，如果当前函数还有剩余的代码未执行完毕，也不会执行了 # 指定程序运行到某一行停下来 until # 想直接跳到 2774 行，直接输入 u 2774 # 查看当前所在线程的调用堆栈，能够知道调用层级关系 backtrace # 简写bt # 切换到其他堆栈处 frame 堆栈编号 # 简写f，编号不用加# # 查看当前函数的参数值 info args # 换到不同的线程 info threads # 查看当前所有的线程。每个线程都会有一个唯一的ID。 # 切换线程，比如，要切换到线程ID为 2 的线程 thread 2 # 然后就可以使用 continue、next、step 和 finish 等命令控制线程的执行。这些命令会在当前选中的线程上执行。 # 我们单步调试线程 A 时，我们不希望线程 A 函数中的值被其他线程改变。gdb 提供了一个在调试时将程序执行流锁定在当前调试线程的命令选项- scheduler-locking，这个选项有三个值，分别是 on、step 和 off， set scheduler-locking on/step/off # set scheduler-locking on 可以用来锁定当前线程，只观察这个线程的运行情况， 当锁定这个线程时， 其他线程就处于了暂停状态，也就是说你在当前线程执行 next、step、until、finish、return 命令时，其他线程是不会运行的。 set scheduler-locking step #也是用来锁定当前线程，当且仅当使用 next 或 step 命令做单步调试时会锁定当前线程，如果你使用 until、finish、return 等线程内调试命令，但是它们不是单步命令，所以其他线程还是有机会运行的。 set scheduler-locking off #用于关闭锁定当前线程。 # 调试多进程，这里说的多进程程序指的是一个进程使用 Linux 系统调用 fork 函数产生的子进程 1.用 gdb 先调试父进程，等子进程被 fork 出来后，使用 gdb attach 到子进程上去 2.gdb 调试器提供一个选项叫 follow-fork ，通过 set follow-fork mode 来设置是当一个进程 fork 出新的子进程时，gdb 是继续调试父进程（取值是 parent）还是子进程（取值是 child），默认是父进程（取值是 parent） # fork之后gdb attach到子进程 set follow-fork child # fork之后gdb attach到父进程，这是默认值 set follow-fork parent # 查看当前值 show follow-fork mode # gcc/g++ 编译出来的可执行程序并不包含完整源码，-g 只是加了一个可执行程序与源码之间的位置映射关系，我们可以通过 dir 命令重新定位这种关系。 dir SourcePath1:SourcePath2:SourcePath3 # 指定多个路径，使用: # dir 命令不加参数表示清空当前已设置的源码搜索目录 dir # SourcePath1、SourcePath2、SourcePath3 指的就是需要设置的源码目录，gdb 会依次去这些目录搜索相应的源文件。 # 将 print 显示的字符串或字符数组显示完整 使用 print 命令打印一个字符串或者字符数组时，如果该字符串太长，print 命令默认显示不全的，我们可以通过在 gdb 中输入 set print element 0 设置一下，这样再次使用 print 命令就能完整地显示该变量所有字符串了。 # 让被gdb调试的程序接收信号 我们让程序在接收到 Ctrl + C 信号（对应信号值是 SIGINT）时简单打印一行信息，当我们用 gdb 调试这个程序时，由于 Ctrl + C 默认会被 gdb 接收到（让调试器中断下来），导致我们无法模拟程序接收这一信号。解决这个问题有两种方式： 1. 在 gdb 中使用 signal 函数手动给我们的程序发送信号，这里就是 signal SIGINT 2. 改变 gdb 信号处理的设置，通过 handle SIGINT nostop print pass告诉 gdb 在接收到 SIGINT 时不要停止、并把该信号传递给调试目标程序 附加进程 某些情况下，一个程序已经启动了，我们想调试这个程序，但是又不想重启这个程序。假设有这样一个场景，我们的聊天测试服务器程序正在运行，我们运行一段时间之后，发现这个聊天服务器再也没法接受新的客户端连接了，这个时候我们肯定是不能重启程序的，如果重启，当前程序的各种状态信息就丢失了。这个时候，我们只需要使用 gdb attach 程序进程ID来将 gdb 调试器附加到我们的聊天测试服务器程序上即可。假设，我们的聊天程序叫 chatserver，我们可以使用 ps 命令获取该进程的 PID，然后 gdb attach 上去，就可以调试了。\nps -ef | grep chatserver 我们得到 chatserver 的 PID 为 42921，然后我们使用 gdb attach 42921 把 gdb 附加到 chatserver 进程：\ngdb attach 42921 # 42921 = $(pidof chatserver) 当用 gdb attach 上目标进程后，调试器会暂停下来，此时我们可以使用 continue 命令让程序继续运 行，或者加上相应的断点再继续运行程序。\n当您调试完程序想结束此次调试，且不对当前进程 chatserver 有任何影响，也就是说想让这个程序继续运行，可以在gdb的命令行界面输入 detach 命令让程序与 gdb 调试器分离，这样 chatserver 可以继续运行。然后再退出gdb就可以了。\n进程 Crash 之后如何定位问题——调试 core 文件 有时候，我们的程序运行一段时间后，会突然崩溃。这当然不是我们希望看到的，我们需要解决这个问题。只要程序在崩溃的时候，有 core 文件(当一个程序崩溃并产生 \u0026ldquo;core dumped\u0026rdquo; 时，生成的核心转储文件,通常称为 \u0026ldquo;core\u0026rdquo; 文件。核心转储文件用于保存程序崩溃时的内存快照)产生，我们就可以使用这个 core 文件来定位崩溃的原因。当然，Linux 系统默认是不开启程序崩溃产生 core 文件的这一机制的，我们可以使用 ulimit -c 来 查看系统是否开启了这一机制。（ulimit 这个命令不仅仅可以查看 core 文件生成是否开 启，还可以查看其它的一些功能，如系统允许的最大文件描述符的数量等等，具体的可以使用 ulimit - a 命令来查看。）\n如果我们需要修改某个选项的值， 可以使用 ulimit 选项名 设置值来修改，例如我们可以将 core 文件生成改成具体某个值（最大允许的字节数）或不限制大小，这里我们直接改成不限制大小，执行命令 ulimit -c unlimited\nulimit -c unlimited ulimit -a 还有一个问题就是，这样修改以后，只对当前会话有效，当我们关闭这个 Linux 会话后，这个设置项的值就会被还原成 0。如果我们的程序以后台程序（守护进程）运行，也就是说当前会话虽然被关闭，程序仍然继续在后台运行，这样这个程序崩溃在某个时刻崩溃后，是无法产生 core 文件，这种情形不利于排查问题。所以，我们希望这个选项永久生效。设置永久生效的方式有两种。\n1.在 /etc/security/limits.conf 中增加一行\n#\u0026lt;domain\u0026gt; \u0026lt;type\u0026gt; \u0026lt;item\u0026gt; \u0026lt;value\u0026gt; * soft core unlimited 这里设置的是不限制 core 文件的大小，也可以设置成具体的数值，如 1024 表示生成的 core 文件最大是 1024k。\n2.把ulimit -c unlimited这一行，加到 /etc/profile 文件中去，放到这个文件最后一行即可，然后执行source /etc/profile让配置立即生效。当然这只是对 root 用户，如果想仅仅作用于某一用户，可以把ulimit -c unlimited加到该用户对应的 ~/.bashrc 或 ~/.bash_profile 文件中去。加进去后记得source /etc/profile 或者source ~/.bashrc 生成的core文件的默认命名方式是：core.pid，其位置是崩溃程序所在目录，举个例子，比如某个程序当时运行时其进程 ID 是16663，那么如果其崩溃产生的 core 文件的名称是 core.16663。调试 core 文件的命令是：\ngdb filename corename # 查看崩溃时的调用堆栈，进一步分析就能找到崩溃的原因 bt 自定义 core 文件的名称和目录 /proc/sys/kernel/core_uses_pid 可以控制产生的 core 文件的文件名中是否添加 PID 作为扩 展，如果添加则文件内容为 1，否则为 0; /proc/sys/kernel/core_pattern 可以设置格式化的 core 文件保存位置或文件名。修改方式如下：\necho \u0026#34;/corefile/core-%e-%p-%t-%s\u0026#34; \u0026gt;\u0026gt; /proc/sys/kernel/core_pattern # 或者在/etc/sysctl.conf中设置 vim /etc/sysctl.conf # 加入下面这行 kernel.core_pattern=/corefile/core-%e-%p-%t-%s # 刷新，使其同步到/proc/sys/kernel/core_pattern文件中 sysctl -p /etc/sysctl.conf %e：程序文件的完整路径（路径中的/会被!替代）\n%p：添加 pid 到 core 文件名中\n%t：进程奔溃的时间戳\n%s：哪个信号让进程奔溃\n%h: 添加主机名到 core 文件名中\n%u: 添加当前 uid 到 core 文件名中\n%g: 添加当前 gid 到 core 文件名中\n需要注意的是，您使用的用户必须对指定 core 文件目录具有写权限，否则生成时会因为权限不足而导致无法生成 core 文件。\n","permalink":"https://dueplay.github.io/posts/linux%E5%9F%BA%E7%A1%80/","summary":"一、目录 1./bin：可执行二进制文件的目录，绿色是可执行文件，\n输入命名./date，date可执行文件执行。cat命令，查看文本文件内容，ctrl+c退出。\n2./boot：linux启动时用到的文件。reboot：重启。\n3./dev：存放设备文件，一切皆文件。\nsudo cat mice鼠标移动，输出。\nsudo临时获得一次管理员权限，cat是查看文件，mice是鼠标文件。\n4./etc：os相关的一些配置文件。cat passwd查看密码。\n5./home：用户的家目录会存在这。Linux系统支持多用户访问。~表示当前用户的家目录。\n6./lib：系统使用的函数库的目录。\n7./root：系统管理员的家目录。普通用户的家目录：/home/cookie。\n切换成管理员账户，sudu su。退出 exit。\n切换普通用户：su 用户名。退出 exit。\ncookie（用户名）@（at在）主机名：当前工作目录$(普通用户)#（管理员）\ncd空格 回车：回到当前用户的“家”目录，宿主目录，这个用户的所有数据。不是home。\ncd空格 - 回到上次工作目录。\n8./tmp：一般用户或正在执行的程序临时存放文件的目录。\n9./usr：unix system resource，应用程序存放目录。\n二、文件类型 linux下不以后缀名区分文件类型。ls -l 查看文件详细信息。\n普通文件-\n目录文件d\n套接字文件s\n软链接文件l\n字符设备文件c\n块设备文件b\n管道文件p\n第一个为文件类型，后面9个，三个一组，r可读，w可写，x可执行。分别为文件所有者权限，所属组权限，其他人的权限。数字2代表硬链接计数。第一个cookie为文件所有者，第二个是所属组。文件所占用的空间大小（byte），最后一次修改时间，文件名。\ngedit 文件名：用记事本编辑文件。\n三、命令 命令格式：命令 -可选 参数\n查看帮助文档：ls \u0026ndash;help；man 1 xxx：1是标准命令，2是系统调用，3是库函数\nctrl+p/n 上/下一条命令\nctrl+u 清空\nctrl+b 光标向前移动一个字符\nctrl+a 光标移动到最前\nctrl+e 光标移动到最后\n通配符：ls std*.h ls std??.h *代表一堆，？代表一个字符。\n输出重定向：\u0026gt;\n追加\u0026raquo;\n删除：rm -f强制删 ；rm -r 递归删（无敌），删目录时必须用这个。","title":"linux基础知识"},{"content":"1.::作用域运算符 可用::对被屏蔽的同名的全局变量进行访问\n后面有::的名称一定是类名或命名空间名。直接::代表全局作用域下\n通常情况下，如果有两个同名变量，一个是全局变量，另一个是局部变量，那么局部变量在其作用域内具有较高的优先权，它将屏蔽全局变量（就近原则）。\n//全局变量 int a = 10; void test(){ //局部变量 int a = 20; //全局a被隐藏 cout \u0026lt;\u0026lt; \u0026#34;a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } 程序的输出结果是a:20。在test函数的输出语句中，使用的变量a是test函数内定义的局部变量，因此输出的结果为局部变量a的值。\n作用域运算符可以用来解决局部变量与全局变量的重名问题\n//全局变量 int a = 10; //1. 局部变量和全局变量同名 void test(){ int a = 20; //打印局部变量a cout \u0026lt;\u0026lt; \u0026#34;局部变量a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; //打印全局变量a cout \u0026lt;\u0026lt; \u0026#34;全局变量a:\u0026#34; \u0026lt;\u0026lt; ::a \u0026lt;\u0026lt; endl; } 这个例子可以看出，作用域运算符可以用来解决局部变量与全局变量的重名问题，即在局部变量的作用域内，可用::对被屏蔽的同名的全局变量进行访问。\n2.namespace 1.命名空间用途：解决名称冲突\n在game1和game2中都有相同名称的goAtk函数，如果不使用命名空间，会有二义性，编译报错。\n#include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;game1.h\u0026#34; #include \u0026#34;game2.h\u0026#34; void test01(){ LOL::goAtk(); KingGlory::goAtk(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } game1.h中\n#pragma once #include \u0026lt;iostream\u0026gt; using namespace std; //lol namespace LOL { void goAtk(); } game1.cpp中\n#include \u0026#34;game1.h\u0026#34; void LOL::goAtk() { cout \u0026lt;\u0026lt; \u0026#34;lol的攻击函数\u0026#34; \u0026lt;\u0026lt; endl; } game2.h中\n//王者荣耀 namespace KingGlory { void goAtk(); } 运行结果：\n2.命名空间下可以存放：变量，函数，结构体，类。\n3.命名空间必须声明在全局的作用域下。\n4.命名空间可以嵌套命名空间。\n5.命名空间是开放的，可以随时添加新的成员。\n6.命名空间可以是匿名的\n7.命名空间可以取别名\n//2.命名空间下可以存放：变量，函数，结构体，类 namespace A { int m_A = 10; void func(); struct Person{}; class Animal{}; } //3.命名空间必须声明在全局的作用域下。在局部中定义会报错:不允许进行命名空间定义 void test02() { /*namespace b { };*/ } //4.命名空间可以嵌套命名空间。 namespace B { int m_A = 20; namespace C { int m_A = 30; } } void test03() { cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::m_A \u0026lt;\u0026lt; endl;//20 cout \u0026lt;\u0026lt; \u0026#34;C命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::C::m_A \u0026lt;\u0026lt; endl;//30 } //5.命名空间是开放的，可以随时添加新的成员。 namespace B { int m_B = 40; }//这段代码不会与上面的B冲突，而是合二为一 void test04() { cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::m_A \u0026lt;\u0026lt; endl;//20 cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_B = \u0026#34; \u0026lt;\u0026lt; B::m_B \u0026lt;\u0026lt; endl;//40 } //6.命名空间可以是匿名的 namespace { int m_C = 50; int m_D = 50; } void test05() { cout \u0026lt;\u0026lt; \u0026#34;m_C = \u0026#34; \u0026lt;\u0026lt; m_C \u0026lt;\u0026lt; endl;//50 cout \u0026lt;\u0026lt; \u0026#34;m_D = \u0026#34; \u0026lt;\u0026lt; ::m_D \u0026lt;\u0026lt; endl;//50 } //7.命名空间可以取别名 namespace veryLongName { int m_A = 100; } void test06() { namespace veryShortName = veryLongName; cout \u0026lt;\u0026lt; veryLongName::m_A \u0026lt;\u0026lt; endl;//100 cout \u0026lt;\u0026lt; veryShortName::m_A \u0026lt;\u0026lt; endl;//100 } 3.using声明和using编译指令 在开发中通常不自己写命名空间\n#include \u0026lt;iostream\u0026gt; using namespace std; namespace LOL { int sunWuKongId = 1; } namespace KingGlory { int sunWuKongId = 3; } void test01() { //int sunWuKongId = 2; //1.using声明 //注意：using声明和就近原则不要同时出现，尽量避免 //using声明导致“LOL::sunWuKongId”的多次声明 using LOL::sunWuKongId;//告诉编译器使用的是sunWuKongId是LOL里的。 cout \u0026lt;\u0026lt; sunWuKongId \u0026lt;\u0026lt; endl; } void test02() { //int sunWuKongId = 2; //2.using编译指令 //注意：using编译指令和就近原则同时出现，优先使用就近原则 //当使用多个using编译指令，并且出现同名情况，使用数据依然加作用域,不加则不明确 using namespace LOL; using namespace KingGlory; cout \u0026lt;\u0026lt; LOL::sunWuKongId \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; KingGlory::sunWuKongId \u0026lt;\u0026lt; endl; } int main() { test02(); system(\u0026#34;pause\u0026#34;); return 0; } 报错：无法解析的外部命令。是在链接阶段出错了.\n4.函数重载原理 编译器为了实现函数重载，也是默认为我们做了一些幕后的工作，编译器用不同的参数类型来修饰不同的函数名，比如void func();编译器可能将函数名修饰成_func,当编译器碰到void func(int x)，编译器可能将函数名修饰为__func_int;当编译器碰到void func(int x,char c)；编译器可能会将函数名修饰为_func_int_char;我这里使用”可能”这个字眼是因为编译器如何修饰重载的函数名称并没有一个统一的标准，所以不同的编译器可能会产生不同的内部名。\nvoid func(){} void func(int x){} void func(int x,char y){} 以上三个函数在linux下生成的编译之后的函数名为:\n_Z4funcv //v 代表void,无参数\n_Z4funci //i 代表参数为int类型\n_Z4funcic //i 代表第一个参数为int类型，第二个参数为char类型\n5.extern “C”浅析 主要用途：c++中调用c语言的文件\n以下在Linux下测试:\nc函数: void MyFunc(){} ,被编译成函数: MyFunc c++函数: void MyFunc(){},被编译成函数: _Z6Myfuncv 通过这个测试，由于c++中需要支持函数重载，所以c和c++中对同一个函数经过编译后生成的函数名是不相同的，这就导致了一个问题，如果在c++中调用一个使用c语言编写模块中的某个函数，那么c++是根据c++的名称修饰方式来查找并链接这个函数，那么就会发生链接错误，以上例，在c++中调用MyFunc函数，在链接阶段会去找Z6Myfuncv，结果是没有找到的，因为这个MyFunc函数是c语言编写的，生成的符号是MyFunc。\n那么如果我想在c++调用c的函数怎么办？\nextern \u0026ldquo;C\u0026quot;的主要作用就是为了实现c++代码能够调用其他c语言代码。加上extern \u0026ldquo;C\u0026quot;后，这部分代码编译器按c语言的方式进行编译和链接，而不是按c++的方式。\n#ifdef __cplusplus//如果c++编译器在编译这个文件的时候，会有__cplusplus宏，就会将下面代码用c方式链接 extern \u0026#34;C\u0026#34; {//告诉编译器，这个{}中的代码都用c语言的方式来链接 #endif #include \u0026lt;stdio.h\u0026gt; void show(); #ifdef __cplusplus } #endif #include \u0026#34;test.h\u0026#34; void show() { printf(\u0026#34;hello world\\n\u0026#34;); } #include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;test.h\u0026#34; //解决方法1. //告诉编译器 利用c语言的方式链接show函数，这种方式就不用包含头文件了,适合一个函数的情况 //extern \u0026#34;C\u0026#34; void show(); //解决方法2：在.h中添加6行代码 void test01() { show();//show函数是在c语言编写的模块中，编译器如果按照c++的方式去找show， //可能将函数名称修饰为_Z4showv的形式，再去调用。在编译时用c++得方式去链接这个函数 //找的其实是_Z4showv这个名称，找不到这个函数的实现体。 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } ","permalink":"https://dueplay.github.io/posts/namespace%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/","summary":"1.::作用域运算符 可用::对被屏蔽的同名的全局变量进行访问\n后面有::的名称一定是类名或命名空间名。直接::代表全局作用域下\n通常情况下，如果有两个同名变量，一个是全局变量，另一个是局部变量，那么局部变量在其作用域内具有较高的优先权，它将屏蔽全局变量（就近原则）。\n//全局变量 int a = 10; void test(){ //局部变量 int a = 20; //全局a被隐藏 cout \u0026lt;\u0026lt; \u0026#34;a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } 程序的输出结果是a:20。在test函数的输出语句中，使用的变量a是test函数内定义的局部变量，因此输出的结果为局部变量a的值。\n作用域运算符可以用来解决局部变量与全局变量的重名问题\n//全局变量 int a = 10; //1. 局部变量和全局变量同名 void test(){ int a = 20; //打印局部变量a cout \u0026lt;\u0026lt; \u0026#34;局部变量a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; //打印全局变量a cout \u0026lt;\u0026lt; \u0026#34;全局变量a:\u0026#34; \u0026lt;\u0026lt; ::a \u0026lt;\u0026lt; endl; } 这个例子可以看出，作用域运算符可以用来解决局部变量与全局变量的重名问题，即在局部变量的作用域内，可用::对被屏蔽的同名的全局变量进行访问。\n2.namespace 1.命名空间用途：解决名称冲突\n在game1和game2中都有相同名称的goAtk函数，如果不使用命名空间，会有二义性，编译报错。\n#include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;game1.h\u0026#34; #include \u0026#34;game2.h\u0026#34; void test01(){ LOL::goAtk(); KingGlory::goAtk(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } game1.","title":"namespace，using，重载，extern c"},{"content":"First time here, just a test. 测试。\n","permalink":"https://dueplay.github.io/posts/hugo-test/","summary":"First time here, just a test. 测试。","title":"Hugo Test"}]